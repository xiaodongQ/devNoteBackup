## 平均负载

[到底应该怎么理解“平均负载”？](https://time.geekbang.org/column/article/69618)

* 简单来说，**平均负载**是指单位时间内，系统处于*可运行状态*和*不可中断状态*的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。
    - 可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。
    - 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。
        + 不可中断状态实际上是系统对进程和硬件设备的一种保护机制。

* `uptime`
    - `09:04:25 up 21 min,  4 users,  load average: 0.00, 0.03, 0.05`
    - 当前时间、系统运行时间以及正在登录用户数。 过去 1 分钟、5 分钟、15 分钟的平均负载（Load Average）。
    - 三个不同时间间隔的平均值，其实给我们提供了，分析系统负载**趋势**的数据来源，让我们能更全面、更立体地理解目前的负载状况
    - 一般当平均负载高于CPU数量*70%*的时候，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。但70%这个数字并不是绝对的，最推荐的方法，还是把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。

* 查看cpu个数(逻辑个数)
    - 查看逻辑CPU的个数(若该cpu支持超线程，则1个物理核对应2个逻辑核/线程。 若支持超线程则与物理核是两倍的关系)
        + `cat /proc/cpuinfo |grep "model name"`
        + 或 `cat /proc/cpuinfo |grep "processor"|wc -l`
    - 物理CPU个数
        + `cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l`
    - 查看CPU是几核心(物理核数，每个cpu的物理核数，若有多个物理cpu，核心数都一样就一条记录)
        + `cat /proc/cpuinfo |grep "cores"|uniq`

* 平均负载与 CPU 使用率
    - 由上面的定义：平均负载是指单位时间内，处于可运行状态和不可中断状态的进程数。 所以，平均负载不仅包括了正在使用CPU的进程，还包括**等待 CPU 和等待 I/O**的进程。
    - 而 **CPU 使用率**，是单位时间内 CPU 繁忙情况的统计，跟平均负载并**不一定完全对应**
        + *CPU 密集型进程*，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
        + *I/O 密集型进程*，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；
        + 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高

* 前置条件
    - 用`iostat`、`mpstat`、`pidstat`，找出平均负载升高的根源。
    - 自己的环境(与链接中不一样):
        + CentOS虚拟机 7.6.1810
        + 2个逻辑CPU、内存1.4G
    - 预先安装 stress 和 sysstat
        + sysstat(CentOS中自带了)包含了常用的 Linux 性能工具，用来监控和分析系统的性能。 本次用到其中的`mpstat` 和 `pidstat`
            * `sar`/`iostat`也包含其中，本案例暂时没用到
        + stress是一个Linux系统压力测试工具（本案例用作异常进程模拟平均负载升高的场景。）
            * 先`yum install -y epel-release`, 再 `yum install -y stress`
                - EPEL (Extra Packages for Enterprise Linux)是基于Fedora的一个项目，为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux.
                - 首先我们需要安装一个叫”epel-release”的软件包，这个软件包会自动配置yum的软件仓库。当然你也可以不安装这个包，自己配置软件仓库也是一样的。 软件仓库配置目录在：`/etc/yum.repos.d/`
            * 使用
                - `-t N` 或 `--timeout N`：运行秒数
                - `-c N` 或 `--cpu N`：产生多个处理sqrt()函数的CPU进程
                    + `stress -c 2 -t 10` 其两个进程测CPU，跑10s
                - `-i N` 或 `--io N`：产生多个处理sync()函数的磁盘I/O进程
                - `-m N` 或 `--vm N`：产生多个处理malloc()/free()内存分配函数的进程
                    + `--vm-bytes B`：指定内存的byte数为B，默认值是256MB
                    + `--vm-hang N`：指定malloc分配的内存多少秒后free()释放掉，默认不释放，0无效
                - `-d N` 或 `--hdd N`：产生多个处理write()/unlink()的进程
                    + `--hdd-bytes B`：指定每个hdd进程处理的byte字节数，默认1GB

* 案例
    - CPU密集型进程： CPU 使用率 100%
        + 在第一个终端运行 stress 命令，模拟一个 CPU 使用率 100% 的场景：`stress --cpu 1 --timeout 600`
        + 在第二个终端运行 uptime 查看平均负载的变化情况：`watch -n3 -d uptime`
        + 在第三个终端运行 mpstat 查看 CPU 使用率的变化情况：`mpstat -P ALL 5`
        + 用pidstat来查询是哪个进程导致了 CPU 使用率为 100%：`pidstat -u 5 1`
    - I/O密集型进程： 模拟 I/O 压力(不停执行sync)
        + `stress -i 1 --timeout 600`, 用`-d`起写文件进程对虚拟机压力比较明显
        + `watch -d uptime`
        + `mpstat -P ALL 5 1`
        + `pidstat -u 5 1`
    - 大量进程场景
        + 当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程
        + `stress -c 8`，超出系统CPU核数，CPU处于严重过载状态

## CPU 上下文切换

[经常说的 CPU 上下文切换是什么意思？](https://time.geekbang.org/column/article/69859)

* CPU 上下文
    - 在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置好 CPU 寄存器和程序计数器（Program Counter，PC）。
    - CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 **CPU 上下文**。

* CPU 的上下文切换
    - **CPU 上下文切换**，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。
    - 根据任务的不同，CPU 的上下文切换就可以分为几个不同的场景，也就是进程上下文切换、线程上下文切换以及中断上下文切换。
    - 进程上下文切换
        + Linux 按照特权等级，把进程的运行空间分为内核空间(对应CPU特权等级Ring 0)和用户空间(对应CPU特权等级Ring 3)， 进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。 从用户态到内核态的转变，需要通过系统调用来完成
        + 系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程
        + 所以一次系统调用的过程，其实是发生了两次 CPU 上下文切换(需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的)，系统调用过程通常称为特权模式切换，而不是上下文切换
        + **进程的上下文切换**就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的*虚拟内存、栈等*保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。
        + 根据[Tsuna](https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html)的测试报告，每次上下文切换都需要*几十纳秒到数微秒*的 CPU 时间。在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在*寄存器、内核栈以及虚拟内存等资源的保存和恢复*上，进而大大缩短了真正运行进程的时间。这也正是导致平均负载升高的一个重要因素。
        + Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系
            * 转译后备缓冲器，也被翻译为页表缓存、转址旁路缓存，为CPU的一种缓存，由存储器管理单元用于改进虚拟地址到物理地址的转译速度。
            * 用处：其搜索关键字为虚拟内存地址，其搜索结果为物理地址。如果请求的虚拟地址在TLB中存在，CAM 将给出一个非常快速的匹配结果，之后就可以使用得到的物理地址访问存储器。如果请求的虚拟地址不在 TLB 中，就会使用标签页表进行虚实地址转换，而标签页表的访问速度比TLB慢很多。
            * 过程：当cpu要访问一个虚拟地址/线性地址时，CPU会首先根据虚拟地址的高20位（20是x86特定的，不同架构有不同的值）在TLB中查找。如果是表中没有相应的表项，称为TLB miss(不命中)，需要通过访问慢速RAM中的页表*计算*出相应的物理地址。同时，物理地址被*存放*在一个TLB表项中，*以后*对同一线性地址的访问，直接从TLB表项中获取物理地址即可，称为TLB hit(命中)。
            * [转译后备缓冲区](https://baike.baidu.com/item/%E8%BD%AC%E8%AF%91%E5%90%8E%E5%A4%87%E7%BC%93%E5%86%B2%E5%8C%BA/22685572?fromtitle=TLB&fromid=2339981)
            * [TLB的作用及工作过程](https://www.cnblogs.com/alantu2018/p/9000777.html)
        + 进程上下文切换潜在的性能问题: 当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。
    - 线程上下文切换
        + 线程与进程最大的区别在于，线程是调度的基本单位，而进程则是资源拥有的基本单位
        + 线程的上下文切换其实就可以分为两种情况：
            * 第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
            * 第二种，前后两个线程属于同一个进程。此时，因为*虚拟内存是共享的*，所以在切换时，虚拟内存这些资源就保持不动，*只需要切换线程的私有数据、寄存器等*不共享的数据。
    - 中断上下文切换
        + 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。
        + 跟进程上下文不同，中断上下文切换并不涉及到进程的用户态
        + 中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。
        + **对同一个 CPU 来说，中断处理比进程拥有更高的优先级**，所以*中断上下文切换并不会与进程上下文切换同时发生*。

* 进程调度的场景
    - 为了保证所有进程可以得到公平调度，CPU时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
    - 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
    - 当进程通过睡眠函数 *sleep* 这样的方法将自己*主动挂起*时，自然也会重新调度。
    - 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行
    - 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。
