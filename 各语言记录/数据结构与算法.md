## 数据结构与算法之美

* 极客时间专栏：[数据结构与算法之美](https://time.geekbang.org/column/intro/126)
* 复杂度分析
    - 复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半
    - 你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比我实实在在跑一遍得到的数据更准确吗？这种方式叫`事后统计法`。但是，这种统计方法有非常大的局限性。
        + 1. 测试结果非常依赖测试环境
            * 换到另一台机器上时，可能会有截然相反的结果
        + 2. 测试结果受数据规模的影响很大
            * 对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别
            * 除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能
            * 我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法
    - `大 O 复杂度表示法`
        + 大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度(asymptotic time complexity)，简称`时间复杂度`
    - 如何分析一段代码的时间复杂度？三个比较实用的方法：
        + 1. 只关注循环执行次数最多的一段代码
        + 2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
            * 如果 `T1(n)=O(f(n))`，`T2(n)=O(g(n))`；那么 `T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n)))`
        + 3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
            * 如果 `T1(n)=O(f(n))`，`T2(n)=O(g(n))`；那么 `T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n))`
    - 几种常见时间复杂度实例分析
        + 常见的复杂度量级并不多：`O(1)`、`O(logn)`、`O(n)`、`O(nlogn)`、`O(n^2)`/`O(n^3)`/.../`O(n^k)`、`O(2^n)`、`O(n!)`
        + 上述复杂度粗略地分为两类：*多项式量级*和*非多项式量级*。
            * 其中，非多项式量级只有两个：`O(2^n)` 和 `O(n!)`
                - 我们把时间复杂度为非多项式量级的算法问题叫作*NP（Non-Deterministic Polynomial，非确定多项式）问题*
                - 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长
        + 主要看几种常见的*多项式时间复杂度*
            * 常数阶`O(1)`：只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)
            * 对数阶`O(logn)`、线性对数阶`O(nlogn)`
                - 实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。
                - 由于对数之间是可以互相转换的，`log3(n)`(此处为以3为底n的对数，由于编辑器排版问题展示不好位置) 就等于 `log3(2) * log2(n)`，所以 `O(log3n) = O(C * log2n)`，其中 `C=log3(2)` 是一个常量
                - 在采用大 O 标记复杂度的时候，可以忽略系数，即 `O(Cf(n)) = O(f(n))`，所以，`O(log2(n))` 就等于 `O(log3(n))`，因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 `O(logn)`
                - 如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)
            * `O(m+n)`、`O(m*n)`
                - 跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定
                - 我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个
    - *空间复杂度分析*
        + 类比一下时间复杂度，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系
        + 常见的空间复杂度就是 `O(1)`、`O(n)`、`O(n^2)`，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多
    - 四个复杂度分析方面的知识点
        + *最好情况时间复杂度（best case time complexity）*
            * 在最理想的情况下，执行这段代码的时间复杂度。
        + *最坏情况时间复杂度（worst case time complexity）*
            * 在最糟糕的情况下，执行这段代码的时间复杂度
        + *平均情况时间复杂度（average case time complexity）*
            * 最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：平均情况时间复杂度，后面简称为平均时间复杂度
            * 平均时间复杂度 的全称应该叫`加权平均时间复杂度`或者`期望时间复杂度`(将各种情况发生的概率考虑进去)
        + *均摊时间复杂度（amortized time complexity）*
            * 大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限
    - [03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？](https://time.geekbang.org/column/article/40036)
    - [04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度](https://time.geekbang.org/column/article/40447)
* [05 | 数组：为什么很多编程语言中数组都从0开始编号？](https://time.geekbang.org/column/article/40961)
    - 数组（Array）是一种线性表数据结构。它用一组`连续`的内存空间，来存储一组具有`相同类型`的数据
    - 数组为了保证内存数据连续性，会导致插入、删除操作比较低效
        + 插入时间复杂度分析
            * 假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位
                - 如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 `O(1)`
                - 但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 `O(n)`
                - 因为我们在每个位置插入元素的`概率是一样的`，所以平均情况时间复杂度为 (1+2+…n)/n=`O(n)`
            * 若数组中的数据是*有序*的，则在某位置插入一个新元素时，就必须按照刚才的方法搬移 k 之后的数据
            * 但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合，则可`改进`为：
                - 在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，*直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置*
                - 利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 `O(1)`。这个处理思想在快排中也会用到
        + 删除操作复杂度分析
            * 跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了
                - 和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 `O(1)`；如果删除开头的数据，则最坏情况时间复杂度为 `O(n)`；平均情况时间复杂度也为 `O(n)`(删除末尾只操作1个数，删除开头操作n个数，第二个n-1...，删除每个元素概率为1/n，`(1+...+n)/n=(n+1)n/2n=(n+1)/2`)
            * 实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？
                - 可以*先记录*下已经删除的数据。每次的删除操作*并不是真正地搬移数据，只是记录数据已经被删除*。当数组没有更多空间存储数据时，我们再*触发执行一次*真正的删除操作，这样就大大减少了删除操作导致的数据搬移。(JVM 标记清除垃圾回收算法与之类似)
    - 开篇的问题：为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？
        + 从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”
            * 如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 `type_size` 的位置，a[k]的内存地址只需要用这个公式：
                - `a[k]_address = base_address + k * type_size`
            * 如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为
                - `a[k]_address = base_address + (k-1)*type_size`
            * 从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于CPU来说，就是多了一次减法指令。为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。
    - 在平时的业务开发中，我们可以直接使用编程语言提供的容器类(如Java的ArrayList)，但是，如果是特别底层的开发，直接使用数组可能会更合适


## 7天入门数据结构与算法

* 极客时间视频课程：[7天入门数据结构与算法](https://u.geekbang.org/lesson/7?article=159518)
    - [数据结构脑图](https://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c)
    - [算法脑图](https://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec)

知识简洁记忆

听七牛云许式伟老师的架构课里说到，“架构能力的提升，本质上是对你的知识脉络的反复梳理与融会贯通的过程”。
目标是把这些内容先读厚，再读薄，融会贯通。

* 数据结构(分三大块，一维数据结构、二维数据结构、特殊数据结构)
    - 一维：
        + 基础型
            * 数组 array
            * 链表 linked list
        + 高级
            * 栈 stack
            * 队列 queue
            * 双端队列 deque
            * 集合 set
            * 映射 map (hash or map)
    - 二维(从一维泛化过来)：
        + 基础型
            * 树 tree
            * 图 graph
        + 高级(在树的基础上加了很多判断)
            * 二叉搜索树 binary search tree (red-black tree, AVL)
            * 堆 heap
            * 并查集 disjoint set
            * 字典树 Trie
    - 特殊(用于工程中特定的场景)
        + 位运算 Bitwise
        + 布隆过滤器 BloomFilter
        + LRU Cache 缓存
* 算法(8大点，前三点是算法最基础的地方，)
    - 分支 Branch: if-else/switch
    - 循环 Iteration: for/while loop
    - 递归 Recursion: Divide & Conquer/Backtrace
    - 搜索 Search: 深度优先搜索 Depth first search/广度优先搜索 Breadth first search/启发式搜索 A*
    - 动态规划 Dynamic Programming
    - 二分查找 Binary Search
    - 贪心 Greedy
    - 数学 Math, 几何 Geometry(英 /dʒiˈɒmətri/)
