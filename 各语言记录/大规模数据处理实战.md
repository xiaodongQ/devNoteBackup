# 大规模数据处理实战

* 学习记录：[大规模数据处理实战](https://time.geekbang.org/column/article/90067)

> 学会用一个技术只是第一步，最重要的是要追问自己：  
	- 这个技术解决了哪些痛点？  
	- 别的技术为什么不能解决？  
	- 这个技术用怎样的方法解决问题？  
	- 采用这个技术真的是最好的方法吗？  
	- 如果不用这个技术，你会怎样独立解决这类问题？  

* 为什么 MapReduce 会被硅谷一线公司淘汰
	- 超大规模数据处理的技术发展阶段
		+ "石器时代"：MapReduce 诞生之前的时期
		+ "青铜时代"：2003 年，MapReduce 的诞生标志了超大规模数据处理的第一次革命
			* 《MapReduce: Simplified Data Processing on Large Clusters》论文，从纷繁复杂的业务逻辑中，为我们抽象出了 Map 和 Reduce 这样足够通用的编程模型，后面的 Hadoop 仅仅是对于 GFS、BigTable、MapReduce 的依葫芦画瓢
		+ "蒸汽机时代"：到了 2014 年左右，Google 内部已经几乎没人写新的 MapReduce 了
			* 2016 年开始，Google 在新员工的培训中把 MapReduce 替换成了内部称为 FlumeJava（不要和 Apache Flume 混淆，是两个技术）的数据处理技术
	- 为什么 MapReduce 会被取代？
		+ 高昂的维护成本
			* 使用 MapReduce，你需要严格地遵循分步的 Map 和 Reduce 步骤。当你构造更为复杂的处理架构时，往往需要协调多个 Map 和多个 Reduce 任务。然而，每一步的 MapReduce 都有可能出错。
			* 为了这些异常处理，很多人开始设计自己的协调系统（orchestration）。例如，做一个状态机（state machine）协调多个 MapReduce，这大大增加了整个系统的复杂度。
		+ 除了高昂的维护成本，MapReduce 的时间性能也是个棘手的问题。
			* 在实际的工作中，不是每个人都对 MapReduce 细微的配置细节了如指掌。这种情况下开发的系统是很难发挥好 MapReduce 的性能的。
			* MapReduce 的性能优化配置究竟复杂在哪，Google500 多页的 MapReduce 性能优化手册足够说明它的复杂度了。。。
