[TOC]


## Tips

开发过程过程中注意空格影响！
  makefile字符串赋值给变量时末尾空格(编辑器尽量开启空格和tab显示)


## REST

REST API: 即Representational State Transfer(表述性状态转移)的缩写
其优点如下：

* 在RESTful架构中，每一个URL代表一种资源；
* 客户端和服务器之间，传递这种资源的某种表现层；
* 客户端通过四个HTTP指令，对服务器端资源进行操作，实现“表现层状态转化”。 建议开发者使用REST API进行币币交易或者资产提现等操作。

## WebSocket API

WebSocket API: WebSocket是HTML5一种新的协议(Protocol)。

>它实现了客户端与服务器全双工通信，使得数据可以快速地双向传播。

通过一次简单的握手就可以建立客户端和服务器连接，服务器根据业务规则可以主动推送信息给客户端。

其优点如下：

* 客户端和服务器进行数据传输时，请求头信息比较小，大概2个字节;
* 客户端和服务器皆可以主动地发送数据给对方；
* 不需要多次创建TCP请求和销毁，节约宽带和服务器的资源。 强烈建议开发者使用WebSocket API获取**市场行情**和**买卖深度**等信息。

## grpc

### grpc介绍
[Go使用grpc+http打造高性能微服务](https://blog.csdn.net/RA681t58CJxsgCkJ31/article/details/78601747)

gRPC是由Google主导开发的RPC框架，使用HTTP/2协议并用Protobuf作为序列化工具

与REST不同的是，REST是基于HTTP1.1 JOSN格式的一种轻量级服务模式

#### JSON和Protobuf比较：

* 首先可以从JOSN与Protobuf之间的差别入手进行对比，Protobuf很难读，它是面向机器的文字格式，而JSON则是面向人的；
* Protobuf相对于JSON而言编解码速度都非常快；
* 最后就是兼容性，现在基本所有浏览器都支持JOSN格式，而Protobuf目前仅部分语言支持。

#### http1.1与http2比较

* http1.1是文本方式，因此http的请求我们都可以很清楚的读懂；
* http1.1中每一个请求会有一个新的connection，但是http2 是一个持续的http connection；
* http1是持续repetitive，http2是compressed；
* http1.1所有浏览器都默认支持，而http2只是部分支持。

HTTP/1的主要问题
[深度解析gRPC以及京东分布式服务框架跨语言实战](http://www.sohu.com/a/126977118_494947)

Head-of-line blocking，新请求的发起必须等待服务器对前一个请求的回应，无法同时发起多个请求，导致很难充分利用TCP连接。
* 头部冗余

HTTP头部包含大量重复数据，比如cookies，多个请求的cookie可能完全一样


### protocol buffer

[Potocol Buffer详解](https://www.cnblogs.com/oumyye/p/4652780.html)

Protobuf 编译器会将 .proto 文件编译生成对应的数据访问类以对 Protobuf 数据进行序列化、反序列化操作

#### 定义第一个Protocol Buffer消息
1. 创建扩展名为.proto的文件
2. 将以下内容存入该文件中。
      message LogonReqMessage {
          required int64 acctID = 1;
          required string passwd = 2;
      }

    说明:
    message是消息定义的关键字
    LogonReqMessage为消息的名字，等同于结构体名或类名。
    required前缀表示该字段为必要字段，既在序列化和反序列化之前该字段必须已经被赋值
    	(另外两个类似的关键字:optional和repeated)
    int64和string分别表示长整型和字符串型的消息字段
    	(在Protocol Buffer中存在一张类型对照表，该对照表中还将给出在不同的数据场景下，哪种类型更为高效。)
    acctID和passwd分别表示消息字段名
    标签数字1和2则表示不同的字段在序列化后的二进制数据中的布局位置。
    	(该值在同一message中不能重复，对于Protocol Buffer而言，标签值为1到15的字段在编码时可以得到优化，既标签值和类型信息仅占有一个byte，标签范围是16到2047的将占有两个bytes；在设计消息结构时，可以尽可能考虑让repeated类型的字段标签位于1到15之间，这样便可以有效的节省编码后的字节数量)

#### 定义第二个（含有枚举字段）Protocol Buffer消息。

enum UserStatus {
          OFFLINE = 0;  //表示处于离线状态的用户
          ONLINE = 1;   //表示处于在线状态的用户
      }
      message UserInfo {
          required int64 acctID = 1;
          required string name = 2;
          required UserStatus status = 3;
      }

   以上消息定义的关键性说明:
   enum是枚举类型定义的关键字
   UserStatus为枚举的名字
   枚举值之间的分隔符是分号，而不是逗号。
   OFFLINE/ONLINE为枚举值
   0和1表示枚举值所对应的实际整型值，可以为枚举值指定任意整型值，而无需总是从0开始定义

#### 定义第三个（含有嵌套消息字段）Protocol Buffer消息

可以在同一个.proto文件中定义多个message

enum UserStatus {
          OFFLINE = 0;
          ONLINE = 1;
      }
message UserInfo {
          required int64 acctID = 1;
          required string name = 2;
          required UserStatus status = 3;
      }
message LogonRespMessage {
          required LoginResult logonResult = 1;
          required UserInfo userInfo = 2;
      }

      说明：
      LogonRespMessage消息的定义中包含另外一个消息类型作为其字段，如UserInfo userInfo
      Protocol Buffer提供了另外一个关键字import，这样我们便可以将很多通用的message定义在同一个.proto文件中，而其他消息定义文件可以通过import的方式将该文件中定义的消息包含进来，如：
      import "myproject/CommonMessages.proto"

> Potocol Buffer部分概念原则

#### 限定符(required/optional/repeated)的基本规则
1. 在每个消息中必须至少留有一个required类型的字段。
2. 每个消息中可以包含0个或多个optional类型的字段。
3. repeated表示的字段可以包含0个或多个数据。需要说明的是，这一点有别于C++/Java中的数组，因为后两者中的数组必须包含至少一个元素。
4. 如果打算在原有消息协议中添加新的字段，同时还要保证老版本的程序能够正常读取或写入，那么对于新添加的字段必须是optional或repeated。

proto3中，去掉了required 和 optional

>We dropped required fields in proto3 because required fields are generally considered harmful and violating protobuf's compatibility semantics.

使用repeated时, protoc生成struct字段为指针数组，即成员都是指针
e.g. MsgList              []*HelloRequest

访问时，使用import包名加结构类型, e.g. 给结构体成员赋初值时: MsgList: []*(pt.HelloRequest){&(pt.HelloRequest{Name: "helloname"})}  (结构体变量的地址赋值给指针数组作为一个成员)

#### 类型对照表
见链接 [](https://www.cnblogs.com/oumyye/p/4652780.html)
| .proto Type | Notes | C++ Type | Java Type  |
| ----------- | ----- | -------- | ---------- |
| double      |       |double    |double      |
| float       |       |float     |float       |
| int32       | Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint32 instead.|  int32   |int|
| int64       | Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint64 instead.|  int64   |long|
| uint32      |  Uses variable-length encoding.|   uint32  |int|
| uint64      |  Uses variable-length encoding.|   uint64  |long|
| sint32      |  Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s.|   int32   |int|
| sint64      |  Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s.|   int64   |long|
| fixed32     | Always four bytes. More efficient than uint32 if values are often greater than 228.|    uint32  |int|
| fixed64     | Always eight bytes. More efficient than uint64 if values are often greater than 256.|   uint64  |long|
| sfixed32    |  Always four bytes.|   int32   |int|
| sfixed64    |  Always eight bytes.|  int64   |long|
| bool        || bool  |boolean|
| string      |A string must always contain UTF-8 encoded or 7-bit ASCII text.| string  |String|
| bytes       |May contain any arbitrary sequence of bytes.|  string  |ByteString|


#### Protocol Buffer消息升级原则

在实际的开发中会存在这样一种应用场景，消息格式因为某些需求的变化而不得不进行必要的升级，但又需要基于新老消息格式的新老程序同时运行，一般遵循如下规则：

1. 不要修改已经存在字段的标签号。
2. 任何新添加的字段必须是optional和repeated限定符，否则无法保证新老程序在互相传递消息时的消息兼容性。
3. 在原有的消息中，不能移除已经存在的required字段，optional和repeated类型的字段可以被移除，但是他们**之前使用的标签号必须被保留**，不能被新的字段重用。
4. int32、uint32、int64、uint64和bool等类型之间是兼容的，sint32和sint64是兼容的，string和bytes是兼容的，fixed32和sfixed32，以及fixed64和sfixed64之间是兼容的，这意味着如果想修改原有字段的类型时，为了保证兼容性，**只能将其修改为与其原有类型兼容的类型**，否则就将打破新老消息格式的兼容性。
5. optional和repeated限定符也是相互兼容的。

#### packages

我们可以在.proto文件中定义包名，如：
      package ourproject.lyphone;
      该包名在生成对应的C++文件时，将被替换为名字空间名称，既namespace ourproject { namespace lyphone。而在生成的Java代码文件中将成为包名。

#### gRPC c++

参考：
[对set_allocated_和mutable_的使用](https://blog.csdn.net/wujunokay/article/details/51287312)

[gRPC Basics - C++](https://grpc.io/docs/tutorials/basic/cpp/)

对于grpc中的结构体成员，通过：
`request->mutable_B类型成员名b()` 的方式访问，

查看分析grpc生成的.cpp和.h文件代码，生成的成员函数为`mutable_`、`set_allocated_`，通过这种方式访问和设置成员。

下面代码演示(另外分析函数入参被限定为const时的访问情况)：

* 程序伪代码：

```cpp

// 假设 B b; 是A的成员变量
void func(const &B)
{
}
...(const A *request) 
{
    // A类中的成员b作为入参，调用func函数，表面上需要解引用作为入参，但直接解引用会报错
    func(*request->mutable_b());
}

// grpc访问结构体成员
若request为const修饰的变量，要调用如下func函数的话，需要解引用，会出现const的this调用非const函数，编译报类似下面错误。
```

* 编译报错：

```sh
# const访问问题
错误：将‘const A’作为‘B* A::mutable_Bstructfield()’的‘this’实参时丢弃了类型限定 [-fpermissive]
```

* 使用方式：

可通过新增变量方式解引用：

```cpp
    auto a = new A;  //注意资源的释放，可以改成智能指针防止忘记
    a->CopyFrom(*request)
    func(*a->mutable_b)
```


## TCP

TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

## 集群

LB集群是load balance 集群的简写，负载均衡集群
LVS是一个实现负载均衡集群的开源软件项目
LVS架构从逻辑上可分为调度层(Director)、server集群层(Real server)和共享存储层

[gRPC服务发现&负载均衡](https://segmentfault.com/a/1190000008672912)

## windows 命令

tasklist 查看进程
tasklist|findstr "9108"

## curl

>curl -X 123.45.67.89:1080 Yahoo
-X选项用于指定代理（服务器和端口号）

>curl -d "user=nickwolfe&password=12345" http://www.yahoo.com/login.cgi
-d选项用于指定发送请求时POST命令的数据

```sh
curl -X POST http://127.0.0.1:8000/person -d "first_name=hello&last_name=world" | python -m json.tool
```

python -m, -m将库中的python模块用作脚本去运行

将模块当做脚本去启动有什么用？
python xxx.py
python -m xxx.py
这是两种加载py文件的方式:
1叫做直接运行
2相当于import,叫做当做模块来启动

## git

### 删除Git中缓存的用户名和密码

运行一下命令缓存输入的用户名和密码：
git config --global credential.helper wincred
清除掉缓存在git中的用户名和密码
git credential-manager uninstall

### 恢复某个已修改的文件（撤销未提交的修改）
git checkout .(全部，或者指定文件来恢复部分)  //本地删除的记录恢复

### 基本命令

Git book：  
[Git 基础 ](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)

* git pull
    - 拉取远程分支更新到本地仓库
    - `git pull <远程主机名> <远程分支名>:<本地分支名>`，一般我们简写成 `git pull`
    - git pull = git fetch + git merge
    - git fetch不会进行合并，执行后需要手动执行git merge合并，而git pull拉取远程分之后直接与本地分支进行合并。
    - 强制覆盖本地：git pull --force
* git fetch
    - 更新远程代码到本地仓库
    - FETCH_HEAD指的是: 某个branch在服务器上的最新状态
        + 这个列表保存在 .Git/FETCH_HEAD 文件中, 其中每一行对应于远程服务器的一个分支。
        + 如果没有显式的指定远程分支, 则远程分支的master将作为默认的FETCH_HEAD
        + 如果指定了远程分支, 就将这个远程分支作为FETCH_HEAD
    - git fetch更新本地仓库的两种用法
        + 方法一
            * `git fetch origin master` #从远程的origin仓库的master分支下载代码到本地的origin master
            * `git log -p master.. origin/master` #比较本地的仓库和远程参考的区别
            * `git merge origin/master` #把远程下载下来的代码合并到本地仓库，远程的和本地的合并
        + 方法二
            * `git fetch origin master:temp` #从远程的origin仓库的master分支下载到本地并新建一个分支temp
            * `git diff temp`  #比较master分支和temp分支的不同
            * `git merge temp` #合并temp分支到master分支
            * `git branch -d temp` #删除temp
* git reset
    - git reset会将撤销点之后的操作都回退到暂存区中
    - git reset是直接删除指定的commit
* git revert
    - git revert 仅仅是撤销某次提交
    - git revert是用一次新的commit来回滚之前的commit

* 撤消操作
    - [2.4 Git 基础 - 撤消操作](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)


## spdlog

使用，两种方式：
1. 只有头文件的方式(代码中不需要加spdlog.cpp)
  拷贝include/spdlog 到代码路径，编译时，添加-std=c++11
  这种方式不需要-DSPDLOG_COMPILED_LIB
2. 使用静态库方式(推荐,把spdlog.cpp编进代码，编译更快)
  拷贝src/spdlog.cpp到代码路径，将cpp一起编译，需要加宏-DSPDLOG_COMPILED_LIB和-std=c++11

日志等级： (从上到下越来越严重，默认日志等级及其更高等级会进行打印，默认info)
  trace
  debug
  info
  warn
  error
  critical

### 基本用法及说明

[spdlog学习笔记](https://blog.csdn.net/haojie_superstar/article/details/89383433)

#### logger
  日志记录器，通过传入一个或者多个sink给它进行记录一个或多个位置
  可以通过spdlog自身的函数方法创建logger，也可以手动创建(先创建一个或者多个sink，再将sink传给spdlog::logger的构造函数进行创建)
    自身方法使用工厂模式创建实例，e.g. spdlog::daily_logger_mt
    sink的命名空间层次为 sdplog::sinks::具体sink类型，e.g. spdlog::sinks:stdout_sink_mt

#### sink

  sink是实际将日志写入目标位置的对象。
  每一个sink仅应负责写一个目标文件（比如 file，console，db）
  并且每一个sink有专属的私有格式化器formatter实例。 (可以手动创建sink，传递给logger，实现多个sink写入)

可用sink：

rotating_file_sink 达到最大文件大小时，关闭文件，重命名文件并创建新文件。
    `spdlog::rotating_logger_mt使用该sink`
daily_file_sink  每天在一个特别的时间创建一个新的日志文件，并在文件名字上添加一个时间戳
    `spdlog::daily_logger_mt`
simple_file_sink 无任何限制的向一个日志文件中写入
    `spdlog::basic_logger_mt`
stdout_sink/stderr_sink with colors
    `spdlog::stdout_color_mt`
    `spdlog::color_logger_mt`
syslog_sink POSIX syslog(3) 发送日志到syslog
    `spdlog::syslog_logger`
dist_sink 将日志消息分发到其他接收器列表 **使用这个sink实现多个sink记日志**
    没有工厂模式返回logger，需要手动添加

```cpp
    auto distsink = std::make_shared<spdlog::sinks::dist_sink_mt>();
    distsink->add_sink(std::make_shared<spdlog::sinks::stdout_sink_mt>());
    distsink->add_sink(std::make_shared<spdlog::sinks::rotating_file_sink_mt>(filepath, 1024*1024*1, 3));
    auto mydistlogger = std::make_shared<spdlog::logger>("mydistlogger", distsink);
    spdlog::register_logger(mydistlogger);
```

**注意**：用户应该负责去创建任何他们需要的文件夹。spdlog除了文件**不会尝试创建任何文件夹**

spdlog::info
spdlog::error

#### 线程安全说明

* spdlog:: 命名空间下的是线程安全的

* 对于sinks，以 _mt 后缀结尾的是线程安全的，比如：daily_file_sink_mt
             以_st 后缀结尾的是非线程安全的，比如：daily_file_sink_st

  单线程的sink不可以在多线程中使用，它的速度会更快，因为没有锁竞争

1.  不同线程处理时以下函数不应该操作：
当loggers在不同的线程同时执行时，下述函数不应该被调用
  spdlog::set_error_handler(log_err_handler) // or logger->set_error_handler(log_err_handler);
logger在其它线程执行过程中，添加或移除sink是线程不安全的
  logger->sinks().push_back(new_sink);       // Don't do this if other thread is already using this logger

2. 要创建线程安全的loggers，使用带 _mt 后缀的工厂函数
  auto logger = spdlog::basic_logger_mt(...);

3. 要创建单线程的loggers，使用带 _st 后缀的工厂函数
  auto logger = spdlog::basic_logger_st(...);

#### 使用
spdlog支持使用最小集的方式，意味着你只用包含你实际需要的头文件，而不是全部，比如说你只需要使用 rotating logger，那么你只需要
`#include <spdlog/sinks/rotating_file_sink.h>`

对于异步特性，你还需要
`#include <spdlog/asynch.h>`

* 几种使用模式：
  返回智能指针 std::shared_ptr<logger>
    每一个logger中包含一个存有一个或多个 std::shared_ptr<spdlog::sink>的 vector
    logger在记录每一条日志时（如果是有效的级别），将会调用每一个std::shared_ptr<spdlog::sink>中的sink(log_msg)函数

```cpp
* stdout打印
    auto console = spdlog::stdout_logger_mt("console");

* 基本文件记录，只有一个，不循环使用不限制大小
    #include "spdlog/sinks/basic_file_sink.h"
    // Create basic file logger (not rotated) // support for basic file logging
    auto my_logger = spdlog::basic_logger_mt("basic_logger", "logs/basic.txt");

* rotate句柄，限制大小和备份数量
    #include "spdlog/sinks/rotating_file_sink.h" // support for rotating file logging
    // file rotating logger with 5mb size max and 3 rotated files，5MB大小，3个循环备份文件(即共4个日志文件) rotate循环，旋转
    auto file_logger = spdlog::rotating_logger_mt("file_logger", "myfilename", 1024 * 1024 * 5, 3);

* 异步logger 使用工厂函数创建异步logger(循环记日志时，每次异步logger不阻塞)
    #include "spdlog/sinks/daily_file_sink.h"
    #include <spdlog/asynch.h>  //异步logger加头文件
    auto async_file = spdlog::basic_logger_mt<spdlog::async_factory>("async_file_logger", "logs/async_log.txt");
  可以通过创建异步logger前调用以下函数来修改线程池个数和待写日志队列长度
    inline void init_thread_pool(size_t q_size, size_t thread_count)

* 创建一个由多个loggers共享同一个输出文件的sink

* auto console = spdlog::stdout_color_mt("xdconsole");
    #include "spdlog/sinks/stdout_color_sinks.h"

  使用spdlog::get("...")访问loggers
    (spdlog::get("xdconsole"))->info("test spdlog::get function")
  spdlog::get可能会拖慢你的程序，因为它内部维护了一把锁，所以要谨慎使用。
    一个很好的方法是建立一个std::shared_ptr<spdlog::logger>私有成员变量，并在构造函数中初始化
```

* 手动创建loggers

参考(上面的sink章节，dist_sink可创建写多个sink的logger)

```cpp
  auto sink = std::make_shared<spdlog::sinks::stdout_sink_mt>();
  auto my_logger= std::make_shared<spdlog::logger>("mylogger", sink);
  my_logger->info("etstesfdljk");
```

* 设置函数

```cpp
  //设置一个logger, 后续使用spdlog::info时，会使用该logger记录
  spdlog::set_default_logger(file_logger);

  //设置模式字符串
  set_pattern(pattern_string);
    //格式应用到所有被注册的logger
    spdlog::set_pattern("*** [%H:%M:%S %z] [thread %t] %v ***");
    //格式应用到具体的logger
    some_logger->set_pattern(">>>>>>>>> %H:%M:%S %z %v <<<<<<<<<");
    //格式应用到具体的logger某个特定sink
    some_logger->sinks()[1]->set_pattern("..");
```

  [spdlog学习笔记_模式标记](https://blog.csdn.net/haojie_superstar/article/details/89383433)
    %H %M %S %z, 时(0-23) 分 秒 时区(“+02:00”)
    %I 时(1-12), %e 毫秒; %f 微秒

    %Y 年(“2014”), %m 月; %d 日(1-31)
    %C 年(“14”); %B 月份全名(August); %A 星期全名(Thursday)


用SPDLOG_INFO/SPDLOG_TRACE 等宏定义记录才有：不能指定logger
    %@ 文件名:行号(my_file.cpp:123)
    %s 文件名
    %# 行号
    %! 函数名

    %P 进程id; %t 线程id

    %+ spdlog的默认格式 “[2014-10-31 23:46:59.678] [mylogger] [info] Some message”
    %v 用户要记的信息

      即 [%Y-%m-%d %H:%M:%S.%e] [%n] [%l] %v

    %^ “[mylogger] [info(green)] Some message”
    %L 日志等级缩写(“D”, “I”, etc)
    %l 日志等级(“debug”, “info”)
    %n logger名

    %% %号

  对齐
    右对齐
      %8l  ("    info")
    -左对齐
      %-8l ("info    ")
    =中间对齐
      %=8l ("  info  ")

[%Y-%m-%d %H:%M:%S.%e] %^

## 编译

### pkg-config 编译时找库 和 ldconfig 运行时找库
编译grpc, third_party少包, git checkout .
  `git submodule update --init`
编译项目pkg-config找不到库
  export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
运行项目找不到动态库，系统中添加路径，或LD_LIBRARY_PATH
  vi /etc/ld.so.conf，添加一行 /usr/local/lib，然后执行ldconfig

编译时提示未定义的引用，如果-l链接了，且路径已经配置或者-L已经指定，还有可能是:
-l链接库在引用库的函数文件之前，这样就会链接不到库，所以要保证链接库的顺序在引用它之前

#### pkg-config
[pkg-config 详解](https://blog.csdn.net/newchenxf/article/details/51750239)

pkg-config是一个linux下的命令，用于获得某一个库/模块的所有编译相关的信息。

```sh
pkg-config --cflags --libs libmongocxx 执行结果为：

-I/usr/local/include/mongocxx/v_noabi -I/usr/local/include/bsoncxx/v_noabi  -L/usr/local/lib -lmongocxx -lbsoncxx
```

> 如果你写了一个库，不管是静态的还是动态的，要提供给第三方使用，那除了给人家库/头文件，最好也写一个pc文件，这样别人使用就方便很多，不用自己再手动写依赖了你哪些库，只需要敲一个”pkg-config [YOUR_LIB] --libs --cflags”。

pkg-config信息两个来源
  第一种：取系统的/usr/lib下的所有*.pc文件。
  第二种：PKG_CONFIG_PATH环境变量所指向的路径下的所有*.pc文件。

## makefile

**注意！ `PRJ_DIR="${shell cd ..;pwd}"       #注释说明`, 这样注释处理会将空格也赋值给PRJ_DIR**

[Makefile编译目录下多个文件以及函数wildcard用法](https://blog.csdn.net/hunanchenxingyu/article/details/12205305)
[makefile 中字符串处理和文件处理函数](https://blog.csdn.net/qhexin/article/details/16951097)

```sh
1. wildcard
  找出目录和指定目录下所有的后缀为c和cpp的文件
  $(wildcard *.c, *.cpp, /***/***/*.c)
    C_SRC = $(wildcard *.c)
    同C_SRC=$(shell echo *.c)

2. foreach
  组合foreach查找多个路径
    SRC_FILES += $(foreach dir,$(SRC_DIR),$(wildcard $(dir)/*.cpp))

3. patsubst 模式字符串替换函数
  $(patsubst <pattern>,<replacement>,<text>)
    <pattern>可以包括通配符“%”，表示任意长度的字串
    如果<replacement>中也包含“%”，那么，<replacement>中的这个“%”将是<pattern>中的那个“%
    以“\%”来表示真实含义的"%"
  e.g.
      将所有的cpp文件的后缀替换为o文件
      CPP_OBJ = $(patsubst %cpp, %o, $(CPP_SRC))
        同CPP_OBJ=$(CPP_SRC:%.cpp=%.o)

4. notdir
  dir=$(notdir $(src)) 把带路径的文件去掉路径，只留文件名

5. subst 字符串替换函数
  $(subst <from>,<to>,<text>)
  e.g.
    $(subst ee,EE,feet on the street)， 将"feet on the street"中的"ee"替换为"EE"，若要替换为空则,,

  其他字符串处理：
    去空格函数——strip
    e.g.
      $(strip a b c ) 把字串“a b c ”去到开头和结尾的空格，结果是“a b c”。

    过滤函数——filter
      sources := foo.c bar.c baz.s ugh.h
      $(filter %.c %.s,$(sources))返回的值是“foo.c bar.c baz.s”。
    反过滤函数——filter-out
      objects=main1.o foo.o main2.o bar.o
      mains=main1.o main2.o
      $(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”
    排序函数——sort
      $(sort foo bar lose)返回“bar foo lose”
    取单词函数——word
      取第n个，从1开始数
      $(word 2, foo bar baz)返回值是“bar”
    取单词串函数——wordlist
      第几到第几个
      $(wordlist 2, 3, foo bar baz)返回值是“bar baz”
    单词个数统计函数——words
      $(words, foo bar baz)返回值是“3”
    首单词函数——firstword
      $(firstword foo bar)返回值是“foo”
  文件名操作函数：
    取目录函数——dir
      目录部分是指最后一个反斜杠（“/”）之前的部分。如果没有反斜杠，那么返回“./”
      $(dir src/foo.c hacks)返回值是“src/ ./”
    取文件函数——notdir
      非目录部分是指最后一个反斜杠（“/”）之后的部分
      $(notdir src/foo.c hacks)返回值是“foo.c hacks”
    取后缀函数——suffix
      如果文件没有后缀，则返回空字串
      $(suffix src/foo.c src-1.0/bar.c hacks)返回值是“.c .c
    取前缀函数——basename
      如果文件没有前缀，则返回空字串
      $(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar hacks”
    加后缀函数——addsuffix
      $(addsuffix .c,foo bar)返回值是“foo.c bar.c”
    加前缀函数——addprefix
      $(addprefix src/,foo bar)返回值是“src/foo src/bar”
    连接函数——join
      $(join <list1>,<list2>)
      如果<list1>的单词个数要比<list2>的多，那么，<list1>中的多出来的单词将保持原样。如果<list2>的单词个数要比<list1>多，那么，<list2>多出来的单词将被复制到list1中末尾
      $(join aaa bbb , 111 222 333)返回值是“aaa111 bbb222 333”
```

通配符$@、$^、$<

这三个分别表示：
$@          --代表目标文件(target)
$^            --代表所有的依赖文件(components)
$<           --代表第一个依赖文件(components中最左边的那个)。

```sh
main.out:main.o line1.o line2.o
  g++ -o $@ $^
main.o:main.c line1.h line2.h
  g++ -c $<
line1.o:line1.c line1.h
  g++ -c $<
line2.o:line2.c line2.h
  g++ -c $<
```

## CMake

[在 linux 下使用 CMake 构建应用程序](https://www.ibm.com/developerworks/cn/linux/l-cn-cmake/)

1. 编写CMakeLists.txt
2. 执行cmake path生成Makefile(path时CMakeLists.txt所在目录)
3. 使用make进行编译

### CMakeLists.txt 的语法

由命令、注释和空格组成

其中命令是不区分大小写的,符号"#"后面的内容被认为是注释。

命令由命令名称、小括号和参数组成,参数之间使用空格进行间隔。 (注意VERSION大写)

```c
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
4 ADD_EXECUTABLE(main ${DIR_SRCS})
```
`aux_source_directory(<dir> <variable>)`
  命令会把参数 <dir> 中所有的源文件名称赋值给参数 <variable>

完成了文件 CMakeLists.txt 的编写后需要使用 cmake 或 ccmake 命令生成Makefile 。 ccmake 与命令 cmake 的不同之处在于 ccmake 提供了一个图形化的操作界面。

加子目录src，链接库Test，并将子目录编译成库(静态库.a)

```
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 ADD_SUBDIRECTORY( src )
4 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
5 ADD_EXECUTABLE(main ${DIR_SRCS}  )
6 TARGET_LINK_LIBRARIES( main Test )
```

子目录src中的CMakeLists.txt

```
1 AUX_SOURCE_DIRECTORY(. DIR_TEST1_SRCS)
2 ADD_LIBRARY ( Test ${DIR_TEST1_SRCS})
```

## linux

### history日志显示日期

.bashrc中设置环境变量:
export HISTTIMEFORMAT="%F %T `whoami` "

### 重定向标准错误

`mv a.log back/ 2>tmp.log  (或者2>>tmp.log)`

将执行的错误信息输出重定向到日志tmp.log中，**注意，2>之间不能有空格**

这种情况下，错误信息只会打印到tmp.log中，若要打印到文件的同时，终端上也能打印(标准输出1)，则可使用tee：

```sh
mv a.log back/ 2>&1 | tee -a tmp.log
```

### tee

[tee命令](https://www.cnblogs.com/leezhxing/p/4092532.html)

tee命令读取**标准输入**，把这些内容同时**输出到标准输出**和**（多个）文件**中，tee命令可以重定向标准输出到多个文件。

在使用管道线时，前一个命令的**标准错误**输出不会被tee读取。

```sh
tee
    只输出到标准输出
tee file
    输出到标准输出的同时，保存到文件file中
    如果文件不存在，则创建；如果已经存在，则覆盖之。
tee -a file
    输出到标准输出的同时，追加到文件file中。
    如果已经存在，就在末尾追加内容，而不是覆盖。
tee -
    输出到标准输出两次
tee file1 file2
    同时保存到file1和file2中

ls "*" 2>&1 | tee -a ls.txt
    使用tee命令把标准错误输出也保存到文件
```

### history记录时间
export HISTTIMEFORMAT="%F %T `whoami` "

### vim
替换指定行之间  :10,15s/abc/hhh/g

把204到233间的" = "替换为"("
`:204,233s/ = /(/g`

204到233间 ");"替换为"));"
`:204,233s/\)\;/));/g`

查找以\结尾：
/\\$  (\\为'\'转义)

### find

查找目录 时跳过指定目录，使用prune(英 /pruːn/   删除；减少)
  (注意顺序，-path接源路径，后面跟-prune，再跟-o，后面再跟其他过滤选项，-print不能少)：
  `find . -path './util' -prune -o -type d -print`

过滤多个目录：
  `find . \( -path './util' -o -path './tradebot \) -prune -o -type d -print`

  -o 类似于 or,  或者;
  -a 类似于 and, 且

  (1) grep指定h文件类型查找hello字符串：
find . -type f -name '*.h' | xargs grep "hello"

查看端口 lsof -i:5000

* 排除目录下所有以md结尾的文件：
`find . -type f ! -name "*.md"`

* 排除多个：
`find . -type f ! -name "*.md" ! -name "*.o"`

* 正则表达式：
`find . -regex '.*\.md\|.*\.h\|.*\.cpp'`

### 统计文本行数

语法：wc [选项] 文件…

说明：该命令统计给定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。

    该命令各选项含义如下：

    　　- c 统计字节数
    　　- l 统计行数
    　　- w 统计字数

* `wc -lcw Makefile`

* 统计src目录下所有cpp文件代码行数(子目录也会统计)

`find src/ -name "*.cpp" |xargs cat|wc -l`

* 统计当前目录及子目录下文件行数
`find . -type f |xargs cat|wc -l`

* 统计当前目录及子目录下.h和.cpp文件行数
`find . -type f -name "*.h" -o -name "*.cpp" |xargs cat|wc -l`
`find . -type f -name "*.h" |xargs cat|wc -l`

* 统计src目录下所有cpp文件代码行数(过滤空行)

`find src/ -name "*.cpp" |xargs cat | grep -v ^$ | wc -l`

### unzip

unzip zip文件

### 目录排序

du -s -d1|sort -n      (h会影响排序，仅按数字来排的)

### grep 查找后去重

grep "#include <boost" -rn *|awk -F' ' '{print $2}'|sort|uniq  (注意要sort，要不仅去重相邻的)

### echo 不换行

* echo -e 允许对下面列出的加反斜线转义的字符进行解释

```sh
  \n    换行符
  \c    禁止尾随的换行符
  \t    水平制表符
  等等

  echo -e "hello\n"  在原来基础上多加一个换行
  echo -e "hello\c"  不换行
```

* `echo -n "hello"` 也可指定不换行(-n 不输出行尾的换行符)

### 正则表达式

非：  volume:[^0] 匹配"volume:"后接非0的行

### chkconfig

chkconfig命令主要用来更新（启动或停止）和查询系统服务的运行级信息。
谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。

```sh
查看开机自启动的服务
chkconfig --list

只查看MySQL服务
chkconfig --list mysqld

配置MySQL的开机自动启动
chkconfig --add mysql
chkconfig mysqld on

命令启动/关闭MySQL实例
service mysqld start/stop
/etc/init.d/mysqld start/stop
```

### systemctl

1. 查看系统当前默认启动项目的方法，不再是setup之类的了。
`systemctl list-unit-files`

2. 取消mysqld的自启动
`systemctl disable mysqld`

查看状态，先status
`systemctl status mysqld.service`

### cpu信息

cpu信息在 /proc/cpuinfo中，根据grep过滤关键字，并配合uniq/sort/wc来过滤重复/排序/计数，统计各信息

* 查看物理CPU的个数(实际物理cpu的个数)

`cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l`

* 查看CPU是几核心(物理核数，每个cpu的物理核数，若有多个物理cpu，核心数都一样就一条记录)

`cat /proc/cpuinfo |grep "cores"|uniq`

* 查看逻辑CPU的个数(若该cpu支持超线程，则1个物理核对应2个逻辑核/线程。 若支持超线程则与物理核是两倍的关系)

`cat /proc/cpuinfo |grep "processor"|wc -l`

超线程计数可以理解为：一颗CPU当成两颗来用，将一颗具有超线程功能的物理CPU变成两颗逻辑CPU，而逻辑CPU对操作系统来说，跟物理CPU并没有什么区别。

超线程介绍：[图说超线程技术(Hyper-Threading Technology)](https://www.cnblogs.com/idorax/p/6884088.html)

获取开发环境配置：

```sh
echo -n "cpu个数: "
cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l
echo -n "cpu核数: "
cat /proc/cpuinfo |grep "cores"|uniq
echo -n "逻辑核数: "
cat /proc/cpuinfo |grep "processor"|wc -l

echo -n "操作系统: "
cat /etc/redhat-release
echo -n "gcc版本: "
gcc -v
```

## valgrind

valgrind ./simulate_server --leak-check=full --show-leak-kinds=definite

## mysql
安装Mysql 8.0
[CentOS 7 安装 Mysql 8.0 教程](https://blog.csdn.net/danykk/article/details/80137223)
1）配置Mysql 8.0安装源
sudo rpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm
2）安装Mysql 8.0
sudo yum --enablerepo=mysql80-community install mysql-community-server

## centos7 mongodb c++驱动安装

翻译：
[mongodb c++ 驱动](https://www.jianshu.com/p/c982a2960175)
  1. 安装c驱动
  2. 下载最新的 mongocxx driver
     git clone https://github.com/mongodb/mongo-cxx-driver.git --branch releases/stable --depth 1
     cd mongo-cxx-driver/build
  3. 配置驱动
     cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local ..
  4. 编译和安装驱动
     若用默认的 MNMLSTC 的C++17 `make EP_mnmlstc_core` (实际安装未执行该步，不确定是否有影响，make正常安装成功)
     make && make install

[mongodb c 驱动](https://www.jianshu.com/p/d77680254418) (第一步安装c驱动，翻译链接)

```sh
  $ wget https://github.com/mongodb/mongo-c-driver/releases/download/1.13.0/mongo-c-driver-1.13.0.tar.gz
  $ tar xzf mongo-c-driver-1.13.0.tar.gz
  $ cd mongo-c-driver-1.13.0
  $ mkdir cmake-build
  $ cd cmake-build
  $ cmake -DENABLE_AUTOMATIC_INIT_AND_CLEANUP=OFF ..

  $ make
  $ make install
```

官网：
[Installing the mongocxx driver](http://mongocxx.org/mongocxx-v3/installation/)

**注意下载安装包最好到官网,博客中下载链接可能是很老的包**

## mongodb安装
[Linux平台安装MongoDB](https://www.runoob.com/mongodb/mongodb-linux-install.html)
curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.12.tgz   # 下载 (对应版本修改下)
tar -zxvf mongodb-linux-x86_64-3.0.6.tgz                                   # 解压
mv  mongodb-linux-x86_64-3.0.6/ /usr/local/mongodb                         # 将解压包拷贝到指定目录

MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中：

export PATH=<mongodb-install-directory>/bin:$PATH
<mongodb-install-directory> 为你 MongoDB 的安装路径。如本文的 /usr/local/mongodb 。

  创建数据库目录
MongoDB的数据存储在data目录的db目录下，但是这个目录在安装过程不会自动创建，所以你需要手动创建data目录，并在data目录中创建db目录。
`mkdir -p /data/db`

  命令行中运行 MongoDB 服务
`$ ./mongod`

MongoDB后台管理 Shell
如果你需要进入MongoDB后台管理，你需要先打开mongodb装目录的下的bin目录，然后执行mongo命令文件。

MongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。

当你进入mongoDB后台后，它默认会链接到 test 文档（数据库）：

```sh
$ cd /usr/local/mongodb/bin
$ ./mongo
MongoDB shell version: 3.0.6
connecting to: test
Welcome to the MongoDB shell.
……
```

## 灰度发布

参考百度百科：
[灰度发布](https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83)

* 灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。
    - 在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。
    - 灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。

* 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。

* 作用： 及早获得用户的意见反馈，完善产品功能，提升产品质量 让用户参与产品测试，加强与用户互动 降低产品升级所影响的用户范围

本质上灰度测试可以算作A/B测试的一种特例

> 灰度发布与互联网公司常用A/B测试似乎比较类似，国外互联网公司似乎并没有所谓的灰度发布的概念。
> 按照wikipedia中对A/B测试的定义，A/B测试又叫：A/B/N Testing、Multivariate Testing，因此本质上灰度测试可以算作A/B测试的一种特例。

* 步骤：
    - 1）定义目标
    - 2）选定策略：包括用户规模、发布频率、功能覆盖度、回滚策略、运营策略、新旧系统部署策略等
    - 3）筛选用户：包括用户特征、用户数量、用户常用功能、用户范围等
    - 4）部署系统：部署新系统、部署用户行为分析系统（web analytics）、设定分流规则、运营数据分析、分流规则微调
    - 5）发布总结：用户行为分析报告、用户问卷调查、社会化媒体意见收集、形成产品功能改进列表
    - 6）产品完善
    - 7）新一轮灰度发布或完整发布

## QT

[Qt Downloads](http://download.qt.io/archive/qt/) 环境搭建(官网的下载链接点击进去找不到界面)

## UML类图

[UML类图与类的关系详解](http://uml.org.cn/oobject/201104212.asp)

[UML——在Visual Studio 2013/2015中设计UML类图](https://www.cnblogs.com/SceneryHao/p/5355915.html)

Unified Modeling Language (UML)又称统一建模语言或标准建模语言。

简单说就是以图形方式表现模型，根据不同模型进行分类

常用 UML 动态图（5 个）：用例图，活动图，状态机图，序列图，通信图。
常用 UML 静态图（4 个）：类图，包图，部署图，构件图。

在所有UML图中，类图是使用频率最高的UML图。
类图用于描述系统中所包含的类以及它们之间的相互关系，帮助人们简化对系统的理解，它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。

类图主要关系有：泛化（Generalization）,  实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)

* 泛化（Generalization)
    - 【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。
    - 【代码体现】：类继承另一个类
    - 【箭头指向】：带三角箭头的实线，箭头指向父类