[TOC]


## Tips

* 开发过程过程中注意空格影响！
    - makefile字符串赋值给变量时末尾空格(编辑器尽量开启空格和tab显示)
* `==` 和 位运算运算符(`&`/`^`/`|`)的优先级
    - 注意 `==` 的优先级比 位运算运算符 高，需要加括号(否则和预期效果不一致)
        + 位运算比逻辑运算符优先级高(==当然更高)，`(1 & 0x01) == 0x01 && (2 & 0x02) == 0x02`

```cpp
if ((iMode & 0x01) == 0x01)
{
    xxx
}
if ((iMode & 0x02) == 0x02)
{
    xxx
}
```


## REST

REST API: 即Representational State Transfer(表述性状态转移)的缩写
其优点如下：

* 在RESTful架构中，每一个URL代表一种资源；
* 客户端和服务器之间，传递这种资源的某种表现层；
* 客户端通过四个HTTP指令，对服务器端资源进行操作，实现“表现层状态转化”。 建议开发者使用REST API进行币币交易或者资产提现等操作。

## WebSocket API

WebSocket API: WebSocket是HTML5一种新的协议(Protocol)。

>它实现了客户端与服务器全双工通信，使得数据可以快速地双向传播。

通过一次简单的握手就可以建立客户端和服务器连接，服务器根据业务规则可以主动推送信息给客户端。

其优点如下：

* 客户端和服务器进行数据传输时，请求头信息比较小，大概2个字节;
* 客户端和服务器皆可以主动地发送数据给对方；
* 不需要多次创建TCP请求和销毁，节约宽带和服务器的资源。 强烈建议开发者使用WebSocket API获取**市场行情**和**买卖深度**等信息。

## TCP

TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

[gRPC服务发现&负载均衡](https://segmentfault.com/a/1190000008672912)

## windows 命令

* tasklist 查看进程
    - tasklist|findstr "9108"

* win10开机内存使用就80%：关闭快速启动
  - [windows 10如何关闭快速启动](https://jingyan.baidu.com/article/ca00d56c7a40e6e99febcf4f.html)
  - win+x -> 电源选项 -> 其他电源设置 -> 选择电源按钮的功能

* `net` (Windows下的net命令)
    - 用于Windows管理网络环境、服务、用户、登陆等信息内容
    - `net user`
        + 添加或更改用户帐号或显示(不带参数则会显示)用户帐号信息
    - `net start`
        + 启动服务(接服务名)，或显示已启动服务的列表(不带参数)
    - `net stop service名`
        + 停止服务，e.g. `net stop mysql`
    - `net pause service名`
        + 暂停正在运行的服务
    - `net continue service名`
        + 重新激活挂起的服务
    - `net statistics`
        + 显示本地工作站或服务器服务的统计记录。
        + 键入不带参数的net statistics列出其统计信息可用的运行服务
    - [windows net 命令详解](https://blog.csdn.net/holandstone/article/details/37544529)

## curl

* [curl 的用法指南](https://www.ruanyifeng.com/blog/2019/09/curl-reference.html)
    - `curl` 是常用的命令行工具，用来请求 Web 服务器。它的名字就是客户端（client）的 URL 工具的意思
    - 不带有任何参数时，curl 就是发出 `GET` 请求
        + e.g. `curl https://www.example.com`
    - `-A` 指定客户端的用户代理标头，即`User-Agent`
        + curl 的默认用户代理字符串是`curl/[version]`
        + e.g. `curl -A 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36' https://google.com` 将User-Agent改成 Chrome 浏览器
        + e.g. `curl -A '' https://google.com` 移除User-Agent标头
        + 也可以通过`-H`参数直接指定标头，更改User-Agent：`curl -H 'User-Agent: php/1.0' https://google.com`
    - `-b` 用来向服务器发送 Cookie
        + `curl -b 'foo=bar' https://google.com`，会生成一个标头`Cookie: foo=bar`，向服务器发送一个名为foo、值为bar的 Cookie
    - `-d` 用于发送 `POST` 请求的数据体
        + e.g. `curl -d'login=emma＆password=123'-X POST https://google.com/login`
            * `&`方式也可以改成`-d 'login=emma' -d 'password=123'`
        + 使用`-d`参数以后，HTTP 请求会自动加上标头`Content-Type : application/x-www-form-urlencoded`
        + 并且会自动将请求转为 `POST` 方法，因此可以省略`-X POST`
        + 还可以读取本地文本文件中的数据：`curl -d '@data.txt' https://google.com/login`
    - `--data-urlencode`，等同于`-d`，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码
    - `-e` 用来设置 HTTP 的标头`Referer`，表示请求的来源
        + `curl -e 'https://google.com?q=example' https://www.example.com`
        + `-H`参数可以通过直接添加标头Referer，达到同样效果：`curl -H 'Referer: https://google.com?q=example' https://www.example.com`
    - `-o` 将服务器的回应保存成文件，等同于`wget`命令
        + e.g. `curl -o example.html https://www.example.com`
        + e.g. `curl -o ./test.jpg http://mirrors.aliyun.com/repo/testjpg`
    - `-O` 将服务器回应保存成文件，并将 URL 的最后部分当作文件名
        + `curl -O https://www.example.com/foo/bar.html`，保存文件名为bar.html
    - `-x` 指定 HTTP 请求的代理
        + `curl -x socks5://james:cats@myproxy.com:8080 https://www.example.com`，指定 HTTP 请求通过`myproxy.com:8080`的 socks5 代理发出。如果没有指定代理协议，默认为 `HTTP`
    - `-X` 指定 HTTP 请求的方法
        + `curl -X POST https://www.example.com`

## git

### 删除Git中缓存的用户名和密码

运行一下命令缓存输入的用户名和密码：
git config --global credential.helper wincred
清除掉缓存在git中的用户名和密码
git credential-manager uninstall

* git终端或者tortoisegit记住密码问题
    - 网络的配置都是向配置中添加credential.helper
        + `git config --global credential.helper store`
    - 这种方式只针对"http://"方式clone的项目代码，对于"ssh://"则不适用
* git协议
    - Git 可以使用四种不同的协议来传输资料：本地协议（Local），HTTP 协议，SSH（Secure Shell）协议及 Git 协议。
        + 不同的协议其URL地址和对应的授权实现不同
        + 对于GitHub可以用SSH生成公钥，将其添加到GitHub的受信任列表来实现免密码登录

### 恢复某个已修改的文件（撤销未提交的修改）
git checkout .(全部，或者指定文件来恢复部分)  //本地删除的记录恢复

### 基本命令

Git book：  
[Git 基础 ](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)

* git pull
    - 拉取远程分支更新到本地仓库
    - `git pull <远程主机名> <远程分支名>:<本地分支名>`，一般我们简写成 `git pull`
    - git pull = git fetch + git merge
    - git fetch不会进行合并，执行后需要手动执行git merge合并，而git pull拉取远程分之后直接与本地分支进行合并。
    - 强制覆盖本地：git pull --force
* git fetch
    - 更新远程代码到本地仓库
    - FETCH_HEAD指的是: 某个branch在服务器上的最新状态
        + 这个列表保存在 .Git/FETCH_HEAD 文件中, 其中每一行对应于远程服务器的一个分支。
        + 如果没有显式的指定远程分支, 则远程分支的master将作为默认的FETCH_HEAD
        + 如果指定了远程分支, 就将这个远程分支作为FETCH_HEAD
    - git fetch更新本地仓库的两种用法
        + 方法一
            * `git fetch origin master` #从远程的origin仓库的master分支下载代码到本地的origin master
            * `git log -p master.. origin/master` #比较本地的仓库和远程参考的区别
            * `git merge origin/master` #把远程下载下来的代码合并到本地仓库，远程的和本地的合并
        + 方法二
            * `git fetch origin master:temp` #从远程的origin仓库的master分支下载到本地并新建一个分支temp
            * `git diff temp`  #比较master分支和temp分支的不同
            * `git merge temp` #合并temp分支到master分支
            * `git branch -d temp` #删除temp
* git reset
    - git reset会将撤销点之后的操作都回退到暂存区中
    - git reset是直接删除指定的commit
    - `git reset --hard 7cffc2b1f25f92e03567f64c7cc3216a5ffd953e` 回退当前工作树，从指定版本之后的跟踪文件修改都被丢弃
* git revert
    - git revert 仅仅是撤销某次提交
    - git revert是用一次新的commit来回滚之前的commit

* 撤消操作
    - [2.4 Git 基础 - 撤消操作](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)
* 重命名
    - 直接文件夹改名并不会记录到git记录里，而是当作删除了原目录，新增了新名称的目录
    - [git mv](https://git-scm.com/docs/git-mv)
    - 使用：`git mv -f oldfolder newfolder`
        - `-f`可选，目标存在也强制命名或移动
        - `-k` 跳过会出错的操作
        - `-n` 不做mv，而只是打印会执行的动作

### git终端显示中文名为数字编码设置

在cygwin中，使用git add添加要提交的文件的时候，如果文件名是中文，会显示形如 274\232\350\256\256\346\200\273\347\273\223.png 的乱码。

解决方案：
在bash提示符下输入：
`git config --global core.quotepath false`
core.quotepath设为false的话，就不会对0x80以上的字符进行quote。中文显示正常。

### git 默认不区分文件名大小写

readme.md 改名为 Readme.md，git status并不会显示任何信息

* 配置git 使其对文件名大小写敏感
    - git config core.ignorecase false

### git签出和提交时，换行问题

* 问题
    - Windows下，git checkout代码时，原始的shell脚本文件中的换行(LF)，自动变成了回车换行(CRLF)，导致再把文件ftp传到Linux上时，执行报错，提示`$'\r': 未找到命令`
    - 关于Linux下(LF)和Windows下(CRLF)的换行问题，之前笔记记录过
        + 回车(CR: Carriage Return): 将当前光标移动到同一行中的最左边（假设是从左到右的输入方式）
        + 换行(LF: Line Feed): 保持当前光标的水平位置位置不变，换到下一行
        + [回车及换行的区别及介绍](http://xiaodongq.github.io/2016/07/08/%E5%9B%9E%E8%BD%A6%E5%92%8C%E6%8D%A2%E8%A1%8C%E7%9A%84%E5%8C%BA%E5%88%AB%E5%8F%8A%E4%BB%8B%E7%BB%8D/)
    - Windows下查看已配置项，`git config -l`
        + 可以看到`core.autocrlf=true`
    - [Git配置中autocrlf来处理crlf](https://www.jianshu.com/p/0a747b2b76a2)
        + Git可以在提交时自动地把行结束符CRLF转换成LF，而在签出代码时把LF转换成CRLF。
        + 用core.autocrlf来打开此项功能(安装git时可选，默认项是打开的) `git config --global core.autocrlf true `
* 签出时不自动转换为CRLF(自己的shell脚本都跑在Linux上，因此我选下面的配置)
    - `git config --global core.autocrlf input`

## spdlog

### 基本用法及说明

* [官网文档](https://github.com/gabime/spdlog/wiki/1.-QuickStart)
* [spdlog学习笔记](https://blog.csdn.net/haojie_superstar/article/details/89383433)

* 使用，两种方式：
    - 1. 只有头文件的方式(代码中不需要加spdlog.cpp)
        + 拷贝include/spdlog 到代码路径，编译时，添加`-std=c++11`
        + 这种方式不需要`-DSPDLOG_COMPILED_LIB`
    - 2. 使用静态库方式(推荐,把spdlog.cpp编进代码，编译更快)
        + 拷贝src/spdlog.cpp到代码路径，将cpp一起编译，需要加宏`-DSPDLOG_COMPILED_LIB`和`-std=c++11`
* 日志等级： (从上到下越来越严重，默认日志等级及其更高等级会进行打印，默认info)
  - trace
  - debug
  - info
  - warn
  - error
  - critical

#### logger

* 日志记录器`logger`，通过传入一个或者多个`sink`给它进行记录一个或多个位置
* 可以通过spdlog自身的函数方法创建`logger`，也可以手动创建(先创建一个或者多个`sink`，再将`sink`传给`spdlog::logger`的构造函数进行创建)
    - 自身方法使用工厂模式创建实例，e.g. `spdlog::daily_logger_mt`
    - `sink`的命名空间层次为 `sdplog::sinks::具体sink类型`，e.g. spdlog::sinks:stdout_sink_mt

#### sink

* `sink`是实际将日志写入目标位置的对象。
    - 每一个`sink`仅应负责写一个目标文件（比如 file，console，db）
    - 并且每一个sink有专属的私有格式化器formatter实例。 (可以手动创建sink，传递给logger，实现多个sink写入)
* 可用的sink：(对于sinks，以 `_mt` 后缀结尾的是线程安全的，比如：`daily_file_sink_mt`)
    - `rotating_file_sink` 达到最大文件大小时，关闭文件，重命名文件并创建新文件。
        + `spdlog::rotating_logger_mt`工厂使用该sink
    - `daily_file_sink`  每天在一个特别的时间创建一个新的日志文件，并在文件名字上添加一个时间戳
        + `spdlog::daily_logger_mt`工厂使用该sink
    - `simple_file_sink` 无任何限制的向一个日志文件中写入
        + `spdlog::basic_logger_mt`工厂使用该sink
    - `stdout_sink`/`stderr_sink` with colors
        + `spdlog::stdout_color_mt`工厂使用该sink
        + `spdlog::color_logger_mt`工厂使用该sink
    - `syslog_sink` POSIX syslog(3) 发送日志到syslog
        + `spdlog::syslog_logger`工厂
    - `dist_sink` 将日志消息分发到其他接收器列表 **使用这个sink实现多个sink记日志**
        + 没有工厂模式返回logger，需要手动添加，示例如下：

```cpp
    auto distsink = std::make_shared<spdlog::sinks::dist_sink_mt>();
    distsink->add_sink(std::make_shared<spdlog::sinks::stdout_sink_mt>());
    distsink->add_sink(std::make_shared<spdlog::sinks::rotating_file_sink_mt>(filepath, 1024*1024*1, 3));
    auto mydistlogger = std::make_shared<spdlog::logger>("mydistlogger", distsink);
    spdlog::register_logger(mydistlogger);
```

* **注意**：用户应该负责去创建任何他们需要的文件夹。spdlog除了文件**不会尝试创建任何文件夹**

#### 线程安全说明

* spdlog:: 命名空间下的是线程安全的

* 对于sinks
    - 以 `_mt` 后缀结尾的是线程安全的，比如：`daily_file_sink_mt`
    - 以 `_st` 后缀结尾的是非线程安全的，比如：`daily_file_sink_st`

* 单线程的sink不可以在多线程中使用，它的速度会更快，因为没有锁竞争

1. 不同线程处理时以下函数不应该操作：
    - 当loggers在不同的线程同时执行时，下述函数不应该被调用
        + `spdlog::set_error_handler(log_err_handler)` 或者 `logger->set_error_handler(log_err_handler);`
    - logger在其它线程执行过程中，添加或移除sink是线程不安全的
        + `logger->sinks().push_back(new_sink);`  // Don't do this if other thread is already using this logger
2. 要创建线程安全的loggers，使用带 `_mt` 后缀的工厂函数
    - `auto logger = spdlog::basic_logger_mt(...);`
3. 要创建单线程的loggers，使用带 _st 后缀的工厂函数
  `auto logger = spdlog::basic_logger_st(...);`

#### 使用

* spdlog支持使用最小集的方式，意味着你只用包含你实际需要的头文件，而不是全部
    - 比如说只需要使用 rotating logger，那么你只需要 `#include <spdlog/sinks/rotating_file_sink.h>`
    - 对于异步特性，你还需要 `#include <spdlog/asynch.h>`

* 几种使用模式：
    - 返回智能指针 std::shared_ptr<logger>
        + 每一个logger中包含一个存有一个或多个 `std::shared_ptr<spdlog::sink>`的 vector
        + logger在记录每一条日志时（如果是有效的级别），将会调用每一个std::shared_ptr<spdlog::sink>中的sink(log_msg)函数

```cpp
* stdout打印
    auto console = spdlog::stdout_logger_mt("console");

* 基本文件记录，只有一个，不循环使用不限制大小
    #include "spdlog/sinks/basic_file_sink.h"
    // Create basic file logger (not rotated) // support for basic file logging
    auto my_logger = spdlog::basic_logger_mt("basic_logger", "logs/basic.txt");

* rotate句柄，限制大小和备份数量
    #include "spdlog/sinks/rotating_file_sink.h" // support for rotating file logging
    // file rotating logger with 5mb size max and 3 rotated files，5MB大小，3个循环备份文件(即共4个日志文件) rotate循环，旋转
    auto file_logger = spdlog::rotating_logger_mt("file_logger", "myfilename", 1024 * 1024 * 5, 3);

* 异步logger 使用工厂函数创建异步logger(循环记日志时，每次异步logger不阻塞)
    #include "spdlog/sinks/daily_file_sink.h"
    #include <spdlog/asynch.h>  //异步logger加头文件
    auto async_file = spdlog::basic_logger_mt<spdlog::async_factory>("async_file_logger", "logs/async_log.txt");
  可以通过创建异步logger前调用以下函数来修改线程池个数和待写日志队列长度
    inline void init_thread_pool(size_t q_size, size_t thread_count)

* 创建一个由多个loggers共享同一个输出文件的sink

* auto console = spdlog::stdout_color_mt("xdconsole");
    #include "spdlog/sinks/stdout_color_sinks.h"

  使用spdlog::get("...")访问loggers
    (spdlog::get("xdconsole"))->info("test spdlog::get function")
  spdlog::get可能会拖慢你的程序，因为它内部维护了一把锁，所以要谨慎使用。
    一个很好的方法是建立一个std::shared_ptr<spdlog::logger>私有成员变量，并在构造函数中初始化
```

* 手动创建loggers

参考(上面的sink章节，dist_sink可创建写多个sink的logger)

```cpp
  auto sink = std::make_shared<spdlog::sinks::stdout_sink_mt>();
  auto my_logger= std::make_shared<spdlog::logger>("mylogger", sink);
  my_logger->info("etstesfdljk");
```

* 指定打印的float/double精度和形式
    - GitHub示例：[Usage samples](https://github.com/gabime/spdlog#usage-samples)
    - `spdlog::info("Support for floats {:03.2f}", 1.23456);`
        + `:.2f`表示打印小数点2位
    - `spdlog::info("Positional args are {1} {0}..", "too", "supported");`
        + `{1}` 表示参数1，即"supported"，`{0}`打印"too"

* 模式设置函数

```cpp
  //设置一个logger, 后续使用spdlog::info时，会使用该logger记录
  spdlog::set_default_logger(file_logger);

  //设置模式字符串
  set_pattern(pattern_string);
    //格式应用到所有被注册的logger
    spdlog::set_pattern("*** [%H:%M:%S %z] [thread %t] %v ***");
    //格式应用到具体的logger
    some_logger->set_pattern(">>>>>>>>> %H:%M:%S %z %v <<<<<<<<<");
    // some_logger->set_pattern("[%Y-%m-%d %H:%M:%S.%e] [%^%l%$] %v");

    //格式应用到具体的logger某个特定sink
    some_logger->sinks()[1]->set_pattern("..");
```

* 各种符号代表的模式参考：[spdlog学习笔记_模式标记](https://blog.csdn.net/haojie_superstar/article/details/89383433)
    - 建议使用的模式：`some_logger->set_pattern("[%Y-%m-%d %H:%M:%S.%e] [%^%l%$] %v");`
    - 日志内容形式为: [2000-01-25 15:32:25.523] [info] [xdtest.cpp:testfunc().50]

```
    %H %M %S %z, 时(0-23) 分 秒 时区(“+02:00”)
    %I 时(1-12), %e 毫秒; %f 微秒

    %Y 年(“2014”), %m 月; %d 日(1-31)
    %C 年(“14”); %B 月份全名(August); %A 星期全名(Thursday)
```

```
    %P 进程id; %t 线程id

    %+ spdlog的默认格式 “[2014-10-31 23:46:59.678] [mylogger] [info] Some message”
    %v 用户要记的信息

      即 [%Y-%m-%d %H:%M:%S.%e] [%n] [%l] %v

    打印颜色(%^和%$之间的模式会打印颜色)：
    %^ “[mylogger] [info(green)] Some message”
    %$

    %L 日志等级缩写(“D”, “I”, etc)
    %l 日志等级(“debug”, “info”)
    %n logger名

    %% %号

  对齐
    右对齐
      %8l  ("    info")
    -左对齐
      %-8l ("info    ")
    =中间对齐
      %=8l ("  info  ")
```

* 用`SPDLOG_INFO`/`SPDLOG_TRACE` 等宏定义记录才支持下面几个信息打印
    - (不过在logger中设置这些模式并未生效，用下面的自定义宏`COMMON_SPDLOG_ERROR`)

```
    %@ 文件名:行号(my_file.cpp:123)
    %s 文件名
    %# 行号
    %! 函数名
```

* 要打印一些文件名、行数等信息，可自定义宏：
    - 形式如：`[2000-01-25 15:32:25.523] [info] [xdtest.cpp:testfunc().50]`

```cpp
// 通用日志格式调整，添加文件名，函数名，行号，传入实际记录的logger
#define filename(x) (strrchr(x,'/')?strrchr(x,'/')+1:x)
#define COMMON_SPDLOG_ERROR(log, fmt, ...) do {log.error("[{}:{}().{}] " fmt, filename(__FILE__) , __FUNCTION__, __LINE__, ##__VA_ARGS__);}while(0)

#define LOGGER_ERROR(fmt, ...) COMMON_SPDLOG_ERROR(logger, fmt, ##__VA_ARGS__)
```

## 编译

* 编译相关的环境变量
    - `C_INCLUDE_PATH`     gcc找到头文件的路径
    - `CPLUS_INCLUDE_PATH` g++找到头文件的路径
    - `LD_LIBRARY_PATH` 找到动态链接库的路径
    - `LIBRARY_PATH` 找到静态库的路径
* `cpp -v` 命令查看系统默认搜索的include路径
    - `cpp`(/usr/bin/cpp) 命令完成 C 语言源文件上的文件包含和宏置换
    - 查看得到include查找路径(本CentOS环境)
        + /usr/include
        + /usr/local/include
        + /usr/lib/gcc/x86_64-redhat-linux/4.8.5/include
        + 注意：usr并不是user用户的缩写，而是unix system resource 的缩写。

### pkg-config 编译时找库 和 ldconfig 运行时找库

* 编译项目pkg-config找不到库
    - `export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH`
* 运行项目找不到动态库，系统中添加路径，或`LD_LIBRARY_PATH`
    - vi /etc/ld.so.conf，添加一行 /usr/local/lib，然后执行ldconfig

* 编译时提示未定义的引用，如果-l链接了，且路径已经配置或者-L已经指定，还有可能是:
    - -l链接库在引用库的函数文件之前，这样就会链接不到库，所以要保证链接库的顺序在引用它之前

#### pkg-config
[pkg-config 详解](https://blog.csdn.net/newchenxf/article/details/51750239)

pkg-config是一个linux下的命令，用于获得某一个库/模块的所有编译相关的信息。

```sh
pkg-config --cflags --libs libmongocxx 执行结果为：

-I/usr/local/include/mongocxx/v_noabi -I/usr/local/include/bsoncxx/v_noabi  -L/usr/local/lib -lmongocxx -lbsoncxx
```

> 如果你写了一个库，不管是静态的还是动态的，要提供给第三方使用，那除了给人家库/头文件，最好也写一个pc文件，这样别人使用就方便很多，不用自己再手动写依赖了你哪些库，只需要敲一个”pkg-config [YOUR_LIB] --libs --cflags”。

pkg-config信息两个来源
  第一种：取系统的/usr/lib下的所有*.pc文件。
  第二种：PKG_CONFIG_PATH环境变量所指向的路径下的所有*.pc文件。

## makefile

**注意！ `PRJ_DIR="${shell cd ..;pwd}"       #注释说明`, 这样注释处理会将空格也赋值给PRJ_DIR**

[Makefile编译目录下多个文件以及函数wildcard用法](https://blog.csdn.net/hunanchenxingyu/article/details/12205305)
[makefile 中字符串处理和文件处理函数](https://blog.csdn.net/qhexin/article/details/16951097)

```sh
1. wildcard
  找出目录和指定目录下所有的后缀为c和cpp的文件
  $(wildcard *.c, *.cpp, /***/***/*.c)
    C_SRC = $(wildcard *.c)
    同C_SRC=$(shell echo *.c)

2. foreach
  组合foreach查找多个路径
    SRC_FILES += $(foreach dir,$(SRC_DIR),$(wildcard $(dir)/*.cpp))

3. patsubst 模式字符串替换函数
  $(patsubst <pattern>,<replacement>,<text>)
    <pattern>可以包括通配符“%”，表示任意长度的字串
    如果<replacement>中也包含“%”，那么，<replacement>中的这个“%”将是<pattern>中的那个“%
    以“\%”来表示真实含义的"%"
  e.g.
      将所有的cpp文件的后缀替换为o文件
      CPP_OBJ = $(patsubst %cpp, %o, $(CPP_SRC))
        同CPP_OBJ=$(CPP_SRC:%.cpp=%.o)

4. notdir
  dir=$(notdir $(src)) 把带路径的文件去掉路径，只留文件名

5. subst 字符串替换函数
  $(subst <from>,<to>,<text>)
  e.g.
    $(subst ee,EE,feet on the street)， 将"feet on the street"中的"ee"替换为"EE"，若要替换为空则,,

  其他字符串处理：
    去空格函数——strip
    e.g.
      $(strip a b c ) 把字串“a b c ”去到开头和结尾的空格，结果是“a b c”。

    过滤函数——filter
      sources := foo.c bar.c baz.s ugh.h
      $(filter %.c %.s,$(sources))返回的值是“foo.c bar.c baz.s”。
    反过滤函数——filter-out
      objects=main1.o foo.o main2.o bar.o
      mains=main1.o main2.o
      $(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”
    排序函数——sort
      $(sort foo bar lose)返回“bar foo lose”
    取单词函数——word
      取第n个，从1开始数
      $(word 2, foo bar baz)返回值是“bar”
    取单词串函数——wordlist
      第几到第几个
      $(wordlist 2, 3, foo bar baz)返回值是“bar baz”
    单词个数统计函数——words
      $(words, foo bar baz)返回值是“3”
    首单词函数——firstword
      $(firstword foo bar)返回值是“foo”
  文件名操作函数：
    取目录函数——dir
      目录部分是指最后一个反斜杠（“/”）之前的部分。如果没有反斜杠，那么返回“./”
      $(dir src/foo.c hacks)返回值是“src/ ./”
    取文件函数——notdir
      非目录部分是指最后一个反斜杠（“/”）之后的部分
      $(notdir src/foo.c hacks)返回值是“foo.c hacks”
    取后缀函数——suffix
      如果文件没有后缀，则返回空字串
      $(suffix src/foo.c src-1.0/bar.c hacks)返回值是“.c .c
    取前缀函数——basename
      如果文件没有前缀，则返回空字串
      $(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar hacks”
    加后缀函数——addsuffix
      $(addsuffix .c,foo bar)返回值是“foo.c bar.c”
    加前缀函数——addprefix
      $(addprefix src/,foo bar)返回值是“src/foo src/bar”
    连接函数——join
      $(join <list1>,<list2>)
      如果<list1>的单词个数要比<list2>的多，那么，<list1>中的多出来的单词将保持原样。如果<list2>的单词个数要比<list1>多，那么，<list2>多出来的单词将被复制到list1中末尾
      $(join aaa bbb , 111 222 333)返回值是“aaa111 bbb222 333”
```

通配符$@、$^、$<

这三个分别表示：
$@          --代表目标文件(target)
$^            --代表所有的依赖文件(components)
$<           --代表第一个依赖文件(components中最左边的那个)。

```sh
main.out:main.o line1.o line2.o
  g++ -o $@ $^
main.o:main.c line1.h line2.h
  g++ -c $<
line1.o:line1.c line1.h
  g++ -c $<
line2.o:line2.c line2.h
  g++ -c $<
```

### ifeq语法

```
ifeq ($(CC),gcc)
    $(CC) -o foo $(objects) $(libs_for_gcc)
else
    $(CC) -o foo $(objects) $(normal_libs)
endif
```

## CMake

* 安装cmake(此处安装cmake3.15)
    - [centos7编译安装cmake](https://blog.csdn.net/xingyu97/article/details/97108108)
    - `wget https://cmake.org/files/v3.15/cmake-3.15.0-Linux-x86_64.tar.gz`
        + 其他版本从官网获取(目前2020.3.26最新为3.17.0版本)：[Get the Software](https://cmake.org/download/)
    - `tar zxvf cmake-3.15.0-Linux-x86_64.tar.gz`

[在 linux 下使用 CMake 构建应用程序](https://www.ibm.com/developerworks/cn/linux/l-cn-cmake/)

1. 编写CMakeLists.txt
2. 执行cmake path生成Makefile(path时CMakeLists.txt所在目录)
3. 使用make进行编译

### CMakeLists.txt 的语法

由命令、注释和空格组成

其中命令是不区分大小写的,符号"#"后面的内容被认为是注释。

命令由命令名称、小括号和参数组成,参数之间使用空格进行间隔。 (注意VERSION大写)

```c
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
4 ADD_EXECUTABLE(main ${DIR_SRCS})
```
`aux_source_directory(<dir> <variable>)`
  命令会把参数 <dir> 中所有的源文件名称赋值给参数 <variable>

完成了文件 CMakeLists.txt 的编写后需要使用 cmake 或 ccmake 命令生成Makefile 。 ccmake 与命令 cmake 的不同之处在于 ccmake 提供了一个图形化的操作界面。

加子目录src，链接库Test，并将子目录编译成库(静态库.a)

```
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 ADD_SUBDIRECTORY( src )
4 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
5 ADD_EXECUTABLE(main ${DIR_SRCS}  )
6 TARGET_LINK_LIBRARIES( main Test )
```

子目录src中的CMakeLists.txt

```
1 AUX_SOURCE_DIRECTORY(. DIR_TEST1_SRCS)
2 ADD_LIBRARY ( Test ${DIR_TEST1_SRCS})
```

* 安装mingw (Minimalist GNU for Windows)，(当前自己用的是安装QT时一并安装的mingw730_64)
    - [mingw官网下载链接](http://mingw-w64.org/doku.php/download/mingw-builds)

* [通过 ccache 改善协同构建时间](https://www.ibm.com/developerworks/cn/linux/l-ccache.html)
    - 在标准的编译过程中，在 UNIX 下使用 C/C++ 开发应用程序通常需要用到一个编译器（如 `gcc`）以及一个编译 工具，比如 `make`。`make`和所有的 C 编译器的问题在于 C 预处理程序（preprocessor）和头文件的工作方式。
    - 每一次编译一个文件时，C 预处理程序（`cpp`）都会解析并引入每个头文件以及这些头文件引用到的任何文件。
        + 通过对内容进行解析，`ccp` 可以将一个相当基本的1-KB大小的源文件转化为一个8-KB大小的源文件，在这个过程中，会合并入几十个甚至几百个头文件。
        + 在典型的开发项目中，有很多与项目相关的头文件可能会在不同的源文件中多次被引入，而且每个头文件本身也可能引用很多其他头文件。
    - 在典型的编译过程中，`make` 工具只编译自上次编译后发生修改的文件，这样就在很大程度上简化了编译过程。
        + make 将必须被编译的文件限制在经过修改的那些源文件范围之内，但是即使是使用 `make`，仍然有相当可观的浪费。
        + 每一次编译项目时，源文件在编译为汇编语言和最终的机器代码之前，都要通过 `cpp` 进行解析。对每一个文件来 说，每一次可能都要重新解析头文件。
        + 从编译的全过程来看，最后可能多次解析了相同的头文件，浪费了处理器周期，更重要的是浪费了开发者的时间，因为他们要等待这一过程的完成
    - `ccache`（“compiler cache”的缩写）工具会高速缓存编译生成的信息，并在编译的特定部分使用高速缓存的信息，比如头文件，这样就节省了通常使用 `cpp` 解析这些信息所需要的时间。
    - 安装
        + 到samba上下载安装包：[samba ftp](https://www.samba.org//ftp/ccache/)
            * 本次下载：ccache-3.6.tar.xz
            * `tar xvf ccache-3.6.tar.xz`, `./configure`, `make`, `make install`
        + [Ccache (简体中文)](https://wiki.archlinux.org/index.php/Ccache_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87))
            * 配置，优先级由高到低为:
                - 环境变量
                - 单个 Cache 的配置文件($HOME/.ccache/ccache.conf)
                - 系统配置文件 (/etc/ccache.conf)
            * `/home/user/.ccache/ccache.conf`
                - 可设置最大缓存大小 e.g. `max_size = 2.0G`
                - 可修改默认缓存目录 e.g. `cache_dir = /ramdisk/ccache`
            * ccache 命令行工具
                - 显示统计数据:`ccache -s`
                - 清空缓存:`ccache -C`
    - 使用
        + `gcc foo.c`方式改成：`ccache gcc foo.c`
        + 可以在编译脚本中设置：`CC='ccache gcc'`
    - 默认情况下，ccache 使用当前用户主目录中的一个目录（$HOME/.ccache）来保持高速缓存信息
        + 环境变量 `CCACHE_DIR` 指定了高速缓存目录的位置
        + 如果是在网络中多台机器上使用 ccache，那么要确保共享的目录要通过 NFS 导出（export）并挂载到每 一个客户机上。
    - Makefile中的gcc/g++前加ccache即可，e.g. `CXX = g++`变量改成`CXX = ccache g++`
        + 第二次包括后续的编译，速度快了很多，试验项目第一次编译耗时：121s，再次`make clean;make`耗时：3s


## linux

### history日志显示日期

.bashrc中设置环境变量:
export HISTTIMEFORMAT="%F %T `whoami` "

### man手册等级

* 1是普通的命令
* 2是系统调用,如open,write之类的(通过这个，至少可以很方便的查到调用这个函数，需要加什么头文件)
* 3是库函数,如printf,fread4是特殊文件,也就是/dev下的各种设备文件
* 5是指文件的格式,比如passwd, 就会说明这个文件中各个字段的含义;
    - 比如`man 5 proc`, 说明进程信息伪文件系统
* 6是给游戏留的,由各个游戏自己定义
* 7是附件还有一些变量,比如向environ这种全局变量在这里就有说明
* 8是系统管理用的命令,这些命令只能由root使用,如ifconfig


### 重定向标准错误

`mv a.log back/ 2>tmp.log  (或者2>>tmp.log)`

将执行的错误信息输出重定向到日志tmp.log中，**注意，2>之间不能有空格**

这种情况下，错误信息只会打印到tmp.log中，若要打印到文件的同时，终端上也能打印(标准输出1)，则可使用tee：

```sh
mv a.log back/ 2>&1 | tee -a tmp.log
```

### tee

[tee命令](https://www.cnblogs.com/leezhxing/p/4092532.html)

tee命令读取**标准输入**，把这些内容同时**输出到标准输出**和**（多个）文件**中，tee命令可以重定向标准输出到多个文件。

在使用管道线时，前一个命令的**标准错误**输出不会被tee读取。

```sh
tee
    只输出到标准输出
tee file
    输出到标准输出的同时，保存到文件file中
    如果文件不存在，则创建；如果已经存在，则覆盖之。
tee -a file
    输出到标准输出的同时，追加到文件file中。
    如果已经存在，就在末尾追加内容，而不是覆盖。
tee -
    输出到标准输出两次
tee file1 file2
    同时保存到file1和file2中

ls "*" 2>&1 | tee -a ls.txt
    使用tee命令把标准错误输出也保存到文件
```

### history记录时间
export HISTTIMEFORMAT="%F %T `whoami` "

### vim

* 替换指定行之间匹配字符
    - `%`所有行，`g`所有匹配到的
        + `%` 表示所有行，若没有`%`则只会替换光标所在行
        + `g` 表示一行中的全部，若没有`g`则只替换该行第一个匹配串
    - `:10,15s/abc/hhh/g`
        + 10到15行之间的`abc` `全部` 替换为 `hhh`
    - `%s/abc/hhh/g`
        + 所有abc都替换为hhh
    - 把204到233间的" = "替换为"("
        + `:204,233s/ = /(/g`
    - 204到233间 ");"替换为"));"
        + `:204,233s/\)\;/));/g`
* 查找以\结尾：
    - `/\\$`  (\\为'\'转义)

#### vim版本更新

* 卸载原来的
    - yum remove vim* -y (建议不要移除vim-minimal)
        + 会把 vim-minimal.xxx也卸载掉，visudo(用于配置sudo权限)需要依赖这个包，所以若(centos)要使用sudo，建议不要移除vim-minimal

* 下载vim8.2
    - (由于自己需要的插件fatih/vim-go需要8.0.x之上的版本，所以升级到最新，截止2020.2.26当前最新版本为vim8.2)，ftp://ftp.vim.org/pub/vim/unix上也有其他版本，可网页登录查看
    - wget ftp://ftp.vim.org/pub/vim/unix/vim-8.2.tar.bz2
* 解压安装
    - tar -jxf vim-8.2.tar.bz2
    - cd vim82
    - make
      + 若报错："no terminal library found"
      + 则 `yum install ncurses-devel.x86_64`
      + 参考[CentOS 编译vim no terminal library found](https://blog.csdn.net/cuijianzhi/article/details/78652745)
    - make install
    - 如果vim打开提示版本不是这个版本，那可以alias别名引导至vim82的路径
      + e.g. `alias vim='/usr/local/bin/vim'`
* 插件安装

### rpm

* [Linux RPM包安装、卸载和升级（rpm命令）详解](http://c.biancheng.net/view/2872.html)
    - 父目录下也包含一些其他Linux配置安装类的介绍(RPM命名规则、yum和yum源、源码包安装升级等)

* rpm包安装
    - `rpm -ivh 包全名`
        + -i：安装（install）;
        + -v：显示更详细的信息（verbose）;
        + -h：打印 #，显示安装进度（hash）;
    - 默认安装位置
        + `/etc/` 配置文件安装目录
        + `/usr/bin/` 可执行的命令安装目录
        + `/usr/lib/` 程序所使用的函数库保存位置
        + `/usr/share/doc/` 基本的软件使用手册保存位置
        + `/usr/share/man/` 帮助文件保存位置
* 卸载
    - `rpm -e 包名`
    - RPM 软件包的卸载要考虑包之间的依赖性。
        + 例如，我们先安装的 httpd 软件包，后安装 httpd 的功能模块 mod_ssl 包，那么在卸载时，就必须先卸载 mod_ssl，然后卸载 httpd，否则会报错。
    - RPM 软件包的卸载命令支持使用“-nocteps”选项，即可以不检测依赖性直接卸载，但此方式`不推荐`大家使用，因为此操作很可能导致其他软件也无法征程使用。
* 升级
    - `rpm -Uvh 包全名`
        + -U（大写）选项的含义是：如果该软件没安装过则直接安装；若安装了则升级至最新版本。
        + 将当前已安装的包升级或新安装到一个新的RPM版本. 升级和 安装是一样的, 区别在于升级要将所有别的版本的包从系统移去
    - `rpm -Fvh 包全名`
        + -F（大写）选项的含义是：如果该软件没有安装，则不会安装，必须安装有较低版本才能升级。
        + 只有在系统存在一个更早版本的包时候才使用这种方式.

### ln

* 链接(或称连接也可，Linux man手册中翻译为"连接"，维基百科中"符号连接"会重定向到"符号链接")
    - [符号链接](https://zh.wikipedia.org/wiki/%E7%AC%A6%E5%8F%B7%E9%93%BE%E6%8E%A5)
    - `ln [-s] 目标 链接名称` 创建一个链接，指向"目标"
        + e.g. `ln -s ~/one/two three`, 创建符号链接(软链接)three，指向目录~/one/two
    - 符号链接(软连接，-s选项创建，Symbolic link or soft link)
        + 指向另一个不同路径文件的一个符号路径
        + 对符号链接文件进行读写的程序会表现得像直接对目标文件进行操作
        + 如果删除一个符号链接，它指向的目标文件不受影响。
        + 如果目标文件被移动、重命名或者删除，任何指向它的符号链接仍然存在，但是它们将会指向一个不复存在的文件。这种情况被有时被称为**被遗弃**。
            * /proc/进程号/fd 中`ls -l`，可看到文件描述符都是链接文件(l)，指向socket的文件在闪烁，说明指向不复存在的文件(被遗弃，此时链接文件背景颜色是高亮的)
    - 硬链接(hard link)
        + 存储了链接建立时它所指向文件的实际数据的文件副本
        + 原始文件被删除后，符号链接将失效，访问软链接时，会提示找不到文件，但硬链接文件还在，而且还保存有原始文件的内容。
        + 修改硬链接文件的内容时，原始文件(被链接的文件)也会被修改
        + `ln` 和标准的 `unlink()` 和 `link()` 函数执行完全一致的操作

### 时区

ll /etc/localtime 查看链接的时区文件

### systemctl

1. 查看系统当前默认启动项目的方法，不再是setup之类的了。
`systemctl list-unit-files`

* systemctl 和 `chkconfig` 区别
    - `systemctl`命令：是一个*systemd*工具，主要负责控制systemd系统和服务管理器。
        + [Systemd 入门教程：命令篇](http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html)
        + Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。
        + 由来：历史上，Linux 的启动一直采用init进程。这种方法有两个缺点。一是启动时间长。二是启动脚本复杂。
            * `/etc/init.d/` (`/etc/init.d`是指向`/etc/rc.d/init.d`的软链接)下面管理开机启动的服务，该目录下README文件做了历史说明(CentOS7)：systemd替换了传统的init脚本，"You are running a systemd-based OS where traditional init scripts have been replaced by native systemd services files"
        + Systemd 就是为了解决这些问题而诞生的。它的设计目标是，为系统的启动和管理提供一套完整的解决方案。
        + 使用了 Systemd，就不需要再用init了。Systemd 取代了initd，成为系统的第一个进程（PID 等于 1），其他进程都是它的子进程。
        + Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。
            * 系统管理
                - `systemctl` 是 Systemd 的主命令，用于管理系统。
                - `systemd-analyze`命令用于查看启动耗时。
                - `hostnamectl` 命令用于查看当前主机的信息。
                - `localectl` 命令用于查看本地化设置
                - `timedatectl`命令用于查看当前时区设置
                - `loginctl`命令用于查看当前登录的用户。
            * Unit
                - Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。Unit 一共分成12种。
                    + Service unit：系统服务
                    + Target unit：多个 Unit 构成的一个组
                    + Device Unit：硬件设备
                    + Mount Unit：文件系统的挂载点
                    + Socket Unit：进程间通信的 socket
                    + Swap Unit：swap 文件
                    + ...
                - `systemctl list-units`命令可以查看当前系统的所有 Unit 。
                - `systemctl status`命令用于查看系统状态和单个 Unit 的状态。
                - `systemctl start apache.service` 立即启动一个服务
                - `systemctl stop apache.service`
                - `systemctl restart apache.service`
                - `systemctl list-dependencies` 命令列出一个 Unit 的所有依赖。
                    + (Unit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。)
                    + `systemctl list-dependencies nginx.service`
                    + 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数：`systemctl list-dependencies --all nginx.service`
            * Unit配置文件
                - 每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。
                    + Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接(symbolic link，软链接)，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录。
                    + 配置文件的后缀名，就是该Unit的种类，比如sshd.socket。**如果省略，Systemd默认后缀名为.service**，所以sshd会被理解成sshd.service。(所以有时执行systemctl可以省略.service，但需要该服务类型确实是service)
                - `systemctl list-unit-files` 列出所有配置文件
                - `systemctl enable` 命令用于在上面两个目录之间，建立*符号链接关系*。如果配置文件里面设置了**开机启动**，该命令相当于激活开机启动。
                    + `systemctl enable docker.service` 开机启动docker服务
                - `systemctl disable` 命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动
                - 每个配置文件的状态，一共有四种(systemctl list-unit-files结果列表中各服务状态)。
                    + enabled：已建立启动链接
                    + disabled：没建立启动链接
                    + static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖
                    + masked：该配置文件被禁止建立启动链接
                - `systemctl status`
                    + 从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行systemctl status命令。
            * Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用`journalctl`一个命令，查看所有日志（内核日志和应用日志）
                - `journalctl` 查看所有日志（默认情况下 ，只保存本次启动的日志）
                - `journalctl -k` 查看内核日志（不显示应用日志）
                - `journalctl -b` 查看系统本次启动的日志
            * 争议
                - 事实上，现在还有很多人反对使用 Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反"keep simple, keep stupid"的Unix 哲学。
                - [systemd 为什么会有那么大的争议？](https://www.zhihu.com/question/25873473)
    - `service`命令：可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。
        + `service mysqld start/stop` 命令启动/关闭MySQL实例(非开机启动)
    - `chkconfig`命令：是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。
        + chkconfig命令主要用来更新（启动或停止）和查询系统服务的运行级信息。
        + 谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号链接。
        + `chkconfig --list` 查看开机自启动的服务
            * 只查看MySQL服务 `chkconfig --list mysqld`
            * 配置MySQL的开机自动启动 `chkconfig --add mysql`; `chkconfig mysqld on`
    - `systemctl` 实际上将 service 和 chkconfig 这两个命令整合到一起。在CentOS 7就开始被使用了。
        + 使某服务自动启动(开机启动)
            * 旧指令: `chkconfig --level 3 httpd on`, 新指令: `systemctl enable httpd.service`
        + 使某服务不自动启动
            * 旧指令: `chkconfig --level 3 httpd off`, 新指令: `systemctl disable httpd.service`
        + 检查服务状态
            * 旧指令: `service httpd status`, 新指令: `systemctl status httpd.service` `systemctl is-active httpd.service`(仅显示是否 Active)
        + 显示所有已设置开机启动的服务
            * 旧指令: `chkconfig --list`, 新指令: `systemctl list-units --type=service`
        + 启动/停止/重启某服务
            * 旧指令: `service httpd start/stop/restart`, 新指令: `systemctl start/stop/restart httpd.service`

运行`chkconfig --list`后结果有如下说明(CentOS)：

```
注：该输出结果只显示 SysV 服务，并不包含
原生 systemd 服务。SysV 配置数据
可能被原生 systemd 配置覆盖。

      要列出 systemd 服务，请执行 'systemctl list-unit-files'。
      查看在具体 target 启用的服务请执行
      'systemctl list-dependencies [target]'。
```

2. 取消mysqld的自启动
`systemctl disable mysqld`

查看状态，先status
`systemctl status mysqld.service`

### service

`systemctl status mysqld` 执行和 `service mysqld status` 类似

* service是一个shell脚本，其中包装了systemctl
    - `which service`执行获取完整路径：/usr/sbin/service
    - vi /usr/sbin/service 里面是shell脚本，基于systemctl执行命令

### cpu信息

* `lscpu`
    - 会列出CPU型号、名称、架构、频率、位数、大小端、逻辑CPU个数、每个核心支持的线程数、物理座数等

或者手动过滤查看：  
cpu信息在 /proc/cpuinfo中，根据grep过滤关键字，并配合uniq/sort/wc来过滤重复/排序/计数，统计各信息

* 查看物理CPU的个数(实际物理cpu的个数)

`cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l`

* 查看CPU是几核心(物理核数，每个cpu的物理核数，若有多个物理cpu，核心数都一样就一条记录)

`cat /proc/cpuinfo |grep "cores"|uniq`

* 查看逻辑CPU的个数(若该cpu支持超线程，则1个物理核对应2个逻辑核/线程。 若支持超线程则与物理核是两倍的关系)

`cat /proc/cpuinfo |grep "processor"|wc -l`

超线程计数可以理解为：一颗CPU当成两颗来用，将一颗具有超线程功能的物理CPU变成两颗逻辑CPU，而逻辑CPU对操作系统来说，跟物理CPU并没有什么区别。

超线程介绍：[图说超线程技术(Hyper-Threading Technology)](https://www.cnblogs.com/idorax/p/6884088.html)

获取开发环境配置：

```sh
echo -n "cpu个数: "
cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l
echo -n "cpu核数: "
cat /proc/cpuinfo |grep "cores"|uniq
echo -n "逻辑核数: "
cat /proc/cpuinfo |grep "processor"|wc -l

echo -n "操作系统: "
cat /etc/redhat-release
echo -n "gcc版本: "
gcc -v
```

### yum

* yum
    - yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。
    - 基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。
    - 命令形式一般如下：`yum [options] [command] [package ...]`
        + [options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为"yes"），-q（不显示安装的过程）等等。
        + [command]为所要进行的操作，[package ...]是操作的对象。
    - 安装
        + `yum install package1` 安装指定的安装包package1
        + `yum groupinsall group1` 安装程序组group1
    - 更新和升级
        + `yum update package1` 更新指定程序包package1
        + `yum check-update` 检查可更新的程序
        + `yum upgrade package1` 升级指定程序包package1
    - 查找和显示
        + `yum info package1` 显示安装包信息package1
            * e.g. `yum info sysstat`，结果里会展示：名称、架构、版本、大小、源、简介、协议、描述、已安装、可安装 等信息
        + `yum list` 显示所有已经安装和可以安装的程序包
        + `yum list package1` 显示指定程序包安装情况package1(会展示指定的已安装和可安装的包)
    - 删除程序
        + `yum remove package1` 或 `yum erase package1` 删除程序包package1
    - 清除缓存
        + `yum clean packages` 清除缓存目录下的软件包
        + 查看`/var/cache/yum/x86_64/7/updates/packages`目录(CentOS7)，发现有五六百MB，可以使用该命令清理这些包
    - [linux yum命令详解](cnblogs.com/chuncn/archive/2010/10/17/1853915.html)

## watch

`watch -n1 -d` -d高亮改变的位置

## valgrind

valgrind ./test_server --leak-check=full --show-leak-kinds=definite

## samba 将linux映射为网络驱动
* Samba
    - Samba是在Linux系统上实现SMB（Session MessageBlock）协议的一个免费软件，以实现文件共享和打印机服务共享
        + SMB（Server Message Block）通信协议是微软（Microsoft）和英特尔(Intel)在1987年制定的协议，主要是作为Microsoft网络的通讯协议。SMB 是在会话层（session layer）和表示层（presentation layer）以及小部分应用层（application layer）的协议。
* Samba服务组件
    - samba有两个主要的进程`smbd`和`nmbd`(systemctl中查看服务名是smb，而不是samba)
        + smbd进程提供了文件和打印服务，
        + 而nmbd则提供了NetBIOS名称服务和浏览支持，帮助SMB客户定位服务器，处理所有基于UDP的协议
    - `/etc/samba/smb.conf` 这是samba的主要配置文件
    - `smbstatus`命令，可以列出目前 Samba 的联机状况， 包括每一条 Samba 联机的 PID, 分享的资源，使用的用户来源等等
    - `smbclient`命令，可用于验证设置是否成功(下面安装完后有示例)
    - 参考：[Samba服务器](https://blog.csdn.net/qq_38410730/article/details/80500920)
* 安装步骤参考：[CentOS服务器的目录映射为Windows磁盘驱动器](https://blog.csdn.net/u010480282/article/details/80518836)
    - 安装 `yum -y install samba  system-config-samba samba-client samba-common`
    - (*是否创建组和是否将用户添加到samba组貌似没关系，只要smbpasswd添加用户即可*)
        + 创建samba用户组 `groupadd samba`
        + 拓展：从组wheel中移除用户test：`gpasswd wheel -d test`，`usermod -a -G wheel test` (test添加到wheel组)
            * 通过`newgrp wheel` 立即更新用户组 (否则需要退出登录重新登录)
        + 发现一个用户若存在于samba用户组时，`smbpasswd`删除该用户后，该用户的网络位置还是会显示，但是登陆拒绝
    - 将root用户添加到samba用户当中 `smbpasswd -a root`
        + 通过在`-a`选项后跟上用户名来实现在本地smbpasswd文件中增加用户
        + 拓展：
            * 从samba删除test用户 `smbpasswd -x test`
                - 注意，以前已有的samba中的用户删除并重启smb服务后，网络位置随即失效
            * `pdbedit -L` 查看samba添加的用户，(`pdbedit`用于管理SAM用户数据库) * 如果smbpasswd文件中已经存在了这样的用户时，命令就变成通常的改口令模式
        + 注意：所要加入的SMB用户必须在系统口令文件中(通常是/etc/passwd)已经存在的用户否则加入操作将会失败
        + **通过smbpasswd添加的用户(添加前已存在于/etc/passwd)，在windows输入`\\ip`访问时，就会多出来该用户的网络位置**
            * 在/etc/samba/smb.conf配置文件中配置的位置，也会出现在查找到的网络位置中
            * smbpasswd添加、删除samba用户后，需重启smb服务(service smb restart)才会重新生效
        + 测试：`smbclient //192.168.50.207/xdroot(一般为配置文件中添加的路径)` 添加用户后可用本地命令测试，输入密码成功则会进入`smb: \> `
    - 修改samba配置文件
        + `/etc/samba/smb.conf`
        + 注意`path`值的路径层次，直接`/`貌似没有权限
        + 配置文件中添加共享项之后，在windows的资源管理器(打开目录的窗口)中输入`\\ip`即可访问Linux，设置的项可展示出来

```
; 自定义共享名称
[xdroot]
    ; 共享描述
    comment = share root
    ; 共享路径
    path = /home/xd
    valid users = root
    ;设置共享是否可浏览，如果no就表示隐藏，需要通过IP+共享名称进行访问
    browseable  =  yes
    ;设置共享是否具有可写权限
    writable = yes
    printable = no
```

* 关闭防火墙(完全关闭防火墙影响安全策略，则可对该服务对应端口进行过滤)
    - `service firewalld stop`
    - 关闭开机启动
        + `systemctl disable firewalld.service`
    - 查看是否开机启动 `systemctl list-unit-files|grep firewalld`
* 若不想直接暴力关闭防火墙，可用`firewall-cmd`添加服务到过滤列表
    - `firewall-cmd --permanent --add-service=samba` 添加规则
        + 删除规则则用 `firewall-cmd --permanent --remove-service=samba`
    - 注意添加后，需要`firewall-cmd --reload`加载一下
    - 检查设定是否生效，使用`firewall-cmd --list-all`查看services中是否有添加的服务
    - 参考：[CentOS 7 中firewall-cmd命令](https://www.jianshu.com/p/411274f96492)
        + 获取所有支持的服务 `firewall-cmd --get-service`
        + 查询服务的启动状态 `firewall-cmd --query-service samba`
    - 关于`firewall-cmd`，也可参考本笔记中章节"firewall-cmd命令"
* 关闭selinux
    - `/etc/selinux/config`，改为 SELINUX=disabled
    - `getenforce` 查看是否启用，修改配置后需要重启生效，若临时生效可`setenforce 0`(不改配置文件则重新登录失效)
* 在Windows上映射网络驱动器
    - 资源管理器，在地址栏 `\\192.168.50.207`即可看到设置的共享路径，进入需要映射的子目录，复制路径
    - 此电脑->右键->映射网络驱动器，添加的时候把复制的路径填入即可。进入新的盘符会直接进入到该路径
    - 扩展：
        + a. Linux上mount挂载Windows的共享目录
            * windows机器(e.g. 192.168.50.204)上选定一个目录共享，e.g. 目录名temp_winshare
            * 进行挂载：`mount -t cifs -o username=Test,password=testpwd //192.168.50.204/temp_winshare /mntshare`
        + b. NFS挂载另一台Linux的路径：`mount -t nfs 192.168.50.207:/public /xdmnt -o proto=tcp -o nolock`
            * 关于NFS挂载，查看本笔记中 `## NFS` 章节

## NFS

* [NFS服务器搭建与配置](https://blog.csdn.net/qq_38265137/article/details/83146421)
    - NFS就是Network File System的缩写，它最大的功能就是可以通过网络，让不同的机器、不同的操作系统可以共享彼此的文件
        + CIFS: Microsoft推出SMB（server message block）后，进一步发展，使其扩展到Internet上，成为CIFS(common internet file system)
    - 当我们在NFS服务器设置好一个共享目录`/home/public`后，其他的有权访问NFS服务器的NFS客户端就可以将这个目录挂载到自己文件系统的某个挂载点，这个挂载点可以自己定义
    - RPC（Remote Procedure Call,RPC）协议就是用来统一管理NFS端口的服务，并且统一对外的端口是`111`，RPC会记录NFS端口的信息，如此我们就能够通过RPC实现服务端和客户端沟通端口信息
        + PRC最主要的功能就是指定每个NFS功能所对应的port number,并且通知客户端
    - 当NFS启动后，就会随机的使用一些端口，然后NFS就会向RPC去注册这些端口，RPC就会记录下这些端口，并且RPC会开启111端口，等待客户端RPC的请求
        + 如果客户端有请求，那么服务器端的RPC就会将之前记录的NFS端口信息告知客户端
        + 如此客户端就会获取NFS服务器端的端口信息，就会以实际端口进行数据的传输了
        + 注意：在启动NFS SERVER之前，首先要启动RPC服务（即portmap服务，下同）否则NFS SERVER就无法向RPC服务区注册
            * 另外，如果RPC服务重新启动，原来已经注册好的NFS端口数据就会全部丢失。因此此时RPC服务管理的NFS程序也要重新启动以重新向RPC注册
            * 特别注意：一般修改NFS配置文档后，是不需要重启NFS的，直接在命令执行systemctl reload nfs或exportfs –rv即可使修改的/etc/exports生效
    - Linux下NFS服务器部署
        + 安装NFS服务，需要安装两个软件
            * RPC主程序：rpcbind
                - (在 CentOS 5.x 以前这个软件称为 portmap，在 CentOS 6.x 之后才称为 rpcbind )
            * NFS主程序：nfs-utils
                - 提供 rpc.nfsd 及 rpc.mountd 这两个 NFS daemons 与其他相关 documents 与说明文件、执行文件等的软件
        + NFS相关文件
            * 主要配置文件：/etc/exports
        + 步骤
            * 安装：
                - `yum install -y nfs-utils` 安装nfs服务
                - `yum install -y rpcbind` 安装rpc服务
            * 启动服务和设置开启启动
                - `systemctl start rpcbind`，`systemctl enable rpcbind` 启动并设置自启动
                - `systemctl start nfs-server`，`systemctl start nfs-secure` 启动nfs服务和nfs安全传输服务
                - `systemctl enable nfs-server` `systemctl enable nfs-secure` 设置开机启动
                    + `systemctl list-unit-files`查看启动项，nfs-secure是static状态的(只能作为其他配置文件的依赖)，所以我觉得配不配感觉没关系，可参考本笔记中的`### systemctl`章节
                - `firewall-cmd --permanent --add-service=nfs` 配置防火墙放行nfs服务
                    + `firewall-cmd --reload` 加载生效
                    + 不过测试时发现配置防火墙之后，在客户端机器上`rpcinfo`和`showmount`还是连不上，关闭防火墙之后能连
            * 配置共享文件目录，编辑配置文件
                - 首先创建共享目录，然后在/etc/exports配置文件中编辑配置即可
                - 比如新建共享目录为： `mkdir /public`
                - /etc/exports添加内容：`/public 192.168.50.0/24(rw,no_root_squash,sync)`
                    + 格式为：`共享目录的路径 允许访问的NFS客户端(共享权限参数)`
                        * NFS客户端地址与权限之间没有空格
                        * ro 只读
                        * rw 读写
                        * `root_squash`    当NFS客户端以root管理员访问时，映射为NFS服务器的匿名用户
                        * `no_root_squash` 当NFS客户端以root管理员访问时，映射为NFS服务器的root管理员
                        * `all_squash` 无论NFS客户端使用什么账户访问，均映射为NFS服务器的匿名用户
                        * sync   同时将数据写入到内存与硬盘中，保证不丢失数据
                        * async  优先将数据保存到内存，然后再写入硬盘；这样效率更高，但可能会丢失数据
                - `systemctl reload nfs` 重新加载NFS服务，使配置文件生效
                - `rpcinfo -p localhost` 查看 RPC 服务的注册状况
                    + -p 针对某 IP (未写则预设为本机) 显示出所有的 port 与 porgram 的信息
                    + -t 针对某主机的某支程序检查其 TCP 封包所在的软件版本
                    + -u 针对某主机的某支程序检查其 UDP 封包所在的软件版本
                - `showmount -e localhost`
                    + -a 显示目前主机与客户端的 NFS 联机分享的状态
                    + -e 显示某部主机的 /etc/exports 所分享的目录数据
    - NFS客户端挂载配置(防火墙需要关闭或者放开端口限制)
        + 安装nfs-utils客户端 `yum -y install nfs-utils`
        + 使用`showmount`命令查看nfs服务器共享信息
            * `showmount -e 192.168.50.207`
        + 挂载：`mount -t nfs 192.168.50.207:/public /xdmnt -o proto=tcp -o nolock`
            * 挂载后即可访问到207设备/public目录下的文件，可通过`df -h`查看
            * `umount /xdmnt` 卸载，需要在本机对其未使用的状态
    - Windows客户端挂载
        + [win7 下设置挂载Linux服务器nfs共享的数据](https://blog.51cto.com/ixdba/920290)
            * 开启NFS客户端服务(Windows10)：控制面板->程序->启用或关闭Windows功能->NFS服务 勾选开启
            * 挂载后的目录能直接读取，但是编辑会提示权限问题，修改注册表解决写入权限问题
                - 打开注册表：HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\ClientForNFS\CurrentVersion\Default，增加两项：AnonymousUid，AnonymousGid，类型是REG_DWORD，值默认0即可
    - 防火墙
        + 如果服务器端的防火墙开着的话，将会提示错误 System Error: No route to host
        + 由于nfs服务需要开启mountd,nfs,nlockmgr,portmapper,rquotad这5个服务(可`rpcinfo -p`查看这些服务端口)，需要将这5个服务的端口加到iptables里面，而nfs 和 portmapper两个服务是固定端口的，nfs为`2049`，portmapper为`111`。其他的3个服务是用的随机端口，那就需要先把这3个服务的端口设置成固定的。修改方式如下：

* 固定端口：
    - 修改配置文件 `/etc/sysconfig/nfs`
    - 添加完后重启nfs `service nfs restart`

```
RQUOTAD_PORT=30001
LOCKD_TCPPORT=30002
LOCKD_UDPPORT=30002
MOUNTD_PORT=30003
STATD_PORT=30004
```

* 防火墙放开端口限制：
    - 添加完规则后重新加载防火墙：`firewall-cmd --reload`
    - 如上所述：nfs 和 portmapper两个服务是固定端口的，nfs为`2049`，portmapper为`111`
        + 对于`nfs`服务的端口`2049`，可以通过`--add-port`放开端口，也可通过`--add-service=nfs`放开nfs服务
            * `firewall-cmd --get-service`可以查看支持的服务列表，portmapper并不在其中

```sh
firewall-cmd --permanent --add-port=111/tcp
firewall-cmd --permanent --add-port=111/udp

#若 firewall-cmd --permanent --add-service=nfs 已经添加了nfs服务则不需要单独再打开端口
#firewall-cmd --permanent --add-port=2049/tcp
#firewall-cmd --permanent --add-port=2049/udp

firewall-cmd --permanent --add-port=30001/tcp
firewall-cmd --permanent --add-port=30001/udp

firewall-cmd --permanent --add-port=30002/tcp
firewall-cmd --permanent --add-port=30002/udp

firewall-cmd --permanent --add-port=30003/tcp
firewall-cmd --permanent --add-port=30003/udp

firewall-cmd --permanent --add-port=30004/tcp
firewall-cmd --permanent --add-port=30004/udp

```

## iptables IP包过滤器管理

* [iptables命令](https://man.linuxde.net/iptables)
* `iptables`命令是Linux上常用的防火墙软件，是netfilter项目的一部分
* iptables命令选项输入顺序
    - `iptables -t 表名 <-A/I/D/R> 规则链名 [规则号] <-i/o 网卡名> -p 协议名 <-s 源IP/源子网> --sport 源端口 <-d 目标IP/目标子网> --dport 目标端口 -j 动作`
        + `-t<表>` 指定要操纵的表，表名包括 raw/mangle/net/filter
        + `-A`向规则链中添加条目、`-D`从规则链中删除条目、`-R`替换规则链中的条目、`-I`插入条目
        + `-s`指定要匹配的数据包源ip地址
        + `-d`目标ip地址
        + 规则链名包括：
            * INPUT链        处理输入数据包
            * OUTPUT链       处理输出数据包
            * FORWARD链      处理转发数据包
            * PREROUTING链   用于目标地址转换（DNAT）
            * POSTOUTING链   用于源地址转换（SNAT）
        + 动作包括：
            * ACCEPT        通过，接收数据包
            * DROP          删除，丢弃数据包
            * QUEUE         排队，包传递到用户空间
            * RETURN        返回，停止这条链的匹配
            * 扩展目标：
                - LOG       为匹配的包开启内核记录
                - REJECT    作为对匹配的包的响应，返回一个错误的包：其他情况下和DROP相同
                - SNAT      这个目标只适用于nat表的POSTROUTING链。它规定修改包的源地址
        + `-j` 指定规则的目标，应当做什么
            * 如果规则的这个选项被忽略，那么匹配的过程不会对包产生影响，不过规则的计数器会增加
        + `-m` 模块名 加载iptables功能模块
            * -m  mac  --mac-source 按照mac地址限制访问
                - e.g. 拒绝某mac访问 `iptables -A INPUT -m mac --mac-source aa:bb:cc:dd:ee:ff -j DROP`
* -L：显示规则链中已有的条目 `iptables -L`
* -F：清除规则链中已有的条目 `iptables -F`
* 实例
    - 开放指定的端口
        + `iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT` #允许本地回环接口(即允许本机访问本机)
        + `iptables -A OUTPUT -j ACCEPT`                        #允许所有本机向外的访问
        + `iptables -A INPUT -p tcp --dport 22 -j ACCEPT`       #允许访问22端口
            * 指定端口时，协议不能用all，要指定确切协议
        + `iptables -A INPUT -p tcp --dport 21 -j ACCEPT`       #允许ftp服务的21端口
        + `iptables -A INPUT -j reject`                         #禁止其他未允许的规则访问
    - 屏蔽IP
        + `iptables -I INPUT -s 123.45.6.7 -j DROP`       #屏蔽单个IP的命令
        + `iptables -I INPUT -s 123.0.0.0/8 -j DROP`      #封整个段即从123.0.0.1到123.255.255.254的命令

## firewall-cmd命令

* [firewall-cmd命令](https://man.linuxde.net/firewall-cmd)
    - 参考链接内容说明
        + (参考中关于iptables在CentOS 7上systemctl已找不到该服务，iptables命令还是可以用)
            * **RHEL 7(Red Hat Enterprise Linux)中，firewalld防火墙取代了iptables防火墙**，因此网上很多博客中的`service iptables status`在CentOS 7中并不生效
        + 链接中的`firewall-cmd --enable`语法，在CentOS 7机器上测试并不支持
    - `firewall-cmd`是Linux上新用的防火墙(管理工具)软件，跟iptables差不多的工具
    - `firewall-cmd` 是 firewalld的字符界面管理工具，firewalld是centos7的一大特性，最大的好处有两个：支持动态更新，不用重启服务；第二个就是加入了防火墙的“zone”概念
    - `firewalld`跟`iptables`比起来的好处
        + firewalld可以动态修改单条规则，而不需要像iptables那样，在修改了规则后必须得全部刷新才可以生效
        + firewalld在使用上要比iptables人性化很多，即使不明白“五张表五条链”而且对TCP/ip协议也不理解也可以实现大部分功能
    - `firewalld`自身并不具备防火墙的功能，而是和`iptables`一样需要通过内核的`netfilter`来实现，也就是说firewalld和 iptables一样，他们的作用都是用于维护规则，而真正使用规则干活的是内核的netfilter，只不过firewalld和iptables的结 构以及使用方法不一样罢了
* 常用命令
    - `firewall-cmd --state` 查看运行状态，会显示 running或者not running
    - `firewall-cmd --permanent --add-service=mysql` 开放指定服务的端口
        + `--remove-service=mysql` 关闭
        + `--permanent` 该参数告诉 firewalld 在每次服务器启动时加载此规则，不用该参数意味着下次重启会恢复(reload也会失效)
    - `firewall-cmd --permanent --add-port=111/tcp` 开放通过tcp访问111端口
        + `--remove-port=111/tcp` 关闭
    - `firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.50.0/24" accept"`
        + 添加ip段，使用`--add-rich-rule`，后面一串都是rule信息
        + 也可以同时指定ip段和端口
        + 删除规则:`firewall-cmd --permanent --remove-rich-rule="rule family="ipv4" source address="192.168.142.166" port protocol="tcp" port="11300" accept"`
        + 参考：[centos7 firewall指定IP与端口访问](https://blog.csdn.net/cn_yaojin/article/details/86351392)
    - `firewall-cmd --reload`
        + 将这些规则应用于当前会话，每次add和remove后，若不重启firewalld则需要reload才能生效(临时不用reload，`--permanent`需要)
    - `firewall-cmd --list-all`
        + 查看所有设置(包含sources,services,ports等等信息)
        + `firewall-cmd --list-services` 则只查看服务(services)
        + `firewall-cmd --list-ports` 只查看端口

## 用户组

* 添加用户组
    - `groupadd samba`
* 用户xd添加到用户组samba
    - `usermod -a -G samba xd` (或者-aG)
    - `-G`后面接的是附加组(即用户xd加到samba组)，可以多个，逗号隔开
    - `-a` 或 `--append`， 将用户添加到附加组，只能和`-G`一起使用(将用户添加到新用户组中而不必离开原有的其他用户组。)
* 从用户组wheel删除test用户
    - `gpasswd wheel -d test`
* 立即更新用户组 (否则需要退出登录重新登录)
    - `newgrp wheel`

## 给用户赋root权限

vi /etc/sudoers，找到下面位置并添加用户记录(输入`visudo`回车可编辑即该文件，sudoers本身是没有写权限的，先chmod +w，改完再chmod -w)

* 建议使用：`visudo` (上面chomd操作规避了权限问题)

```sh
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
新用户名 ALL=(ALL) ALL （添加这一行）
```

## 灰度发布

参考百度百科：
[灰度发布](https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83)

* 灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。
    - 在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。
    - 灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。

* 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。

* 作用： 及早获得用户的意见反馈，完善产品功能，提升产品质量 让用户参与产品测试，加强与用户互动 降低产品升级所影响的用户范围

本质上灰度测试可以算作A/B测试的一种特例

> 灰度发布与互联网公司常用A/B测试似乎比较类似，国外互联网公司似乎并没有所谓的灰度发布的概念。
> 按照wikipedia中对A/B测试的定义，A/B测试又叫：A/B/N Testing、Multivariate Testing，因此本质上灰度测试可以算作A/B测试的一种特例。

* 步骤：
    - 1）定义目标
    - 2）选定策略：包括用户规模、发布频率、功能覆盖度、回滚策略、运营策略、新旧系统部署策略等
    - 3）筛选用户：包括用户特征、用户数量、用户常用功能、用户范围等
    - 4）部署系统：部署新系统、部署用户行为分析系统（web analytics）、设定分流规则、运营数据分析、分流规则微调
    - 5）发布总结：用户行为分析报告、用户问卷调查、社会化媒体意见收集、形成产品功能改进列表
    - 6）产品完善
    - 7）新一轮灰度发布或完整发布

## QT

[Qt Downloads](http://download.qt.io/archive/qt/) 环境搭建(官网的下载链接点击进去找不到界面)

## UML类图

[UML类图与类的关系详解](http://uml.org.cn/oobject/201104212.asp)

[UML——在Visual Studio 2013/2015中设计UML类图](https://www.cnblogs.com/SceneryHao/p/5355915.html)

Unified Modeling Language (UML)又称统一建模语言或标准建模语言。

简单说就是以图形方式表现模型，根据不同模型进行分类

常用 UML 动态图（5 个）：用例图，活动图，状态机图，序列图，通信图。
常用 UML 静态图（4 个）：类图，包图，部署图，构件图。

在所有UML图中，类图是使用频率最高的UML图。
类图用于描述系统中所包含的类以及它们之间的相互关系，帮助人们简化对系统的理解，它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。

类图主要关系有：泛化（Generalization）,  实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)

* 泛化（Generalization)
    - 【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。
    - 【代码体现】：类继承另一个类
    - 【箭头指向】：带三角箭头的实线，箭头指向父类

## sysctl

* sysctl
    - 参见man手册
    - 在运行时修改内核参数
    - 系统会从按顺序从一系列配置文件中加载配置
        + `/run/sysctl.d/*.conf`
        + `/etc/sysctl.d/*.conf`
        + `/usr/local/lib/sysctl.d/*.conf`
        + `/usr/lib/sysctl.d/*.conf`
        + `/lib/sysctl.d/*.conf`
        + `/etc/sysctl.conf` 这个配置在修改内核参数时也是经常用的
    - `sysctl -p[FILE]` 从指定的文件中加载配置，如果没有指定则默认从 /etc/sysctl.conf
    - `sysctl -a` 展示当前所有可用配置的值

## /etc/security/limits.conf

* /etc/security/limits.conf
    - limits.conf文件介绍
        + 是Linux PAM (插入式认证模块，Pluggable Authentication Modules)中 pam_limits.so 的配置文件
        + pam_limits模块对 `用户的会话` 进行 `资源限制`。
            * 一个shell的初始limits就是由pam_limits设定的
    - 配置格式：`<domain>        <type>  <item>  <value>`
        + e.g. `@root           hard    core    307200`
        + `<domain>` 可以指定用户(用户)、组(@组名)、`*`和`%`通配符
        + `<type>` 两种形式
            * "soft" 软限制
                - soft指的是当前系统生效的设置值，软限制也可以理解为警告值
            * "hard" 硬限制
                - hard表明系统中所能设定的最大值
                - soft的限制不能比hard限制高
                - 配置文件中用`-`表明同时设置了soft和hard的值。
            * **soft和hard需要都进行设置,才能生效**
        + `<item>` 项目
            * `ulimit -a`可以查看一些配置项，也可以通过ulimit临时设置配置项
        + `<value>` 取值
    - 配置文件说明可以参考：[/etc/security/limits.conf 详解与配置](https://www.cnblogs.com/operationhome/p/11966041.html)
    - 临时设置
        + `ulimit -SHn 65536` 重启后会失效(可以启动程序前进行一次设置，以免影响设备全局)
            * ubuntu下，`-SH -c`没有生成core，建议还是不要加`-SH`了(CentOS下是ok的)
        + `ulimit` 命令
            * `-H` 和 `-S` 指定为所给资源设定的**硬性**和**柔性**限额
            * 针对对应的资源项，实际使用资源在达到设置的硬性限额后不能增加；达到设置的柔性限额后可以增加，直到与硬性限额相等。
            * 如果没有给出 `-H` 或 `-S` 选项，将同时设置硬性和柔性限额。
    - 永久配置
        + 配置到配置文件`/etc/security/limits.conf`或者 `/etc/security/limits.d/` 中
        + 重新生效：退出当前会话，重新登录；或者重启
* 注意
    - /etc/security/limits.d/ 下文件的相同配置可以覆盖 /etc/security/limits.conf
    - nofile不能设置 unlimited
    - nofile可以设置的最大值为 1048576(`2**20`)，设置的值大于该数，就会进行登录不了。
    - soft 设置的值 一定要小于或等于 hard 的值。(如果soft值更大，也只会限制为hard设置的值)
* 通过该配置的调整解决了zabbix远程命令启动的进程无法生成core文件的问题(hard限制的问题)
    - 试过：
        + 在.bashrc中添加 `ulimit -S -c unlimited`,`ulimit -c 307200`(300MB)
        + 启动程序前`ulimit -S -c unlimited`
        + `/etc/security/limits.conf`中添加root组限制，但是只开了soft
        + 环境和正常环境有点特别：配置了zabbix远程监控主机上的进程，当进程不存在时执行启动脚本进行启动
            * 本地终端启动进程，然后发送段错误信号`kill -s SEGV pid`，能正常生成core文件
            * 但是通过zabbix远程启动(sudo xxx.sh,zabbix添加进sudoers免密中)的进程，不能正常生成core
    - 原因是对`-S`和`-H`的理解模糊导致的问题(关于含义参见上面说明)
    - 解决方法一：最终在`limits.conf`中新增hard配置后解决(zabbix添加进了root组， 若没有添加进group保险起见可以单独配置zabbix组或者用户)
        + `@root               soft    core            307200`
        + `@root               hard    core            307200`
    - 解决方法二：意识到是由于hard项的配置问题，把`limits.conf`中配置还原后(即啥都不动)，在启动脚本中单独`ulimit -c 307200`，也可正常生成core文件
        + **配置注意！**(包括下面/etc/sysctl.conf的配置):
            * 1. `/etc/sysctl.conf` 中`=`后面的内容不要用引号括起来`"`
            * 2. .bashrc/.zshrc，和服务脚本中，设置`ulimit -c 307200`，*不要加`-SH`*分别限制软硬限额
                - 加了`-SH`则ubuntu下ulimit不会生效，而centos下是生效的。。。坑人
        + 在ubuntu上，.zshrc中添加`ulimit -c 307200`，session中启动的程序能生成core，但是zabbix拉起的生成不了
            * 用脚本拉服务，就算脚本中设置了`ulimit -SH -c 307200`，但.zshrc中未设置，也生成不了core
            * 而拉服务的脚本中设置`ulimit -c 307200`能正常生成，看来应该设置`ulimit -c 307200`，不用加`-SH` *试好多次发现的坑*
                - 再次尝试，.zshrc中不加ulimit，只是服务脚本中ulimit不加`-SH`也能生成core
        + 基于各种踩坑，最后的最佳实践是：
            * 若不想影响其他服务，则在单独服务的脚本中设置`ulimit -c`(且不加`-SH`选项，ubuntu和centos表现不同)，整体配置可不修改
            * 若对本机所有服务生效，则在`/etc/security/limits.conf`中设置core类型
                - `.bashrc/.zshrc`中设置`ulimit -c`(且不加`-SH`选项)，zabbix远程执行脚本并没有用，要脚本中设置ulimit
    - 需要注意环境变量的问题：通过重启来重新加载环境变量(或重新登录重新让.bashrc中的配置生效)，需要注意的是通过脚本操作时，其当前对应的环境变量与系统可能是不一样的(像crontab里根本就不用系统环境变量而需要其进行一下source)

## core

* 允许生成 core文件
    - [Linux生成core文件、core文件路径设置](https://blog.csdn.net/u011417820/article/details/71435031)
    - `ulimit -c 设置大小`
        + 注意在终端敲命令执行ulimit时，只会影响本终端，其他终端起的进程并不会受影响，所以在启动服务的终端设置
        + 在系统配置中修改：`/etc/security/limits.conf`，(.bashrc中添加只影响终端session)
    - `/etc/sysctl.conf`
        + 添加配置项：`kernel.core_pattern=/corefile/core-%e-%p-%t`，
            * 然后`sysctl -p`生效，会改变`/proc/sys/kernel/core_pattern`中的值
            * **注意** `=`后面的内容不要用`"`，否则设置的路径不生效，不生成core
        + `/proc/sys/kernel/core_pattern` 临时设置core文件保存位置和文件名格式
            * 重启后会恢复，完全生效需修改sysctl.conf
        + "|/usr/libexec/abrt-hook-ccpp %s %c %p %u %g %t e %P %I %h" CentOS7默认内容
            * 注意最后的`/`后面是文件命名格式
            * `%p` 添加pid
            * `%u` 添加当前uid
            * `%g` 添加当前gid
            * `%s` 添加导致产生core的信号
            * `%t` 添加core文件生成时的unix时间
            * `%h` 添加主机名
            * `%e` 添加导致产生core的命令名(触发core生成的进程/线程名，不过名称可能不完整)(建议程序中单独设置线程名)
        + 可以查看`/proc/sys/kernel/core_pattern`中的内容，已改成了`/etc/sysctl.conf`设置的格式
            * 注意设置的目录需要存在(提前新建好)，否则不会生成core文件
        + 由于corefile都比较大，需要监控生成core文件的个数，防止磁盘被占满
            * 建议的实践是固定一个存储位置(如/corefile/)并进行脚本监控个数，下面附自己写的监控脚本，脚本执行可添加到crontab中
    - `kill`
        + `kill -l` 打印信号列表，(man中提示在`/usr/include/linux/signal.h`也可找到，看了下内容只#define了两个宏。。)
        + `kill -s` 指定发送的信号，信号可以以*信号名*或者数字发送

```sh
#!/bin/bash
# check_core.sh 监控core文件
CORE_DIR=/corefile
CHECK_LOG_FILE=check.log

function check_create_dir()
{
    NEED_DIR=$1
    if [ ! -d ${NEED_DIR} ]; then
        mkdir ${NEED_DIR}
    fi
}

function check_log_size()
{
    MAX_LOG_SIZE=$((1024*1024*30))

    CHECK_SIZE_LOG_FILE=$1
    OPS_LOG_FILE_SIZE=`ls -l ${CHECK_SIZE_LOG_FILE} | awk -F' ' '{ print $5}'`
    echo "[$(date)], file[${CHECK_SIZE_LOG_FILE}] size:${OPS_LOG_FILE_SIZE}" >> ${CHECK_SIZE_LOG_FILE}
    # 大于30M则重新生成
    if [ $OPS_LOG_FILE_SIZE -gt ${MAX_LOG_SIZE} ]; then
        echo "[$(date)], file[${CHECK_SIZE_LOG_FILE}] size:${OPS_LOG_FILE_SIZE} over $((${MAX_LOG_SIZE}/1024/1024)) MB, recover" > ${CHECK_SIZE_LOG_FILE}
    fi
}


check_create_dir ${CORE_DIR}

cd ${CORE_DIR}
if [ $? -ne 0 ]; then
    echo "[$(date)], cd ${CORE_DIR} error, exit!"
    exit -1
fi
echo "[$(date)], cd ${CORE_DIR}" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}

# 过滤日志文件后的文件数量
corefile_num=`ls -I ${CHECK_LOG_FILE}|wc -l`
echo "[$(date)], file num:${corefile_num}" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}
# 超过n个core则只保留最近的n个
if [ ${corefile_num} -gt 3 ]; then
    echo "[$(date)], file num:${corefile_num} over 3!" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}
    filelist=`ls -I ${CHECK_LOG_FILE} -t`
    i=0
    for file in ${filelist}
    do
        ((i++))
        if [ $i -le 3 ]; then
            continue
        fi
        echo "[$(date)], rm:[$(file ${file})], i:$i" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}
        # 避免rm -rf ${a}/${b}形式的语句，防止a为空导致误操作/目录
        rm -rf ${file}
    done
fi

# 日志文件大小限制
check_log_size ${CORE_DIR}/${CHECK_LOG_FILE}
```

## gdb

* [gdb官网文档](http://www.gnu.org/software/gdb/documentation/)
    - [Debugging with GDB](https://sourceware.org/gdb/current/onlinedocs/gdb/)
        + 生成core：[10.19 How to Produce a Core File from Your Program](https://sourceware.org/gdb/current/onlinedocs/gdb/Core-File-Generation.html#Core-File-Generation)
        + core文件/core dump文件：记录正在运行的进程的内存映像及其进程状态的文件
        + 它的主要用途是对在调试器之外运行时崩溃的程序进行事后调试
        + 也可以从正在执行的程序生成一个core文件：
            * `usage:  gcore [-a] [-o filename] pid` 没有指定名称则默认"core.pid"
    - 支持语言：C/C++、Go、Objectiv-C、Rust 等(不怎么耳熟的未列)
        + [Supported Languages](https://sourceware.org/gdb/current/onlinedocs/gdb/Supported-Languages.html#Supported-Languages)

* 设置系统允许生成core文件，参考上面记录的core章节，本笔记中搜索`## core`
* gcc -g选项：以操作系统的本地格式(stabs, COFF, XCOFF, 或 DWARF). 产生调试信息. GDB 能够使用这些调试信息.

* 升级gcc 4.8.5
[CentOS升级gcc4.4.7到gcc4.8.5](https://blog.csdn.net/shine_journey/article/details/62039381)

* 断点
    - 添加
        + `break` / `b`, 四种形式
            * break line-number                    在执行给定行之前
            * break function-name                  在进入指定的函数之前
            * break line-or-function if condition  如果condition（条件）是真，程序到达指定行或函数时停止
            * break routine-name                   在指定例程的入口处设置断点
        + 可以在各个原文件中设置断点
            * break filename:line-number
            * break filename:function-name
        + 回车会在上一个位置再次设置一个端点
    - 查看
        + `info break`
    - 删除
        + `delete`
            * delete 5 (指定编号)
            * delete 1-10(连续的断点号)
        + `clear`
            * clear list.c:12           //删除文件：行号的所有断点
            * clear 12                  //删除行号的所有断点
            * clear list.c:list_delet   //删除文件：函数的所有断点
            * clear 删除断点是基于行的，不是把所有的断点都删除
    - 临时断点
        + 在使用gdb调试时，如果想让断点只生效一次，可以使用`tbreak`命令（缩写为`tb`），和设置断点的过程一样
            * 临时断点13显示:*del*, 普通断点:*keep*
    - 条件断点
        + `break 行号 if 条件`，意思是只有在条件满足的时候，断点才会被触发
        + `b 222 if i==100` (i为100时触发断点)
    - 忽略断点
        + 在设置了断点之后，可以使用命令`ignore 断点编号i cnt`来忽略断点，意思是接下来的cnt次编号为i的断点触发都不会让程序暂停，只有第cnt+1次断点触发才会让程序暂停

```sh
# 临时断点
Num     Type           Disp Enb Address            What
13      breakpoint     del  y   0x0000000000415383 in Thread_func(void*) at src/func.cpp:224
14      breakpoint     keep y   0x0000000000415353 in Thread_func(void*) at src/func.cpp:222
```

* gdb 查看虚函数表
    - a. `b 行号` 打断点到对象定义后，`p b`打印对象
        + `set print object on` 可设置打印真实的类类型(即打印对象的指针时，打印派生的实际类而不是基类)
            * 有RTTI才生效，需要有虚函数才生效
            * 参考gdb onlinedoc(搜set print object on)：[gdb onlinedoc](https://sourceware.org/gdb/onlinedocs/gdb/Print-Settings.html)
    - b. 设置上面的object on后，`p b`打印前面多了一个`(真实类型)`
        + `$6 = {_vptr.Base = 0x400f90 <vtable for Base+16>}` 设置前
        + `$7 = (Base) {_vptr.Base = 0x400f90 <vtable for Base+16>}` 设置后
    - c. 查看虚表指针(`0x400f90`)中的内容(可以看到虚函数f()、g()、h()及对应地址)
        + `p /a *(void**)0x400f90@4` 或(`p/a`)
            * `$15 = {0x400ce6 <Base::f()>, 0x400d10 <Base::g()>, 0x400d3a <Base::h()>, 0x6465766972654437}`
            * `set print symbol-filename on` 可打印各虚函数在文件中的位置(文件和行号)
            * `set print pretty on` 如果打开printf pretty这个选项，那么当GDB显示结构体时会比较漂亮
        + [GDB print 详解](https://blog.csdn.net/linuxheik/article/details/17380767)
            * `@` 是一个和数组有关的操作符
            * `::` 指定一个在文件或是一个函数中的变量。变量重名时，查看文件f2.c中的全局变量x的值：`(gdb) p 'f2.c'::x`
            * `p *array@len ` array:数组的首地址，len:数据的长度
            * `/a` 按十六进制格式显示变量。 还可以`p/c`字符格式、`p/d`十进制、`p/o`八进制、`p/f`浮点数等等
    - [gdb查看虚函数表、函数地址](https://www.cnblogs.com/johnnyflute/p/3675630.html)


### 遇到过的问题记录

* 收到：signal SIGABRT，程序退出

```golang
//gdb程序报错退出
// (发现问题是root用户编译，用普通用户执行的，push_back()时就报这个退出了，奇葩问题奇葩操作...):
Program received signal SIGABRT, Aborted.

terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7ffff070f700 (LWP 12784)]
0x00007ffff5573207 in raise () from /lib64/libc.so.6

//bt查看:
(gdb) bt
#0  0x00007ffff5573207 in raise () from /lib64/libc.so.6
#1  0x00007ffff55748f8 in abort () from /lib64/libc.so.6
#2  0x00007ffff609d445 in __gnu_cxx::__verbose_terminate_handler () at ../../../../libstdc++-v3/libsupc++/vterminate.cc:95
#3  0x00007ffff609b5d6 in __cxxabiv1::__terminate (handler=<optimized out>)
    at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:38
#4  0x00007ffff609b603 in std::terminate () at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:48
#5  0x00007ffff609b823 in __cxxabiv1::__cxa_throw (obj=0x7fffe0013ce0, tinfo=0x7ffff6322b00 <typeinfo for std::bad_alloc>,
    dest=0x7ffff6099cd0 <std::bad_alloc::~bad_alloc()>) at ../../../../libstdc++-v3/libsupc++/eh_throw.cc:87
#6  0x00007ffff609bd1d in operator new (sz=18446744073709551600) at ../../../../libstdc++-v3/libsupc++/new_op.cc:56
#7  0x00000000004259e8 in __gnu_cxx::new_allocator<TestResult>::allocate (this=0x7ffff070eb20, __n=256204778801521550)
    at /usr/local/include/c++/4.8.5/ext/new_allocator.h:104
#8  0x0000000000421ec5 in std::_Vector_base<TestResult, std::allocator<TestResult> >::_M_allocate (
    this=0x7ffff070eb20, __n=256204778801521550) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:168
#9  0x0000000000525324 in std::vector<TestResult, std::allocator<TestResult> >::_M_emplace_back_aux<TestResult const&> (this=0x7ffff070eb20) at /usr/local/include/c++/4.8.5/bits/vector.tcc:404
#10 0x00000000005212d5 in std::vector<TestResult, std::allocator<TestResult> >::push_back (
    this=0x7ffff070eb20, __x=...) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:911
```


## 线程

* pthread_create 创建分离线程后，传入的参数应该立即(*应该usleep一定的时间*,e.g. 1ms), 在线程中新建存储区进行存储，不应该一直使用外部的地址。

## perf

* centos安装 `yum install perf`
* ubuntu安装 `apt install linux-tools-common`
* 需要以root用户运行
* `perf top [-g] -p 进程号`， 查看cpu使用率高问题
    - -g: Enables call-graph (stack chain/backtrace) recording，启用调用图记录
* `perf record [-o filename]` 和 `perf report`
    - `perf top` 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。
    - 而 `perf record` 则提供了保存数据的功能，保存后的数据，需要你用 `perf report` 解析展示
    - `perf record [-g]`，一段时间后按Ctrl+C终止采样； 再执行`perf report`，展示类似于perf top的报告
        + 在实际使用中，我们还经常为其加上-g参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。
    - `-a` 来自所有CPU的全系统范围的收集
    - 可以配合sleep使用，自动记录一段时间 `perf record -a sleep 10` (记录10s)
        + **注意**： 此处若不加`-a`指定所有cpu，则跟踪到的只有`sleep`的调用堆栈
    - 可以配合`火焰图`对文件处理更直观地进行分析(后面有记录用法，按关键词`火焰图`搜索笔记)
* `perf script`
    - 读取`perf record`生成的perf.data文件，并展示跟踪输出，e.g. `perf script -i perf.data > perf.unfold`
    - `perf record` 生成的文件类型是`data`(二进制数据,`file perf.data`查看)，而`perf script`生成的文件类型是`ASCII text`
    - 语法格式：
        + `perf script [<options>]` 查看记录下来的perf.data文件对应的：工作负载的详细跟踪
            * -i 指定输入文件名(不指定则默认读取perf.data)
        + 还可以运行一组预录制的脚本，它们以各种方式聚合和汇总原始跟踪数据：
            * `perf script [<options>] record <script> [<record-options>] <command>`
                - `<script>`指定跟踪的脚本，可以通过：`perf script --list`或`perf script -l` 查看可用的脚本名
            * `perf script [<options>] report <script> [script-args]`
            * man perf script查看更多用法和选项
* `perf stat`
    - [系统级性能分析工具 — Perf](https://blog.csdn.net/zhangskd/article/details/37902159)
    - 分析指定程序的性能概况 e.g. `perf stat ls`
    - 选项
        + `-p` 指定已有进程
        + `-e` 指定关注事件
        + `-o` 输出到指定文件
    - 默认统计的事件：
        + `task-clock (msec)`，任务真正占用的处理器时间，单位为ms
            * `CPUs utilized` = task-clock / time elapsed，CPU的占用率
        + `context-switches`，上下文的切换次数
        + `cpu-migrations`，处理器迁移次数。Linux为了维持多个处理器的负载均衡，在特定条件下会将某个任务从一个CPU迁移到另一个CPU
        + `page-faults` 缺页异常的次数。当应用程序请求的页面尚未建立、请求的页面不在内存中，或者请求的页面虽然在内存中，但物理地址和虚拟地址的映射关系尚未建立时，都会触发一次缺页异常。另外TLB不命中，页面访问权限不匹配等情况也会触发缺页异常。
        + `cycles` 消耗的处理器周期数
        + `instructions` 执行了多少条指令。IPC为平均每个cpu cycle执行了多少条指令
        + `branches` 遇到的分支指令数。
        + `branch-misses` 是预测错误的分支指令数
* `perf list` 可以列出`-e`支持的事件类型
* `while(1) {dosomething();}`，或者直接`while(1) {}` cpu使用率100%问题
    - Unix系统使用cpu通过时间片轮转(而Windows则属于抢占式的，进程主动放弃使用CPU)，while(1){}会持续占用cpu，导致cpu使用率很高
    - 在while体中添加usleep(1000)，即sleep 1ms，cpu使用率大大降低
    - 在while体中，若当次不执行任何操作，建议添加一个短的等待时间(**包含不满足继续条件直接continue,不执行任何其他语句的情况**)
    - 中断
        + 内核统计程序占的CPU是通过时钟中断完成的，当时钟中断发生时候，通过IP记数器(程序计数器PC)找到发生前正在运行的程序。
        + 程序不做事情时，进入内核中的 idle() 程序，等待中断唤醒。而该程序使CPU处于休息状态，将CPU的系统时钟频率调整到很低，此时会比较省电，风扇不转，然后在这个状态下循环等待

>理想情况下，假设原本执行一次循环只需要消耗10个CPU周期的话，如果不进行阻塞，2Ghz的CPU在一秒内会执行`2*10^9/10=2*10^8`次的循环，然而在1秒内执行那么多次循环对我们的程序一点帮助都没有，还会抢占CPU资源；而阻塞该程序1ms后，相当于每进行一次循环后就让出1ms的运算资源，也就是让出2*10^6个cpu周期，原本占用100%的程序只会占用不到1万次CPU周期，这对于2Ghz的CPU来说几乎是0负担的。 [CPU占用率100%](https://cloud.tencent.com/developer/article/1327007)

## strace

* [Linux strace命令](https://www.cnblogs.com/ggjucheng/archive/2012/01/08/2316692.html)
    - `strace`常用来跟踪进程执行时的系统调用和所接收的信号，
    - 可以跟踪到一个进程产生的系统调用,包括参数，返回值，执行消耗的时间
    - 结果每行的形式(每行一个系统调用)：`read(3, "     # discp s"..., 4096) = 4096`
        + 等号左边是系统调用的函数名及其参数，右边是该调用的返回值
* 使用
    - `strace -o output.txt -T -tt -e trace=all -p 28979` (注意`-o xxxfile`要放到前面)
        + `-o output.txt` 记录结果存在output.txt文件
        + `-T` 显示每一调用所耗的时间
        + `-tt` 在输出中的每一行前加上时间信息,微秒级
        + `-e xxx`
            * 只跟踪xxx系统调用，等价于 `-e trace=xxx`
            * e.g. `-e open`等价于 `-e trace=open`，表示只跟踪`open`调用
        + `-e trace=xxxset(xxxset为某调用集合，逗号分隔)`
            * `-e trace=`只跟踪指定的系统调用，如`-e trace=open,close,rean,write`只跟踪这四个调用
                - 默认调用集合为`all`
            * `-e trace=file` 只跟踪文件相关的系统调用
            * `-e trace=network` 网络相关
            * `-e strace=signal` 信号相关
        + `-e signal=xxxset` 只跟踪指定信号集，e.g. `-e signal=!SIGIO` (`!`取反，除SIGIO外的所有信号)
        + `-e read=3,5` 只跟踪从fd为3和5的文件读取的操作
        + `-f` 跟踪由fork调用所产生的子进程
            * `-F` 尝试跟踪`vfork`调用，在`-f`时,`vfork`不被跟踪
        + `-d` 输出strace关于标准错误的调试信息
        + `-c` 统计每一系统调用的所执行的时间,次数和出错的次数等
        + `-s strsize` 指定输出的字符串的最大长度，默认为32
        + `-u username` 跟踪用户`username`相关的操作
        + 其他选项可参考上面的链接
    - `strace -p进程号或者线程号` (已启动的进程)
    - `strace ./xxxserver` 新启动服务时分析

## ltrace

* 安装
    - `yum install ltrace` (CentOS)
* [Linux 性能工具(1): ltrace](https://zhuanlan.zhihu.com/p/22596610)
    - `ltrace`用于跟踪库函数调用 (`strace`主要用来跟踪系统调用)
    - 实现原理：实现的关键在于系统调用`ptrace`
        + ltrace进程本身：首先会fork一个新进程，并调用execvp执行被跟踪的进程，此后调用"`waitpid(-1, &status, __WALL)`"捕获被跟踪进程的相关信息，并调用WIFSTOPPED等来解析status，从而可以获知相关库调用信息
        + 被ltrace跟踪的进程: 主要是调用”ptrace(PTRACE_TRACEME, 0, 0, 0) “，从而相关调用可以被捕获
    - 使用：
        + 跟踪某个程序，例如要跟踪“top"命令的函数调用，可以使用 `ltrace top`
        + 跟踪已有的进程: `ltrace -p <pid>`
        + 跟踪进程以及其所有创建的所有子进程/线程的调用：`ltrace -f -t -p <pid>`
* [linux ltrace-跟踪进程调用库函数的情况](https://www.cnblogs.com/mayou18/p/9546645.html)
    - `ltrace [option ...] [command [arg ...]]`
    - 和 `strace`比较类似
        + `-a` 对齐具体某个列的返回值。
        + `-c` 计算时间和调用，并在程序退出时打印摘要。
        + `-C` 解码低级别名称（内核级）为用户级名称。
        + `-d` 打印调试信息。
        + `-e` 改变跟踪的事件。
        + `-f` 跟踪子进程。
        + `-h` 打印帮助信息。
        + `-i` 打印指令指针，当库调用时。
        + `-l` 只打印某个库中的调用。
        + `-L` 不打印库调用。
        + `-n`, --indent=NR 对每个调用级别嵌套以NR个空格进行缩进输出。
        + `-o`, --output=file 把输出定向到文件。
        + `-p` PID 附着在值为PID的进程号上进行ltrace。
        + `-r` 打印相对时间戳。
        + `-s` STRLEN 设置打印的字符串最大长度。
        + `-S` 显示系统调用。
        + `-t`, -tt, -ttt 打印绝对时间戳。
        + `-T` 输出每个调用过程的时间开销。
        + `-u` USERNAME 使用某个用户id或组ID来运行命令。
        + `-V`, --version 打印版本信息，然后退出。

## 粘滞位(Stickybit)

* [Linux-粘滞位的使用](https://www.cnblogs.com/hanxiaoyu/p/5622036.html)
    - 粘滞位（Stickybit），又称粘着位，是Unix文件系统权限的一个旗标。
        + 最常见的用法在目录上设置粘滞位，也**只能针对⽬录设置**，对于⽂件⽆效。
    - 设置了粘滞位后，只有目录内文件的所有者或者root才可以删除或移动这些文件
        + 如果不为目录设置粘滞位，任何具有该目录写和执行权限的用户都可以删除和移动其中的文件
    - 粘滞位一般用于`/tmp`、`/var/tmp`目录，以防止普通用户删除或移动其他用户的文件
        + `/tmp` 目录的属性为(`ls -l /`查看)：
            * `drwxrwxrwt.  11 root root 4096 6月   4 10:56 tmp`
            * 其中的`t`就是粘滞位
        + 而其他777权限的目录，目录可执行`x`会变为`t`
            * `lrwxrwxrwx.  1 root root    6 3月  23 11:16 run -> ../run`
    - e.g. `chmod +t xddir` 为xddir目录添加粘滞位，`-t`则为去掉粘滞位(去掉后变为`-x`可执行/访问)

## stress

* stress是一个Linux系统压力测试工具，可模拟CPU、IO、内存负载
    - 先`yum install -y epel-release`, 再 `yum install -y stress`
        + EPEL (Extra Packages for Enterprise Linux)是基于Fedora的一个项目，为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux.
        + 首先我们需要安装一个叫”epel-release”的软件包，这个软件包会自动配置yum的软件仓库。当然你也可以不安装这个包，自己配置软件仓库也是一样的。 软件仓库配置目录在：`/etc/yum.repos.d/`

* 使用
    - `-t N` 或 `--timeout N`：运行秒数
    - `-c N` 或 `--cpu N`：产生多个处理sqrt()函数的CPU进程
        + `stress -c 2 -t 10` 其两个进程测CPU，跑10s
    - `-i N` 或 `--io N`：产生多个处理sync()函数的磁盘I/O进程
    - `-m N` 或 `--vm N`：产生多个处理malloc()/free()内存分配函数的进程
        + `--vm-bytes B`：指定内存的byte数为B，默认值是256MB
        + `--vm-hang N`：指定malloc分配的内存多少秒后free()释放掉，默认不释放，0无效
    - `-d N` 或 `--hdd N`：产生多个处理write()/unlink()的进程
        + `--hdd-bytes B`：指定每个hdd进程处理的byte字节数，默认1GB

## mpstat

[mpstat命令](https://man.linuxde.net/mpstat)

* mpstat
    - mpstat命令指令主要用于多CPU环境下，它显示各个可用CPU的状态信息，包括硬件软件中断信息。
    - 这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。
    - 包含在 sysstat 软件包中，`yum info sysstat`查看该软件包信息(CentOS)
        + `apt-get install -y sysstat` (Ubuntu)
    - `mpstat [ -A ] [ -u ] [ -V ] [ -I { SUM | CPU | SCPU | ALL } ] [ -P { cpu [,...] | ON | ALL } ] [ interval [ count ] ]` (最后两个参数用于指定间隔和次数)
    - `mpstat (选项) (参数)`
        + 选项-P：指定CPU编号，指定-P ALL 则显示所有逻辑CPU列表，并会显示一个all的统计
        + 参数 间隔时间：每次报告的间隔时间（秒）；
        + 参数 次数：显示报告的次数。
        + e.g. `mpstat -P ALL 5 2` 所有CPU，间隔5S，只显示2次(参数和选项均为可选)
    - 当mpstat不带参数时，输出为从系统启动以来的平均值，*默认打印CPU*使用报告
    - The mpstat command can be used both on SMP and UP machines
        + UP（Uni-Processor）：系统只有一个处理器单元，即单核CPU系统
        + SMP（Symmetric Multi-Processors）：系统有多个处理器单元。各个处理器之间共享总线，内存等等。 在操作系统看来，各个处理器之间没有区别。
    - 更新sysstat包：新版本中(11.5.5版本以后)才开始有 %iowait列，下载github上的最新版本，目前12.3.1
        + 链接：[github](https://github.com/sysstat/sysstat)
        + `yum remove sysstat`，然后解压后编译安装 `./configure; make; make install`

```sh
[➜ /home/xd/ ]$ mpstat -P ALL 3 #间隔3s，该虚拟机环境有两个逻辑CPU
Linux 3.10.0-957.el7.x86_64 (localhost.localdomain)     2019年11月25日     _x86_64_    (2 CPU)

13时56分13秒  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
13时56分16秒  all   48.71    0.00    0.00    0.00    0.00    0.17    0.00    0.00    0.00   51.11
13时56分16秒    0   91.17    0.00    0.00    0.00    0.00    0.35    0.00    0.00    0.00    8.48
13时56分16秒    1    8.31    0.00    0.33    0.00    0.00    0.33    0.00    0.00    0.00   91.03
```

* 含义
    - CPU CPU编号(all为平均)
    - %usr
        + 在用户态的CPU使用率
    - %nice
        + 在用户态以nice等级执行时的CPU使用率
            * nice/renice设置nice值为非0时，CPU跑在%nice等级上，看mpstat里%usr的使用率会比较小，大部分使用率在%nice列
            * nice默认0时，%nice列是0.00
    - %sys
        + 内核态的CPU使用率(注意不包含硬件和软件中断的时间)
    - %iowait
        + 系统有未完成的磁盘IO请求时，CPU闲置状态的时间百分比
    - %irq
        + CPU为服务硬件中断的时间百分比
    - %soft
        + CPU为服务软件中断的时间百分比
    - %steal
        + 管理程序为另一个虚拟处理器提供服务时，虚拟CPU非自愿等待所花费的时间百分比
    - %guest
        + CPU运行一个虚拟处理器花费的时间百分比
    - %gnice
        + CPU运行一个设置了nice的客户机花费的时间百分比
    - %idle
        + CPU处于空闲状态且系统没有未完成的磁盘I/O请求时的时间百分比

## pidstat

* pidstat
    - [pidstat 命令详解](https://www.jianshu.com/p/3991c0dba094)
    - 报告Linux任务的统计数据
    - `pidstat [ 选项 ] [ <时间间隔> ] [ <次数> ]`
    - 选项
        + `-p` 指定进程号
        + -u 默认，显示各个进程的cpu使用统计
            * `UID       PID   %usr %system  %guest   %wait    %CPU   CPU  Command`
            * UID:被监视任务的真实用户标识号;
            * %usr:用户态CPU使用率; %system:内核态CPU使用率; %guest:运行在虚拟机中的CPU使用率
            * %wait: 等待运行的CPU使用率; %CPU: 总的CPU使用率; CPU: CPU号
        + -d，显示各进程IO使用情况
            * `UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command`
            * 每秒从磁盘读取的KB、写入磁盘KB、任务取消的写入磁盘的KB(当任务截断脏的pagecache的时候会发生)、io延迟
        + -r，显示页面错误和内存使用情况
            * `UID       PID   minflt/s  majflt/s     VSZ     RSS   %MEM  Command`
            * minflt/s: 每秒 次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数
            * majflt/s: 每秒 主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时， 相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生
            * VSZ: 该进程使用的虚拟内存(以kB为单位)
            * RSS(常驻集大小): 该进程使用的物理内存(非交换物理内存，以kB为单位)
            * %MEM: 该进程使用内存的百分比
        + -w，显示每个进程的上下文切换情况
            * `UID       PID   cswch/s nvcswch/s  Command`
        + -t，显示选择任务的线程的统计信息外的额外信息
            * `UID      TGID       TID   cswch/s nvcswch/s  Command`
            * TGID:线程组leader的标识号;
            * TID:被监控的线程标识号
        + -l，显示命令名和所有参数(Command列会展示完整的执行命令)
            * e.g. Command列显示完整的`pidstat -l 2`，不加-l则只显示`pidstat`
    - pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。(**不加-t则不统计线程，注意**)

`pidstat 1`:

```
平均时间:   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
平均时间:     0      1485    0.00    0.50    0.00    0.00    0.50     -  pidstat
平均时间:   985      3176    0.00    0.50    0.00    0.00    0.50     -  testxd
平均时间:     0     10127    0.50    0.00    0.00    1.00    0.50     -  a.out
```

`pidstat -t 1`

```
平均时间:   UID      TGID       TID    %usr %system  %guest   %wait    %CPU   CPU  Command
平均时间:     0         -       883    0.00    0.11    0.00    0.33    0.11     -  |__kworker/1:2
平均时间:     0      1733         -    0.44    1.11    0.00    0.00    1.55     -  pidstat
平均时间:     0         -      1733    0.44    1.11    0.00    0.00    1.55     -  |__pidstat
平均时间:     0      3154         -    0.11    0.00    0.00    0.00    0.11     -  tuned
```

## vmstat

* vmstat
    - 报告虚拟内存的统计信息
    - vmstat  对系统的进程情况、内存使用情况、交换页和I/O块使用情况、中断以及CPU使用情况进行统计并报告相应的信息。
    - 需要特别关注的四列内容：
        + cs（context switch）是每秒上下文切换的次数
        + in（interrupt）则是每秒中断的次数
        + r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
        + b（Blocked）则是处于不可中断睡眠状态的进程数。
    - vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用 `pidstat` 了
        + 加上 -w 选项 `pidstat -w 2`
        + 两列内容是我们的重点关注对象
            * 一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数
                - **自愿上下文切换**，是指进程无法获取所需资源，导致的上下文切换。
                - 比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
            * 另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。
                - **非自愿上下文切换**，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。
                - 比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。
    - 选项
        + `-S`：使用指定单位显示。参数有 k 、K 、m 、M(分别代表1000、1024、1000000、1048576字节)。
            * 默认单位为K（1024 bytes）
            * `vmstat -S M 1` 或者 `vmstat -SM 1`，以单位MB显示

* `vmstat`结果示例:

```
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 9  0      0 672340   2116 561728    0    0     0     0 2742  266 99  1  0  0  0
 8  0      0 672204   2116 561736    0    0     0     0 2754  254 99  1  0  0  0
```

* `pidstat -w 2`结果示例：

```
15时28分58秒   UID       PID   cswch/s nvcswch/s  Command
15时29分00秒     0         9      4.48      0.00  rcu_sched
15时29分00秒     0        14      0.50      0.00  ksoftirqd/1
```

## dstat

* dstat
    - `yum info dstat` 查看dstat包的信息(CentOS)
        + dstat是vmstat、iostat、netstat和ifstat的通用替代品，dstat克服了它们的一些限制并添加了一些额外的特性。Dstat在性能调优测试、基准测试，或故障排除时监控系统非常方便。
    - [linux命令---dstat](https://blog.csdn.net/yue530tomtom/article/details/75443305)
        + `dstat` 是一个可以取代`vmstat`，`iostat`，`netstat`和`ifstat`这些命令的多功能产品。dstat扬长避短，即克服了这些命令的局限又增加了一些额外的功能，不但拥有更多的监控项，也更灵活。dstat在性能测试、基准测试和排除故障过程中可以很方便监控系统运行状况。 (比上面自己参照yum info信息配合有道翻译的好多了。。。)
    - `概述`
        + dstat可以查看所有的实时系统资源
        + dstat以列表的形式提供选项信息，并清晰地告知以何种幅度和单位显示输出。
            * 输出信息整洁，降低发生错误的概率。最重要的是，整洁的数据更容易编写插件用来收集分析关注的数据信息。
        + dstat默认输出是专门为实时查看而设计的
            * 然而也可以将详细信息通过cvs输出到一个文件，然后将cvs文件导入到Gnumeric或者Excel中生成图表。
    - `特性` (选取部分，具体查看上面的参考链接，或 `man dstat`)
        + 在分析和排障时可以通过启用监控项并排序
        + 使用python编写的，方便扩展现有的工作任务
            * `vi /usr/bin/dstat` 查看内容，可用看到是一个python内容的文件
            * 如果升级Python3.x后报错，把`# /usr/bin/python`修改为`# /usr/bin/python2.7`
        + 包含的许多扩展插件——增加新的监控项目很方便
        + 显示准确地单位和和限制转换误差范围
        + 不同的计量单位用不同的颜色显示
        + 显示中间结果延时小于1秒
        + 支持输出CSV格式报表，并能导入到Gnumeric和Excel以生成图形
    - 命令选项
        + `dstat`敲击时，默认开启了一些选项
            * 相当于 `dstat -cdngy` 和 `dstat -a`
        + `-c` 或 `--cpu`， 开启CPU统计
            * `-C` 指定CPU，和`-c`同时用时才生效(dstat -a包含-c)，可指定多个：`dstat -c -C 0,1`
            * 展示结果的第一行可以看出是哪个CPU，e.g. `-------cpu0-usage------`
        + `-d` 或 `--disk`，开启磁盘统计,e.g. `dstat -d -D /dev/sda`
            * `-D` 指定磁盘，和`-c`同时用时才生效(-a包含-d)
            * 展示结果第一行可以看出是哪个磁盘，e.g. `--dsk/sda--`
        + `-n` 或 `--net`， 开启net统计，包括接受和发送
            * `-N` 指定网络设备
        + `-g` 或 `--page`，开启分页统计
        + `-y` 或 `--sys`， 开启系统统计，包括中断和上下文切换
        + 还有一些其他常用项
            * `-i` 中断
                - `dstat -ai` 加一列中断展示项，展示中断类型15、19、21，可以查看/proc/interrupts中这几项的变化
                - `watch -d -n1 "cat /proc/interrupts"` 其中展示的是总数，dstat中展示变化值
            * `-l` 平均负载
                - `1m   5m  15m`
            * `-m` 内存统计
                - `used  buff  cach  free`
            * `-t` 或 `--time`，启用时间和日期输出
            * `-f` 或 `--full` 相当于`-C, -D, -I, -N and -S` 列出各子项(如列出多个CPU、多个磁盘、网卡)
        + 综合其他工具的项
            * `--socket` 开启sockets统计，包括 (total, tcp, udp, raw, ip-fragments)
            * `--tcp` 开启tcp统计，包括(listen, established, syn, time_wait, close)
                - `--udp` 开启udp统计 (listen, active)
                - `--unix` 开启unix统计(datagram, stream, listen, active)
            * `--fs` 开启文件系统统计，包括 (open files, inodes)
            * `--lock` 开启文件锁统计，包括 (posix, flock, read, write)
            * `--ipc` 开启进程间通信ipc统计，包括 (message queue, semaphores, shared memory)
        + `dstat --list` 列举支持的内置插件扩展的名称
            * dstat附带大量的插件
                - 显示某一时间磁盘的忙碌状况 `--disk-util`
                - 显示当前磁盘空间使用率 `--freespace`
                - 显示CPU占用最大的进程 `--top-cpu`
                - 显示正常I/O最大的进程 `--top-io`
                - 显示占用最多内存的进程 `--top-mem`
            * 组合使用
                - 内存资源使用情况：`dstat -glms --top-mem`
                - CPU资源使用情况：`dstat -cyl --proc-count --top-cpu`
            * `--output file` 输出结果到cvs文件中(终端上打印的同时输出到文件)

`dstat`结果:

```
----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw
  3   0  97   0   0   0|  26k   19k|   0     0 |   4B    5B| 409   365
 47   0  53   0   0   0|   0     0 | 244B  882B|   0     0 |1617   435
 47   0  53   0   0   1|   0     0 | 884B 4482B|   0     0 |1621   439
```

## sar

* sar
    - System Activity Reporter, 系统活动情况报告

## ps 各项释义

* ps选项
    - 接受三种风格的选项(不同类型的选项可以自由混合，但是可能会出现冲突)
        + UNIX options，前面必须有一个破折号"-" (dash)
        + BSD options，不能使用破折号
        + GNU long options，前面有两个破折号"--"
    - 注意`ps -aux` 和 `ps aux` 是不同的
        + POSIX and UNIX标准里，`ps -aux`表示打印用户"x"的所有进程，如果"x"不存在则可能解释为`ps aux`，表现是不固定的所以不应该依赖这种方式
    - 自己平常习惯UNIX风格`ps -fe` (相对aux少了进程状态、但是多了PPID)
        + `-e`, Select all processes. Identical to -A，选择所有进程，和-A相同
        + `-f`, 全格式化列表
        + `-o`, 用户自定义输出格式，如：`ps -eo pid,state,tname,time,command`
    - `-T` 显示线程(`SPID`列)
    - 使用`ps aux` (BSD风格，注意不能使用破折号)
        + `ps aux`多显示一个进程状态和会话相关的状态，很有价值。参考：[Linux性能优化实践笔记](https://github.com/xiaodongQ/devNoteBackup/blob/master/%E5%90%84%E8%AF%AD%E8%A8%80%E8%AE%B0%E5%BD%95/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.md)，笔记中搜索关键字："系统中出现大量不可中断进程和僵尸进程怎么办"
        + 关于`会话`，本笔记里有记录，搜索关键字：`防止关闭终端进程退出` 或 `SIGHUP`
        + 执行结果 `ps aux`
            * `USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND`
            * `root         1  0.0  0.2 125856  4428 ?        Ss   12月23   0:25 /usr/lib/systemd/syst`
        + 部分项释义
            * STAT 进程状态，参考下面的man中含义
                - `S`表示进程状态，后面的`s`表示这个进程是一个会话的领导进程
                - BSD风格才会展示，"对于BSD格式，当使用stat关键字时，可能会显示其他字符"
                    + `<` 高优先级(优先于其他用户)
                    + `N` 低优先级(优先级低于其他用户)
                    + `L` 有页锁定到内存中(用于实时和自定义IO)
                    + `s` 是一个会话的领导进程
                    + `l` 是多线程的
                    + `+` 前台进程组
    - 一般来说，ps 的输出中，名字括在中括号里的，一般都是内核线程
        + e.g. `ps -fe|grep ksoftirqd`(软中断线程)，结果为：`root         3     2  0 12月25 ?      00:00:02 [ksoftirqd/0]`

```sh
[➜ /home/xd/ ]$ ps -lp9467
F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
1 R  1000  9467  9466 99  80   0 -  1827 -      pts/4    00:36:24 stress
```

* 含义
    - 查看man手册
    - F(PROCESS FLAGS): flags associated with the process，进程相关的标志
        + `1    forked but didn't exec` fork但不执行
        + `4    used super-user privileges` 使用超级用户权限
    - S(PROCESS STATE CODES): 进程状态
        + R    running or runnable (on run queue)，运行或者可运行状态
        + D    (Disk Sleep)uninterruptible sleep (usually IO)，不可中断睡眠状态(一般在跟硬件交互，最常见的是等待硬件设备的 I/O 响应)
        + S    interruptible sleep (waiting for an event to complete)，可中断的的sleep
        + Z    defunct ("zombie") process, terminated but not reaped by its parent，僵尸进程
        + T    stopped by job control signal，任务控制信号中止
        + t    stopped by debugger during the tracing
        + X    dead (should never be seen)，进程消亡，不会看到进程的该状态
        + W    paging (not valid since the 2.6.xx kernel)，2.6内核版本之后无效
    - UID 进程号
    - PPID 父进程号
    - C(pcpu) CPU使用率
    - PRI
        + 进程优先级，值越*小*优先级越*高*
        + 一般启动进程的PRI为 20
    - NI 进程nice值
        + 表示进程可被执行的优先级的修正数值
        + PRI值越小越快被执行，那么加入nice值后，将会使得PRI变为：`PRI(new)=PRI(old)+nice` (即通过nice/renice修改nice会改变PRI)
        + 当nice值为负值的时候，那么该程序新PRI值将变小，即其优先级会变高，则其越快被执行
        + 进程的nice值不是进程的优先级，它们不是一个概念，但是进程nice值会影响到进程的优先级变化
    - ADDR
    - SZ
        + size in physical pages of the core image of the process，映射到内存中的页面, 这些页面仅由进程单独使用，进程实际占用的内存数
        + VSZ
            * virtual memory size of the process in KiB (1024-byte units), 进程的虚拟内存大小(KB)
        + RSS
            * resident set size, the non-swapped physical memory that a task has used (in kiloBytes), 常驻集大小，任务使用的非交换物理内存(KB)
            * This is usually at least 20 KiB of memory that is always resident，通常有20KB常驻内存
    - WCHAN
        + address of the kernel function where the process is sleeping 进程正在休眠的内核函数的地址，运行中的进程将显示'-'
    - TTY
        + tty ==> 泛指所有终端(Terminal)
        + 它是 Teletype(或者TeletypeWriter)的缩写，中文翻译：电传打字机
    - TIME
        + accumulated cpu time, user + system，累计cpu时间，用户+系统
    - 另外还有
        + PGID 进程组ID(也是进程组领导进程的进程号)
        + SID  会话ID(也是会话的领导进程的进程号)
        + TPGID 控制终端进程组ID(当前前台进程组的ID)
        + 进程、进程组、会话的关系参考本笔记中的` 会话`

* 修改进程优先级的命令主要有两个：`nice`, `renice`
    - [linux进程优先级、进程nice值](https://blog.csdn.net/codestinity/article/details/7496962)
    - `nice` 改变程序执行的优先权等级
        + 语法：`nice [-n <优先等级>][--help][--version][执行指令]`
            * -n 设置欲执行的指令的优先权等级，等级的范围从[-20, 19]，其中-20最高，19最低 (即值越小，进程优先级越高)
    - `renice` renice指令可重新调整程序执行的优先权等级。
        + e.g. `renice -5 -p 5200`, 将5200进程的nice设置为-5
    - 也可以在`top`中，输入`r`，对指定PID进行nice的调整设置

* 僵尸进程
    - 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。
    - 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为**僵尸进程**。
    - 危害：如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。
* 孤儿进程
    - 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
    - 孤儿进程不会导致资源浪费

## top

* 释义
    - `us`, user: 未设置nice的用户进程运行占用的CPU时间百分比
    - `sy`, system: 内核进程运行占用CPU时间百分比
    - `ni`, nice: 设置了nice的用户进程运行占用的CPU时间百分比
    - `wa`, IO-wait: 等待I/O完成占用的CPU时间百分比
    - `hi` 服务硬件中断占用的CPU时间百分比
    - `hi` 服务软件中断占用的CPU时间百分比
    - `st` 虚拟机窃取的CPU时间百分比

```sh
# 按下数字 1 切换到所有 CPU 的使用情况，观察一会儿按 Ctrl+C 结束
$ top
top - 05:56:23 up 17 days, 16:45,  2 users,  load average: 2.00, 1.68, 1.39
Tasks: 247 total,   1 running,  79 sleeping,   0 stopped, 115 zombie
%Cpu0  :  0.0 us,  0.7 sy,  0.0 ni, 38.9 id, 60.5 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  0.0 us,  0.7 sy,  0.0 ni,  4.7 id, 94.6 wa,  0.0 hi,  0.0 si,  0.0 st
...

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 4340 root      20   0   44676   4048   3432 R   0.3  0.0   0:00.05 top
 4345 root      20   0   37280  33624    860 D   0.3  0.0   0:00.01 app
 4344 root      20   0   37280  33624    860 D   0.3  0.4   0:00.01 app
    1 root      20   0  160072   9416   6752 S   0.0  0.1   0:38.59 systemd
...
```

## htop

[htop使用详解](https://www.cnblogs.com/yqsun/p/5396363.html)

官网安装：https://sourceforge.net/projects/htop/ , 下载tar.gz文件解压，./configure; make; make install

* 比较
    - 两者相比起来，top比较繁琐
    - 默认支持图形界面的鼠标操作
    - 可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行
    - 杀进程时不需要输入进程号等

* htop每列内容与top差不多，多了不少便捷的操作
    - 可以通过鼠标进行点击操作，最下方栏列出了F1~F10，都可以通过鼠标点击，当然也可以按键盘按键
    - `S` (或`F2`) 进行一些htop的设置，里面可以用鼠标操作(按快捷键会自动修改里面的配置)
        + Meters (htop顶端的显示项)
            * 分左右两边, 从Available meters中选择，F5添加到左边，F6添加到右边(最下面有操作提示信息)
            * 在对应的选项上按回车，可以选择该项展示的方式: LED会模拟液晶屏显示/Bar显示进度条/Text文本
            * 本设置：添加hostname(文本), Clock(文本，显示时间)
        + Display options (显示选项)
            * 可以设置线程是否展示、线程名称是否展示等(可以勾选显示线程名)
            * 本设置：取消用户线程隐藏、不同颜色显示线程、显示线程名、高亮程序基本名称
        + Colors 设置显示颜色，默认颜色挺舒服的
        + Columns 选择主面板要展示的列，默认的列是跟top保持一致的，可以定制选择加一些列
            * 本设置：添加读和写io、忽略信号
        + **设置是本用户生效**
    - `/` (或`F3`) 可搜索进程名，光标会跳到进程位置
    - `\` (或`F4`) 过滤进程，和F3类似，不过过滤后只显示该进程
        + 退出该模式则再次按下`\` (可以看到输入还是上次的关键字)，需要再Esc退出(此时回车只会退出本次输入)
    - `t` (或`F5`) 显示树形结构
    - `k` (或`F9`) 对进程传递信号，按下后左边会多出一个信号列表视图(右边视图停留在选择的进程)，可用鼠标或上下键选择要传递的信号
    - `q` (或`F10`) 退出htop
    - `u` 选择展示列表中某个用户的进程，要退出则再按u后选所有用户
    - `H` 显示或隐藏用户线程，默认是显示(默认显示进程名，可以设置显示线程名，**不过`\`过滤时就只能过滤显示进程名，线程名不一样则显示不了**，可以配合ps -Tp或者top -Hp找到对应线程号，再到htop中查看跟踪)
    - `M`/`P`/`T` 按内存/CPU/TIME+ 排序，用`I` 来倒转排序顺序
    - `s` 对选择的进程来用`strace`追踪
* 对于指定进程的监测，并不能 `top -Hp xxx`指定显示进程下的所有线程(-p会指定某一个线程号)

## 防止关闭终端进程退出(SIGHUP)

* 关闭是由于 SIGHUP 信号
    - [解决Linux关闭终端（关闭SSH等）后运行的程序或者服务自动停止【后台运行程序】](https://www.cnblogs.com/bohaoist/p/4965103.html)

* 一些概念(以及进程、进程组、会话的关系):
    - 参考：[前台进程组、孤儿进程组、会话、控制终端](https://blog.csdn.net/hmsiwtv/article/details/7901711)
        + `PGID` 进程组ID(也是进程组领导进程的进程号)
        + `SID`  会话ID(也是会话的领导进程的进程号)
        + `TPGID` 控制终端进程组ID(当前前台进程组的ID)
    - `控制终端（controlling terminal）`
        + 会话可以有一个单独的控制终端
        + `控制进程`（controlling process）
            * 与控制终端连接的会话首进程叫做控制进程
    - `会话（session）`
        + 一个或多个进程组的集合，有唯一一个`会话首进程`（session leader）。
        + 一般由一个`会话首进程`、一个`前台进程组`、一个`后台进程组`组成。
        + 会话ID为首进程的ID(PID)
        + `会话首进程`
            * 新建会话时，会话中的唯一进程，其PID=SID
    - `进程组（process group）`：
        + 一个或多个进程的集合，进程组属于一个`会话`
            * fork()并不改变进程组ID
            * 每一个进程组有唯一一个进程组ID，即`进程组长`的进程ID。
        + `进程组组长`
            * `PID`与`PGID`相等的进程。
            * 组长可以改变子进程的进程组ID，使其转移到另一进程组。
            * e.g. 一个shell进程（以自己环境里的`zsh`为例，原链接中是`bash`，若演示环境是bash则找进程名`bash`即可），当使用管道线时，如`echo "hello" | cat`，zsh以第一个命令的进程ID为该管道线内所有进程设置进程组ID。此时`echo`和`cat`的进程组ID都设置成echo的进程ID
                - 执行`echo "hello" | cat`时，`ps`监测不到对应的进程，可以使用`execsnoop`监测短时进程，参考笔记中查找`execsnoop`：[Linux性能优化实践.md](https://github.com/xiaodongQ/devNoteBackup/blob/master/%E5%90%84%E8%AF%AD%E8%A8%80%E8%AE%B0%E5%BD%95/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.md)
                - 通过`execsnoop`还发现了zsh终端每次执行命令时还获取了一些git相关的状态信息用于展示(zsh的git插件)
                - 根据结果中`cat`执行的父进程PID，可以看到其进程名为`-zsh`，`ps aux`显示进程`STAT`为：`Ss`，`s`表示一个会话的领导进程。追踪父进程最终能找到`systemd(进程号为1)`
        + `前台进程组`
            * 当前与终端交互的进程称为前台进程组。 该进程组中的进程能够向终端设备进行`读、写`操作的进程组。
            * 前台进程组的进程其 `TPGID = PGID`，常常可以通过比较它们来判断前后台进程组。
        + `后台进程组`
            * 一个会话中，除前台进程组、会话首进程以外的所有进程组。
            * 该进程组中的进程能够向终端设备`写`，*但是当试图`读`终端设备时，将会收到SIGTTIN信号*，并停止。
            * 前台进程组ID只能有一个，而后台进程组同时可存在多个。
            * 后台进程组的PGID≠TPGID。

* 挂断信号（SIGHUP）
    - 挂断信号（SIGHUP）默认的动作是终止程序
    - 当终端接口检测到网络连接断开，会将挂断信号发送给控制进程（会话首进程）
    - 如果会话首进程终止，则该信号发送到该会话*前台进程组*

* 关闭shell终端不终止进程
    - 使用后台运行命令&，并不能摆脱ssh进程组控制，还是会发送 SIGHUP 使进程组关闭
    - 为了能够再注销以后 依然能后台运行，可以使用`nohup`命令，忽略所有挂断（SIGHUP）信号
    - `nohup ./server > /dev/null 2>&1 &`, 不关心输出则重定向到/dev/null，不指定输出位置会自动生成nohup.out
    - nohup忽略之后，关闭终端后，原终端运行进程的父进程即kill了，会变成孤儿进程，由init进程(进程号1)接收

获取正在执行的shell自身进程号：`$$`

看门狗脚本检查：

```sh
#!/bin/bash
# monitor_server.sh, 执行时为防止关闭终端受NOHUP影响，使用 "nohup ./monitor_server.sh > /dev/null 2>&1 &" 运行

server=testServer

start_server()
{
    serverpid=`ps -fe|grep testServer | grep -v gdb|grep -v grep |awk '{print $2}'`
    kill -9 $(serverpid)
    ./testServer &
}

monitornum=`ps -fe|grep "monitor_server.sh"| grep -v vi|grep -v grep |grep -v $$ |awk '{print $2}'|wc -l`
if [ $monitornum -gt 0 ]; then
    date | tee -a run.log
    echo "already exist monitor, exit" | tee -a run.log
    exit 1
fi

while true
do
    num=`ps -fe|grep testServer | grep -v gdb|grep -v grep |awk '{print $2}'|wc -l`
    if [ $num -eq 0 ]; then
        start_server
        date | tee -a run.log
        echo "restart $(server)" | tee -a run.log
    fi
    sleep 5
done
```

## pstack & gstack

* pstack
    - `which pstack` 路径为 /usr/bin/pstack
    - `ll /usr/bin/pstack`，得到 `lrwxrwxrwx. 1 root root 6 8月  22 20:26 /usr/bin/pstack -> gstack`，可知pstack实际是指向gstack的软链接

* gstack
    - `which gstack` 路径为 /usr/bin/gstack
    - `vim /usr/bin/gstack` 打开gstack，可以看到它实际是一个脚本，其包装了gdb bt，并用sed对gdb bt的输出结果做了过滤而已

## pstree

* pstree
    - `pstree 选项 [pid, user]`
        + 可以接pid只显示该pid信息 或 接user只显示该用户信息
    - 以树状图的方式展现进程之间的派生关系，显示效果比较直观。
    - `pstree -cpus pid` 不精简显示(c)、显示进程号(p)、显示用户(u)、显示父进程树(s)
    - 选项
        + `-a`：显示每个程序的完整指令，包含路径，参数或是常驻服务的标示；
        + `-c`：不使用精简标示法；(默认会精简显示，多个相同的进程名会显示为`2*[sshd───zsh]`形式)
        + `-h`：列出树状图时，特别标明`现在执行`的程序；
        + `-H PID` 高亮指定进程号和其祖先(和-h不能同时用)
        + `-n` 输出时按`PID`排序
            * `-N type` 指定以什么类型来排序(ipc, mnt, net, pid, user, uts)
        + `-p` 显示进程号
        + `-u` 显示用户名(uid)
        + `-s` 显示父进程(当指定pid时可以一并把父进程树显示出来)
        + `pstree 用户` 显示基于指定用户的进程树

## last 命令

* last
    - last命令用于显示最近登录的用户列表
    - last向后检索/var/log/wtmp文件(也可-f指定检索文件)，并显示自这个文件创建以来所有登录（退出）系统的用户列表。
    - 选项
        + `-a` 在最后一列显示主机名(不-a时主机名也会显示，显示在别的列而不是最后一列，-R指定不显示该列)
        + `-i` 显示远程主机(即非本机)的IP地址
        + `-d` 显示远程主机(即非本机)的主机名
        + `-x` 显示系统关机记录和运行级别改变
            * 相比没有-x会多显示运行级别改变的日志。
            * 开机之后，runlevel会变，可以此判断开机；关机则可根据关键词reboot过滤，或者直接 `last reboot`也可
        + 命名后面空格+用户名，可以只显示指定用户的登录退出记录 e.g. `last xd -ai`
            * `last reboot` 每次系统重新**启动**时，*虚用户:reboot*都会被记录到日志中。所以`last reboot`会列出自日志文件创建以来的所有重新启动的日志记录。

`last -axi`执行结果截取：

```sh
root     pts/2        Mon Dec  9 09:01   still logged in    192.168.50.204
root     pts/1        Mon Dec  9 09:00 - 12:27  (03:26)     192.168.50.234
# 运行级别修改，此处系统启动后进入图形GUI模式(runlevel 5)
runlevel (to lvl 5)   Mon Dec  9 08:59 - 14:57  (05:58)     0.0.0.0
root     pts/0        Mon Dec  9 08:59 - 13:45  (04:46)     192.168.50.234
# 系统启动，虚用户reboot被记录(没有关闭机器的记录是因为直接操作机器电源关闭的，而不是reboot)
reboot   system boot  Mon Dec  9 08:58 - 14:57  (05:59)     0.0.0.0
root     pts/2        Fri Dec  6 18:50 - 02:04  (07:13)     192.168.50.204
root     pts/1        Fri Dec  6 18:50 - 02:03  (07:13)     192.168.50.204
# 系统启动
runlevel (to lvl 5)   Fri Dec  6 18:48 - 08:59 (2+14:11)    0.0.0.0
root     pts/0        Fri Dec  6 18:48 - 02:03  (07:15)     192.168.50.204
# 系统启动
reboot   system boot  Fri Dec  6 18:47 - 14:57 (2+20:10)    0.0.0.0
# 系统关闭，此处手动敲了reboot
shutdown system down  Fri Dec  6 18:47 - 18:47  (00:00)     0.0.0.0
root     pts/7        Fri Dec  6 16:20 - down   (02:26)     192.168.50.234
root     pts/3        Fri Dec  6 15:48 - down   (02:58)     192.168.50.204
```

## 运行级别

* Linux系统的7个运行级别(runlevel)
    - 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动
    - 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆
    - 运行级别2：多用户状态(没有NFS)
    - 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式
    - 运行级别4：系统未使用，保留
    - 运行级别5：X11控制台，登陆后进入图形GUI模式
    - 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动
* 命令模式启动
    - 方法一：修改`/etc/default/grub`文件，选项改成`GRUB_CMDLINE_LINUX="text"`
        + 然后`update-grub`基于这些更改重新生成/boot下的GRUB2配置文件
        + 重启则可进入命令行模式
        + [将ubuntu由图形模式启动更改为命令行启动](https://www.cnblogs.com/asulove/p/6038826.html)
    - 方法二：
        + `systemctl set-default multi-user.target`
        + `systemctl get-default` 可查看运行级别
            * 图形界面是 graphical.target
            * 要恢复到桌面则 `systemctl set-default graphical.target`
        + [Ubuntu开机时直接进入命令行模式](https://blog.csdn.net/nima1994/article/details/79564622?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1&utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1)
* `/etc/rc.d/init.d`
    - `/etc/rc.d/init.d`下有许多服务器脚本程序，一般称为服务(service)
    - `/etc/init.d` 是指向 `/etc/rc.d/init.d`的软链接
    - 在/etc/rc.d下有7个名为rcN.d的目录(N为0-7)，对应系统的7个运行级别
        + rcN.d目录下都是一些符号链接文件，这些链接文件都指向init.d目录下的service脚本文件
        + 命名规则为K+nn+服务名或S+nn+服务名，其中nn为两位数字，e.g. `K90network -> ../init.d/network`
            * 对于以K开头的文件，系统将终止对应的服务
            * 对于以S开头的文件，系统将启动对应的服务
        + 系统会根据指定的运行级别进入对应的rcN.d目录，并按照文件名顺序检索目录下的链接文件
    - 查看运行级别用：`runlevel`
        + e.g. 本地CentOS虚拟机执行结果：`N 3`，命令行模式
    - 进入其它运行级别用：`init N`
        + `init 0`为关机，`init 6`为重启系统(默认运行级别不能设为6，否则不能正常启动)
        + 现在的Linux系统安装完后就运行在第5个级别，即系统启动后直接进入图形界面，而不用在字符模式下登录后用startx或者xinit 来起动图形界面。
        + 默认运行等级设置：`/etc/inittab`，使用systemd后不再使用该配置文件
            * `systemctl get-default` 查看
            * `systemctl set-default TARGET.target` 设置
        + 在任何运行级别，用户都可用init 命令来切换到其他运行级别(若不重启切换到图形界面，则`init 5`)


## crontab

linux系统由 cron (crond) 这个系守护进程服务来控制循环运行的例行性计划任务

crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。

* Linux下的任务调度分为两类，系统任务调度和用户任务调度。
    - 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。
    - 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。

* crontab
    - `-l` 显示当前crontab
    - `-r` 移除, `-i`去掉移除时的提示
    - `-e` 编辑

* cron 的主配置文件是 /etc/crontab
* 当我们要增加全局性的计划任务时，一种方式是直接修改/etc/crontab。但是，一般不建议这样做，/etc/cron.d目录就是为了解决这种问题而创建的。
    - 增加一项定时的备份任务，我们可以这样处理：在/etc/cron.d目录下新建文件backup.sh
    - cron进程执行时，就会自动扫描该目录下的所有文件，按照文件中的时间设定执行后面的命令。
    - cron执行时，也就是要读取三个地方的配置文件：一是`/etc/crontab`，二是`/etc/cron.d`目录下的所有文件，三是每个用户的配置文件
* 日志
    - linux(计划任务执行记录): /var/log/cron.log
    - mail任务(如果计划任务执行出错，mail中的信息比较详细): /var/spool/mail/root 或者 /var/mail/root(用户名)
        + `/var/mail` 是 指向 `/var/spool/mail`目录 的软链接
* crontab -e报找不到vi问题
    - 可以在.bashrc中设置环境变量`VISUAL`或者`EDITOR`为vi的路径，注意需要绝对路径，e.g. `export EDITOR=/usr/local/bin/vim`
    - `EDITOR`历史上用于更早期的编辑器，`VISUAL`用于比较高级的编辑器(如vi/emacs)，不过目前两者是兼容的，如果在bash终端调用一个编辑器，bash先会找`VISUAL`指定的编辑器，如果失败则会找`EDITOR`指定的编辑器
    - 参考：[VISUAL vs. EDITOR – what’s the difference?](https://unix.stackexchange.com/questions/4859/visual-vs-editor-what-s-the-difference)

/etc/crontab文件：

```sh
# 前四行是用来配置crond任务运行的环境变量
# 第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root

# For details see man 4 crontabs

# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name  command to be executed
```

在以上各个字段中，还可以使用以下特殊字符：

- 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。
- 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”
- 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”
- 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。

对于命名：如果是自己新建的crontab文件，命名成 "crontab", "crontab.xd"，用vim打开都能显示语法高亮;
而"crontab_xd", "xd_crontab", "crontab_xd.xd"则不行。 使用crontab.用户名方式命名

### 环境变量问题

不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点：

1）脚本中涉及文件路径时写全局路径；

2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如：

```sh
cat start_cbp.sh

#!/bin/sh
source /etc/profile
export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf
/usr/local/jboss-4.0.5/bin/run.sh -c mev &
```

3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如：

```
0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh
```

### 部分用法示例：

更多实例查看上面的链接

* 每隔两分钟执行

  `*/2 * * * * cmd`

* 每小时的奇数分钟执行，（0不执行，1执行）

  `1-59/2 * * * * cmd`

* 每天18:00至23:00间每隔30分钟

  `0,30 18-23 * * * cmd`

  `0-59/30 18-23 * * * cmd`

> * `A,B,C` A或B或C
* `A-B` A到B之间
* `*/A` 每A分钟（小时等）

* 两小时运行一次，注意分钟要设置值

  `* */2 * * * cmd （错误）`
  `0 */2 * * * cmd （正确）`


## SMTP

## DNS

[DNS详解: A记录,子域名,CNAME别名,PTR,MX,TXT,SRV,TTL](https://yq.aliyun.com/articles/611293)

A记录 A (Address) 记录是用来指定主机名（或域名）对应的IP地址记录。

## netstat

* netstat
    - `netstat -anp`
    - `netstat -nptul` 所有监听的连接
        + `-t` [--tcp|-t]
        + `-u` [--udp|-u]
        + `-l` [--listening|-l] 只显示正在侦听的套接字
        + `-p` [--program|-p]   显示套接字所属进程的PID和名称
        + `-n` [--numeric|-n]   显示数字形式地址而不是去解析主机、端口或用户名。
            * 前面描述`ps`时写过选项的风格
                - UNIX options，前面必须有一个破折号"-"
                - BSD options，不能使用破折号
                - GNU long options，前面有两个破折号"--"

## arping

* 查看mac冲突，同网段找台非自身设备发送arp，查看应答mac有几个: `arping -I enp2s0 192.168.50.207`
  - arping命令是以广播地址发送arp packets，以太网内所有的主机都会收到这个arp packets，但是本机收到之后不会Reply任何信息


## 负载均衡

LB集群是load balance 集群的简写，负载均衡集群
LVS是一个实现负载均衡集群的开源软件项目
LVS架构从逻辑上可分为调度层(Director)、server集群层(Real server)和共享存储层


golang consul-grpc服务注册与发现

## Linux安装

### Ubuntu安装(虚拟机里安装)

* 安装包下载
    - [中科大镜像站](http://mirrors.ustc.edu.cn/ubuntu-releases/) 速度挺快的
    - 选择下载了：`ubuntu-19.10-live-server-amd64.iso` (非desktop版本)
* 镜像源
    - 系统安装时需要下载一些包，设置镜像源改成清华镜像源：`https://mirrors.tuna.tsinghua.edu.cn/ubuntu/`
        + 默认的镜像源实在太慢了，试了好多次下载一直卡着重试。直接在默认的位置删除后输入上面的镜像源地址即可
        + 其实清华镜像源上也有安装包，`https://mirrors.tuna.tsinghua.edu.cn/ubuntu-releases/`，之前网上搜索时别的链接可以下载，就下载了
        + 参考：[Linux---Ubuntu19.10安装教程](https://blog.csdn.net/caigen0001/article/details/102738874)
* 开启允许root连接ssh
    - `vi /etc/ssh/sshd_config`，把`PermitRootLogin`项的值改为yes后重启sshd(注意是`sshd_config`，而不是`ssh_config`配置文件)
    - [linux下开启SSH，并且允许root用户远程登录,允许无密码登录](https://blog.csdn.net/jia0511/article/details/8237698)

### CentOS安装(Windows机器安装)

* [Centos7.6单系统安装 - 替换 windows10](https://blog.csdn.net/pptsv7/article/details/84900377)
  - 

## Linux Kernel

* 下载源码
    - [linux内核源码下载地址](http://ftp.sjtu.edu.cn/sites/ftp.kernel.org/pub/linux/kernel/)
        + http://ftp.sjtu.edu.cn/sites/ftp.kernel.org/pub/linux/kernel/
    - tar.xz类型解压，分两步
        + `xz -d xxx.xz` 得到.tar文件
        + `tar -xvf xxx.tar` 解压

## 火焰图(Flame Graph)

* 火焰图
    - 参考：[Linux下用火焰图进行性能分析](https://blog.csdn.net/gatieme/article/details/78885908)
        + 其中红/蓝差分火焰图原文来自"Brendan Gregg"：[Differential Flame Graphs](http://www.brendangregg.com/blog/2014-11-09/differential-flame-graphs.html)
        + 关于"Brendan Gregg"：[Brendan Gregg: 一个实战派大神](https://book.douban.com/review/7894012/)
    - 常见的火焰图类型有 `On-CPU`, `Off-CPU`, 还有 Memory, Hot/Cold, Differential 等等.
    - 纵向表示调用栈的`深度`, 横向表示`消耗的时间`. 因为调用栈在横向会按照字母排序, 并且同样的调用栈会做合并, 所以一个格子的宽度越大越说明其`可能是瓶颈`
    - 什么时候使用 On-CPU 火焰图? 什么时候使用 Off-CPU 火焰图呢?
        + 取决于当前的瓶颈到底是什么, 如果是 CPU 则使用 On-CPU 火焰图, 如果是 IO 或锁则使用 Off-CPU 火焰图. 如果无法确定, 那么可以通过压测工具来确认 :
            * 通过压测工具看看能否让 CPU 使用率趋于饱和, 如果能那么使用 On-CPU 火焰图, 如果不管怎么压, CPU 使用率始终上不来, 那么多半说明程序被 IO 或锁卡住了, 此时适合使用 Off-CPU 火焰图.
            * 关于压测工具的选择, 如果选择 `ab` 的话, 那么务必记得开启 `-k`(允许KeepAlive) 选项, 以避免耗尽系统的可用端口.
            * 除了`ab`外，http压测工具还可以选择`wrk`/`locust`/`Jmeter`，`wrk`比`ab`功能更强大(使用了一些操作系统特定的高性能I/O机制, 比如 select, epoll, kqueue 等。其实它是复用了 redis 的 `ae 异步事件驱动框架`)
                - `wrk`可参考：[性能测试工具 wrk 安装与使用](https://www.cnblogs.com/savorboard/p/wrk.html)
        + 如果还是确认不了, 那么不妨 On-CPU 火焰图和 Off-CPU 火焰图都搞搞, 正常情况下它们的差异会比较大, 如果两张火焰图长得差不多, 那么通常认为 CPU 被其它进程抢占了.
    - 使用：
        + 获取GitHub：[brendangregg/FlameGraph](https://github.com/brendangregg/FlameGraph)
            * `git clone https://github.com/brendangregg/FlameGraph.git`
        + 生成和创建火焰图需要如下几个步骤
            * 捕获堆栈：使用 perf/systemtap/dtrace 等工具抓取程序的运行堆栈
                - `perf record -a -F 99 -p 3887 -g sleep 30` (-F每秒采集99次，-g记录调用栈，`-a`和`[-- ]sleep`搭配)
                    + 注意此处相比原链接中加了`-a`选项(全CPU全系统范围收集)，要不只会抓取到sleep的调用堆栈
                    + 可以用`perf report -n [--stdio]` 在终端查看(`-n`显示每个符号的样本数，`--stdio`使用stdio接口， 会展开显示结果)
            * 折叠堆栈：用上面的trace工具(perf/systemtap/dtrace等)抓取的系统和程序运行每一时刻的堆栈信息, 对他们进行分析组合, 将重复的堆栈累计在一起, 从而体现出负载和关键路径，使用FlameGraph 中的 `stackcollapse` 程序
                - `perf script -i perf.data > perf.unfold`，用`perf script`对`perf.data`进行解析(不用`-i`则默认会解析perf.data)
                    + `perf record` 生成的文件类型是`data`(二进制数据,`file perf.data`查看)，而`perf script`生成的文件类型是`ASCII text`
                - `./stackcollapse-perf.pl perf.unfold > perf.folded`，将perf解析出的内容 perf.unfold 中的符号进行折叠
            * 生成火焰图：分析 stackcollapse 输出的堆栈信息生成火焰图，使用`flamegraph.pl`
                - `./flamegraph.pl perf.folded > perf.svg`
                - 之后就可以用浏览器打开火焰图(.svg)进行分析了
        + 可以简化：`perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl > process.svg`
        + `SVG格式(Scalable Vector Graphics)`：可缩放的矢量图形，基于XML（Extensible Markup Language），由World Wide Web Consortium（W3C）联盟进行开发的。
            * 用来描述二维矢量及矢量/栅格图形。
            * SVG图形是可交互的和动态的，可以在SVG文件中嵌入动画元素或通过脚本来定义动画。
            * 用户可以设计高分辨率的Web图形页面，可以直接用代码来描绘图像，可以用任何文字处理工具打开SVG图像，通过改变部分代码来使图像具有交互功能，并可以随时插入到HTML中通过浏览器来观看。
            * 可以任意放大图形显示，但绝不会以牺牲图像质量为代价；
    - 分析：
        + 火焰图含义：火焰图是基于 `stack` 信息生成的 SVG 图片, 用来展示 CPU 的调用栈。
            * y 轴表示调用栈, 每一层都是一个函数. 调用栈越深, 火焰就越高, 顶部就是正在执行的函数, 下方都是它的父函数.
            * x 轴表示抽样数, 如果一个函数在 x 轴占据的宽度越宽, 就表示它被抽到的次数多, 即执行的时间长
                - *注意*, x 轴不代表时间, 而是所有的调用栈合并后, 按字母顺序排列的
            * 火焰图就是看顶层的哪个函数占据的宽度最大. 只要有 "平顶"(plateaus), 就表示该函数可能存在性能问题。
            * 颜色没有特殊含义, 因为火焰图表示的是 CPU 的繁忙程度, 所以一般选择暖色调
        + 互动性：火焰图是 SVG 图片, 可以与用户互动.
            * 鼠标悬浮：火焰的每一层都会标注函数名, 鼠标悬浮时会显示完整的函数名、抽样抽中的次数、占据总抽样次数的百分比。
            * 点击放大：在某一层点击，火焰图会水平放大，该层会占据所有宽度，显示详细信息。
            * 搜索：按下 `Ctrl+F` 会显示一个搜索框，用户可以输入关键词或正则表达式，所有符合条件的函数名会高亮显示.
                - 和浏览器自身的`Ctrl+F`不一样，颜色是svg中定义的，`Ctrl+i`可以切换是否取消大小写
    - 红/蓝差分火焰图
        + 对于修改程序前后的**性能回退问题**，使用`红/蓝差分火焰图(red/blue differential flame graphs)`快速找到根因。 如果在修改前后或者不同时期和场景下的火焰图之间, 不断切换对比来找出问题所在，这样会很繁琐。
        + `红/蓝差分火焰图`使用两种颜色来表示状态：
            * 红色表示增长
            * 蓝色表示衰减
        + 分析步骤如下：
            * 抓取修改前的堆栈 profile1 文件
                - `perf record -a -g -o perf1.data sleep 30` (注意需要`-a`)
                - `perf script -i perf1.data | stackcollapse-perf.pl > perfdiff1.folded`
            * 取修改后(或不同时期/场景)的堆栈 profile2 文件
                - `perf record -a -g -o perf2.data sleep 30`
                - `perf script -i perf2.data | stackcollapse-perf.pl > perfdiff2.folded`
            * 生成红蓝差分火焰图
                - a. `difffolded.pl -n perfdiff1.folded perfdiff2.folded | flamegraph.pl > diff.svg`
                    + `difffolded.pl` 只能对 "折叠" 过的堆栈 profile 文件进行操作
                    + "折叠操作"由`stackcollapse 系列`脚本完成
                - b. `difffolded.pl -n perfdiff2.folded perfdiff1.folded | flamegraph.pl --negate > diff2.svg`
                - 生成差分比较时，折叠文件的前后顺序不同是有影响的(上面的a和b)
                    + a: 宽度是以修改前profile文件为基准，颜色表明将要发生的情况
                    + b: 宽度是以修改后profile文件为基准，颜色表明已经发生的情况
                    + 功能验证测试时，可以同时生成这两张图进行对比


## Jupyter Notebook

* 学习背景
    - 学习C++11/14新特性时，有篇文章推荐了一个在线编写代码然后运行查看结果的工具(对于容器能直接查看成员列表内容，很方便直观)，进去试了一下保存了书签
        + C++工具在线链接Jupyter with C++：[jupyter xcpp](https://notebooks.gesis.org/binder/jupyter/user/jupyter-xeus-xeus-cling-wb7alqte/notebooks/notebooks/xcpp.ipynb)
    - 查Consul的博客文章时，看到博主主页博文中的notebook是基于Jupyter Notebook，看得Jupyter眼熟，回头搜了下果然是之前看过的，遂有了下面的进一步了解
        + [博主页面教程链接](http://www.liangxiansen.cn/Python/)
* [Jupyter Notebook介绍、安装及使用教程](https://www.jianshu.com/p/91365f343585)
    - [官网](https://jupyter.org/try)
    - Jupyter Notebook是基于网页的用于交互计算的应用程序。其可被应用于全过程计算：开发、文档编写、运行代码和展示结果。

## 开源协议

* [开源许可证教程](http://www.ruanyifeng.com/blog/2017/10/open-source-license-tutorial.html)
    - 根据使用条件的不同，开源许可证分成两大类。
    - 宽松式许可证
        + 宽松式许可证（permissive license）是最基本的类型，对用户几乎没有限制。用户可以修改代码后闭源。
        + 常见的宽松式许可证有四种。
            * BSD（二条款版） 分发软件时，必须保留原始的许可证声明
            * BSD（三条款版） 分发软件时，必须保留原始的许可证声明。不得使用原始作者的名字为软件促销
            * MIT 分发软件时，必须保留原始的许可证声明，与 BSD（二条款版）基本一致
            * Apache 2, 分发软件时，必须保留原始的许可证声明。凡是修改过的文件，必须向用户说明该文件修改过；没有修改过的文件，必须保持许可证不变。
    - Copyleft 许可证
        + Copyleft 是理查德·斯托曼发明的一个词，作为 Copyright （版权）的反义词。Copyright 直译是"复制权"，这是版权制度的核心，意为不经许可，用户无权复制。作为反义词，Copyleft 的含义是不经许可，用户可以随意复制。
        + 但是，它带有前提条件，比宽松式许可证的限制要多。
            * 如果分发二进制格式，必须提供源码
            * 修改后的源码，必须与修改前保持许可证一致
            * 不得在原始许可证以外，附加其他限制
        + 上面三个条件的核心就是：修改后的 Copyleft 代码不得闭源
        + 常见的 Copyleft 许可证也有四种（对用户的限制从最强到最弱排序）
            * Affero GPL (AGPL) 如果云服务（即 SAAS）用到的代码是该许可证，那么云服务的代码也必须开源
            * GPL 如果项目包含了 GPL 许可证的代码，那么整个项目都必须使用 GPL 许可证
            * LGPL 如果项目采用动态链接调用该许可证的库，项目可以不用开源
            * Mozilla（MPL） 只要该许可证的代码在单独的文件中，新增的其他文件可以不用开源
* [如何选择开源许可证？](http://www.ruanyifeng.com/blog/2011/05/how_to_choose_free_software_licenses.html)
* [一张图看懂开源许可协议](https://blog.csdn.net/testcs_dn/article/details/38496107)
* BSD开源协议 (Berkeley Software Distribution, 伯克利软件发行版)
    - BSD开源协议是一个给于使用者很大自由的协议。基本上使用者可以”为所欲为”,可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。
    - 当你发布使用了BSD协议的代码，或则以BSD协议代码为基础做二次开发自己的产品时，`需要满足三个条件`：
        + 如果再发布的产品中包含`源代码`，则在源代码中必须带有原来代码中的BSD协议。
        + 如果再发布的只是`二进制类库/软件`，则需要在类库/软件的文档和版权声明中`包含原来`代码中的BSD协议。
        + `不可以`用开源代码的作者/机构名字和原来产品的名字做`市场推广`
    - BSD 代码鼓励代码共享，但需要尊重代码作者的著作权。BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销售，因此是`对商业集成很友好`的协议。
    - 而很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者二次开发。
* Apache Licence 2.0
    - Apache Licence是著名的非盈利开源组织Apache采用的协议。该协议和BSD类似，同样鼓励代码共享和尊重原作者的著作权，同样允许代码修改，再发布（作为开源或商业软件）。
    - `需要满足的条件`也和BSD类似：
        + 需要给代码的用户一份Apache Licence
        + 如果你修改了代码，需要在被修改的文件中说明
        + 在衍生的代码中（修改和有源代码衍生的代码中）需要带有原来代码中的协议，商标，专利声明和其他原来作者规定需要包含的说明。
        + 如果再发布的产品中包含一个Notice文件，则在Notice文件中需要带有Apache Licence。你可以在Notice中增加自己的许可，但不可以表现为对Apache Licence构成更改。
    - Apache Licence也是`对商业应用友好`的许可。使用者也可以在需要的时候修改代码来满足需要并作为开源或商业产品发布/销售。
* GPL (GNU General Public License, GNU通用公共许可协议)
    - *如果项目包含了 GPL 许可证的代码，那么整个项目都必须使用 GPL 许可证。*
    - 我们很熟悉的Linux就是采用了GPL。
    - GPL协议和BSD, Apache Licence等鼓励代码重用的许可很不一样。
    - GPL的出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用，但不允许修改后和衍生的代码做为闭源的商业软件发布和销售。(这也就是为什么我们能用免费的各种linux，包括商业公司的linux和linux上各种各样的由个人，组织，以及商业软件公司开发的免费软件了。)
    - GPL协议的`主要内容`是只要在一个软件中`使用`(”使用”包含类库引用、修改后的代码或者衍生代码)GPL 协议的产品，则该软件产品`必须也采用GPL协议`，即`必须也是开源和免费`。这就是所谓的`”传染性”`。GPL协议的产品`作为一个单独的产品使用没有任何问题`，还可以享受免费的优势。
    - 由于GPL严格要求使用了GPL类库的软件产品必须使用GPL协议，对于使用GPL协议的开源代码，`商业软件`或者对代码有保密要求的部门就`不适合集成/采用作为类库和二次开发`的基础。
* LGPL (GNU Lesser General Public License, GNU 宽通用公共许可证)
    - *如果项目采用动态链接调用该许可证的库，项目可以不用开源。*
    - LGPL是GPL的一个为主要为`类库`使用设计的开源协议。
    - 和GPL要求任何使用/修改/衍生之GPL类库的的软件必须采用GPL协议不同。LGPL `允许商业软件通过类库引用(link)`方式使用LGPL类库`而不需要开源商业软件的代码`。
    - 这使得采用LGPL协议的开源代码可以被商业软件作为类库引用并发布和销售。
    - GPL/LGPL都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品
* MIT (Massachusetts Institute of Technology, 源自麻省理工学院)
    - MIT是和BSD一样宽范的许可协议,作者只想保留版权,而无任何其他了限制.也就是说,你必须在你的发行版里`包含原许可协议的声明`,无论你是以二进制发布的还是以源代码发布的.(e.g. cJSON使用MIT，可以直接使用源码，不过发布程序时需要带上其原来的协议声明)
* MPL (The Mozilla Public License)
    - *只要该许可证的代码在单独的文件中，新增的其他文件可以不用开源。*
    - MPL是The Mozilla Public License的简写，是1998年初`Netscape(网景)的 Mozilla小组`为其开源软件项目设计的软件许可证。
    - MPL许可证出现的最重要原因就是，Netscape公司认为GPL许可证没有很好地平衡开发者对源代码的需求和他们利用源代码获得的利益。同著名的GPL许可证和BSD许可证相比，MPL在许多权利与义务的约定方面与它们相同（因为都是符合OSIA 认定的开源软件许可证）
        + `OSIA`: “开放源代码首创行动组织”（Open Source Initiative Association，简称OSIA）是一个非盈利的组织，是美国的Bruce Perens 和 Eric S. Raymond 等人于1998年在美国加州发起设立的，倡导了“开放源代码首创行动” （Open Source Initiative，简称OSI），其目的就是要让开放源代码软件的发展有一个更好的土壤。
    - 但是，相比而言MPL还有以下几个显著的`不同之处`:
        + MPL虽然要求对于经MPL许可证发布的源代码的修改也要以MPL许可证的方式再许可出来，以保证其他人可以在MPL的条款下共享源代码。但是，在MPL 许可证中对“发布”的定义是“以源代码方式发布的文件”，这就意味着MPL允许一个企业在自己已有的源代码库上加一个接口，除了接口程序的源代码以MPL 许可证的形式对外许可外，源代码库中的源代码就可以不用MPL许可证的方式强制对外许可。这些，就为借鉴别人的源代码用做自己商业软件开发的行为留了一个豁口。
        + MPL许可证第三条第7款中允许被许可人将经过MPL许可证获得的源代码同自己其他类型的代码混合得到自己的软件程序。

### Creative Commons 知识共享协议

* 另外拓展记录一下CC协议(很多博客和文章都是基于此协议的组合)，之前自己也做过记录，现搬运到一起。[个人翻译记录链接](https://github.com/xiaodongQ/devNoteBackup/blob/master/translation/xd_97ThingsEveryProgrammerShouldKnow/README.md)

* 参考：
    - [知识共享](https://baike.baidu.com/item/%E7%9F%A5%E8%AF%86%E5%85%B1%E4%BA%AB/1607078?fromtitle=Creative%20Commons&fromid=8755425)
* Creative Commons，简称CC，中国大陆正式名称为知识共享，台湾正式名称为创用CC。
* 是一个非营利组织，也是一种创作的授权方式。
* 此组织的主要宗旨是增加创意作品的流通可及性，作为其他人据以创作及共享的基础，并寻找适当的法律以确保上述理念。
* 四种核心权利，作为作者，你可以选择以下1~4种权利组合:
    - 署名（Attribution，简写为BY）：必须提到原作者。
    - 非商业用途（Noncommercial，简写为NC）：不得用于盈利性目的。
    - 禁止演绎（No Derivative Works，简写为ND）：不得修改原作品, 不得再创作。
    - 相同方式共享（Share Alike，简写为SA）：允许修改原作品，但必须使用相同的许可证发布。

这些不同条件共有16种组合模式，  
其中4种组合由于同时包括互相排斥的“nd”和“sa”而无效；  
1种没有以上任何条件的协议，它相当于公有领域。  
在CC 2.0以上的版本，又有5种没有署名条款的协议被列为淘汰，因为98%的授权者都要求署名。

* 简化后剩下6种协议组合：
    - 署名（BY） (即Attribution)
    - 署名（BY）-相同方式共享（SA） (即Attribution-ShareAlike)
    - 署名（BY）-禁止演绎（ND） (即Attribution-No Derivative Works)
    - 署名（BY）-非商业性使用（NC） (即Attribution-NonCommercial)
    - 署名（BY）-非商业性使用（NC）-相同方式共享（SA） (即Attribution-NonCommercial-ShareAlike)
    - 署名（BY）-非商业性使用（NC）-禁止演绎（ND） (即Attribution-NonCommercial-No Derivative Works)

* 在最新Creative Commons（知识共享）3.0协议中，署名(BY)权利成为必选项。  
相比较于之前协议版本, Creative Commons 3.0极大的简化了协议复杂度。

* [97件每个程序员都应该知道的事](https://97-things-every-x-should-know.gitbooks.io/97-things-every-programmer-should-know/content/en/) 使用的协议：Creative Commons Attribution-NonCommercial-ShareAlike 3.0  
(知识共享 署名（BY）-非商业性使用（NC）-相同方式共享（SA）

## abort()与exit()的区别

* [exit abort return 区别](https://blog.csdn.net/qingyue_bao/article/details/6577087)
* `exit()`
    - `void exit(int status);`， `#include <stdlib.h>`
    - 在调用时，会做大部分清理工作，但是决不会销毁局部对象，因为没有stack unwinding
    - 会进行的清理工作包括：销毁所有static和global对象，清空所有缓冲区，关闭所有I/O通道。终止前会调用经由`atexit()`注册的函数。
    - 所有用 `atexit()` 和 `on_exit()`注册的函数都以与注册时相反的顺序被依次执行
* `abort()`
    - `void abort(void);`， `#include <stdlib.h>`
    - `abort`先解除`SIGABRT`信号的锁定，然后向调用程序发出该信号。若没有捕获`SIGABRT`信号，则直接终止程序(程序异常终止)
    - 终止程序时，所有打开的流都会关闭并刷新
    - 如果`SIGABRT`信号被忽略，或捕获信号的处理函数返回后，`abort()`函数都会终止进程
* `retrun`
    - 调用时，进行stack unwinding，调用局部对象析构函数，清理局部对象。如果在main中，则之后再交由系统调用`exit()`。
    - `return`返回，可析构 main或函数中的局部变量，尤其要注意局部对象，如不析构可能造成 内存泄露。

## realloc

* realloc
    - `void *realloc(void *ptr, size_t size);`， `#include <stdlib.h>`
    - 改变ptr指向内存块的大小，原先长度范围的内容不变，若有新内存则新长度部分内存是没有被初始化的
    - `realloc()`返回一个指向新分配内存的指针，对任何对象都进行了适当的对齐，该指针指向位置可能和ptr原位置不同
    - 若ptr是NULL，则和`malloc(size)`效果一样；若size是0则ptr非NULL，则和`free(ptr)`效果一样

## 高性能代码编写原则

* [高性能代码编写原则](https://www.cnblogs.com/moodlxs/p/3501900.html)
    - 看到这篇文章，觉得很有参考意义，平时开发需要有意识注意
    - 低代价优先返回原则
        + 对于一段代码，应该`优先处理低代价`的逻辑，低代价的逻辑包括：
            * 1.`纯CPU计算，不需要访问网络、io、数据库的逻辑`。
                - 纯CPU计算部分是最快的，应该`最优先判断`，不通过就直接返回，不再计算后面的网络、io、数据库逻辑。如果纯CPU计算部分的判断不通过，则后续需要用到网络、io、数据库的逻辑部分就可以免除了，这样可以大大减少各种io等待。
            * 2.`失败几率最高的逻辑`。
                - 假如一段代码中，有A->B->C->D->OK, 四个判断阶段，其中D阶段的`淘汰率最高`,C次之，A、B再次之，那么处理顺序应该改为D->C->A->B->OK,这样在第一个判断阶段就过滤了大量的数据流入第二阶段，减少了非常多无谓的A、B阶段的处理。
                - 思考：把最容易失败的分支提前
    - 只有一个...

## uuid

* 安装 libuuid-devel 软件包
    - `yum install libuuid-devel` centos
    - `sudo apt-get install uuid-dev` ubuntu

```cpp
#include <uuid/uuid.h>

// 生成uuid "1b4e28ba-2fa1-11d2-883f-0016d3cca427"
void util_generate_uuid(string &strUuid)
{
    uuid_t uu;
    char szBuff[37] = {0};
    uuid_generate(uu);
    uuid_unparse(uu, szBuff);

    strUuid = szBuff;
}
```

## tcpdump

* tcpdump
    - `tcpdump -i enp3s0 port 8080 -s 0`
    - `-n` 显示ip，不用该选项部分地址显示hostname
* wireshark
    - *显示过滤* 和 *捕获过滤*，设置规则的语法不同(很多文章没有明确或者弄混淆了)
        + 两者都可以用逻辑运算来组合条件： 非 `!`/`not`，且 `&&`/`and`，或`||`/`or`
        + 显示过滤使用`==`或`eq`来精确指定，也可用`>`，`<`来过滤显示；而捕获过滤不用`==`和`>`，`<`等
        + 显示过滤引用端口需要用`.`，e.g. `[tcp/udp].port==80`；捕获过滤使用`[tcp/udp/空] port 80`
    - 显示过滤
        + `ip.addr == 192.168.1.1` 经过指定ip的包，不管目标还是源地址
            * `ip.src == 192.168.1.1` 源地址为指定ip
            * `ip.dst == 192.168.1.1` 目的地址为指定ip
            * 也可以过滤网段：`192.168.0.0/16`
            * 或者使用`eq`来替换`==`
        + `eth.addr == 80:f6:2e:ce:3f:00` mac过滤
            * `eth.dst == 80:f6:2e:ce:3f:00` 目的mac
    - 捕获过滤
        + `host 192.168.1.1` 抓取过该ip地址的所有数据包
            * `src host 192.168.1.1` 源
            * `dst host 192.168.1.1` 目的
            * `net 192.168.1` 过滤抓取网段
        + `ether host 80:05:09:03:E4:35` 过滤抓取mac
        + `[tcp] port 80` 过滤tcp端口

## Linux启动盘

* a 使用Rufus制作
    - [1分钟学会U盘启动安装Linux系统](https://www.linuxidc.com/Linux/2019-11/161337.htm)
    - rufus官网下载：[rufus官网](http://rufus.ie/) (免安装)
* b UltraISO软碟通
    - [UltraISO制作U盘启动安装CentOS](https://www.cnblogs.com/reid21/articles/8413584.html)

## TOML

* [TOML介绍](https://segmentfault.com/a/1190000000477752)
    - TOML的全称是 Tom's Obvious, Minimal Language，因为它的作者是GitHub联合创始人Tom Preston-Werner
    - TOML 的目标是成为一个极简的配置文件格式
    - TOML 被设计成可以无歧义地被映射为哈希表，从而被多种语言解析。
    - **大小写敏感**
    - 语法
        + 缩进使用空格或Tab都可以
        + 使用 `#` 表示注释
        + 字符串和 JSON 的定义一致，只有一点除外：TOML要求使用UTF-8编码
            * 常用的转义序列：
            * `\b`     - backspace       (U+0008)
            * `\t`     - tab             (U+0009)
            * `\n`     - linefeed        (U+000A)
            * `\r`     - carriage return (U+000D)
            * `\"`     - quote           (U+0022)
            * `\/`     - slash           (U+002F)
            * `\\`     - backslash       (U+005C)
            * `\uXXXX` - unicode         (U+XXXX)
            * 使用保留的特殊字符，TOML　会抛出错误，如Windows下用`\\`表示路径，用`\`则不对
            * 二进制数据建议使用 Base64 或其他合适的编码。具体的处理取决于特定的应用
        + 布尔值：永远是小写，`true`，`false`
        + 日期时间：使用 `ISO 8601` 完整格式，e.g. `1979-05-27T07:32:00Z`
        + 数组
          * 数组使用方括号包裹。
          * 空格会被忽略。
          * 元素使用逗号分隔。
          * `[ 1, 2, 3 ]`、`[ "red", "yellow", "green" ]`
          * 注意，不允许混用数据类型
            - `[ [ 1, 2 ], ["a", "b", "c"] ]` 这是可以的。
            - `[ 1, 2.0 ]` 注意：这是不行的。
          * 数组可以多行。也就是说，除了空格之外，方括号间的换行也会被忽略。
          * 在关闭方括号前的最终项后的逗号是允许的 `[1,2,3,]`
        + 表格(table)
          * 表格（也叫哈希表或字典）是键值对的集合
          * 它们在方括号内，自成一行。注意和数组相区分，数组只有值
          * 在此之下，直到下一个　table 或　EOF 之前，是这个表格的键值对
          * 键值对是无序的
          * 可以随意缩进，使用 Tab 或空格
          * 示例：
              - `[dog.tater]`
              - `type = "pug"`
          * 上面的示例等价于JSON结构：`{ "dog": { "tater": { "type": "pug" } } }`
            - 即可以直接写成`[x.y.z.w]`，而可以不声明所有父表 `[x]` `[x.y]` `[x.y.z]`
          * 空表是允许的，其中没有键值对
          * 不能多次定义键和表格。这么做是不合法的
        + 表格数组
          * `[[products]]` 使用相同的双方括号名称的表格是同一个数组的元素，参考链接中的示例层级
    - 各个语言解析支持：
      + C (@ajwans) - https://github.com/ajwans/libtoml
      + C++ (@evilncrazy) - https://github.com/evilncrazy/ctoml
      + C++ (@skystrife) - https://github.com/skystrife/cpptoml
      + Go (@thompelletier) - https://github.com/pelletier/go-toml
      + Go (@laurent22) - https://github.com/laurent22/toml-go

```sh
# TOML文件示例
title = "TOML 例子"

[owner]
name = "Tom Preston-Werner"
organization = "GitHub"
bio = "GitHub Cofounder & CEO\nLikes tater tots and beer."
dob = 1979-05-27T07:32:00Z # 日期时间是一等公民。为什么不呢？

[database]
server = "192.168.1.1"
ports = [ 8001, 8001, 8002 ]
connection_max = 5000
enabled = true

[servers]

  # 你可以依照你的意愿缩进。使用空格或Tab。TOML不会在意。
  [servers.alpha]
  ip = "10.0.0.1"
  dc = "eqdc10"

  [servers.beta]
  ip = "10.0.0.2"
  dc = "eqdc10"

[clients]
data = [ ["gamma", "delta"], [1, 2] ]

# 在数组里换行没有关系。
hosts = [
  "alpha",
  "omega"
]
```

## YAML

* [YAML 简介](https://www.ibm.com/developerworks/cn/xml/x-cn-yamlintro/index.html)
    - `YAML Ain't Markup Language`
    - 和GNU一样，YAML是一个递归着说“不”的名字。不同的是，GNU对UNIX说不，YAML说不的对象是XML(Extensible Markup Language 可扩展标记语言)，即YAML不是XML
    - `YAML`试图用一种比`XML`更敏捷的方式，来完成`XML`所完成的任务
* [YAML 入门教程](https://www.runoob.com/w3cnote/yaml-intro.html)
    - 特别适合用来表达或编辑数据结构、各种配置文件、倾印调试内容、文件大纲（例如：许多电子邮件标题格式和YAML非常接近）
    - 基本语法规则
        + **大小写敏感**
        + 使用缩进表示层级关系
        + 缩进时不允许使用Tab键，只允许使用空格
        + 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可
        + `#` 表示注释，从这个字符一直到行尾，都会被解析器忽略
    - YAML 的配置文件后缀为 `.yml`，如：runoob.yml
    - YAML 支持以下几种数据类型：
        + 对象：键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary）
            * 对象键值对使用冒号结构表示 `key: value`，冒号后面要加一个空格
            * 也可以使用 `key:{key1: value1, key2: value2, ...}` (可以使用缩进表示层级关系)
                - 较为复杂的对象格式，可以使用问号加一个空格代表一个复杂的key，配合一个冒号加一个空格代表一个value
        + 数组：一组按次序排列的值，又称为序列（sequence） / 列表（list）
            * 以`-`开头的行表示构成一个数组，`- A`
            * YAML 支持多维数组，可以使用行内表示 `key: [value1, value2, ...]`
        + 纯量（scalars）：单个的、不可再分的值，包括：
            * 字符串
                - `哈哈` 可以不用引号
                - `'Hello world'` 可以用双引号或单引号包裹特殊字符
            * 布尔值、
                - TRUE，true，True都可以
                - FALSE，false，False都可以
            * 整数、
                - `123`
                - `0b1010_0111_0100_1010_1110` 二进制表示
            * 浮点数、
                - `3.14`
                - `6.8523015e+5` 可以使用科学计数法
            * Null、
                - `parent: ~`  使用`~`表示null
            * 时间、
                - `2018-02-17T15:02:31+08:00` 时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区
            * 日期
                - `2018-02-17` 日期必须使用ISO 8601格式，即yyyy-MM-dd
    - 引用
        + `&` 锚点和 `*` 别名，可以用来引用
            * `&` 用来建立锚点（defaults）
            * `<<` 表示合并到当前数据，`*` 用来引用锚点
        + 见下面列出示例

```yaml
# 数组示例
- A
- B
- C

# 也可用行内表示：
key: [value1, value2, ...]

# companies属性是一个数组，每一个数组元素又是由id、name、price三个属性构成(缩进的空格数目不重要，相同层级对齐即可)
companies:
    -
        id: 1
        name: company1
        price: 200W
    -
        id: 2
        name: company2
        price: 500W
```

```yaml
# 数组和对象可以构成复合结构
languages:
  - Ruby
  - Perl
  - Python
websites:
  YAML: yaml.org
  Ruby: ruby-lang.org
  Python: python.org
  Perl: use.perl.org
```

```yaml
# 纯量示例
boolean:
    - TRUE  #true,True都可以
    - FALSE  #false，False都可以
float:
    - 3.14
    - 6.8523015e+5  #可以使用科学计数法
int:
    - 123
    - 0b1010_0111_0100_1010_1110    #二进制表示
null:
    nodeName: 'node'
    parent: ~  #使用~表示null
string:
    - 哈哈
    - 'Hello world'  #可以使用双引号或者单引号包裹特殊字符
    - newline
      newline2    #字符串可以拆成多行，每一行会被转化成一个空格
date:
    - 2018-02-17    #日期必须使用ISO 8601格式，即yyyy-MM-dd
datetime:
    -  2018-02-17T15:02:31+08:00    #时间使用ISO 8601格式，时间和日期之间使用T连接，最后使用+代表时区
```

```yaml
# 锚点示例
defaults: &defaults
  adapter:  postgres
  host:     localhost

development:
  database: myapp_development
  <<: *defaults

# 相当于：
defaults:
  adapter:  postgres
  host:     localhost

development:
  database: myapp_development
  adapter:  postgres
  host:     localhost
```

