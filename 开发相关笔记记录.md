[TOC]


## Tips

开发过程过程中注意空格影响！
  makefile字符串赋值给变量时末尾空格(编辑器尽量开启空格和tab显示)


## REST

REST API: 即Representational State Transfer(表述性状态转移)的缩写
其优点如下：

* 在RESTful架构中，每一个URL代表一种资源；
* 客户端和服务器之间，传递这种资源的某种表现层；
* 客户端通过四个HTTP指令，对服务器端资源进行操作，实现“表现层状态转化”。 建议开发者使用REST API进行币币交易或者资产提现等操作。

## WebSocket API

WebSocket API: WebSocket是HTML5一种新的协议(Protocol)。

>它实现了客户端与服务器全双工通信，使得数据可以快速地双向传播。

通过一次简单的握手就可以建立客户端和服务器连接，服务器根据业务规则可以主动推送信息给客户端。

其优点如下：

* 客户端和服务器进行数据传输时，请求头信息比较小，大概2个字节;
* 客户端和服务器皆可以主动地发送数据给对方；
* 不需要多次创建TCP请求和销毁，节约宽带和服务器的资源。 强烈建议开发者使用WebSocket API获取**市场行情**和**买卖深度**等信息。

## TCP

TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

[gRPC服务发现&负载均衡](https://segmentfault.com/a/1190000008672912)

## windows 命令

tasklist 查看进程
tasklist|findstr "9108"

win10开机内存使用就80%：关闭快速启动

[windows 10如何关闭快速启动](https://jingyan.baidu.com/article/ca00d56c7a40e6e99febcf4f.html)

## curl

* `curl -o` 指定写到文件名
    - e.g. `curl -o ./test.jpg http://mirrors.aliyun.com/repo/testjpg`

* curl -X

>curl -X 123.45.67.89:1080 Yahoo
-X选项用于指定代理（服务器和端口号）

>curl -d "user=nickwolfe&password=12345" http://www.yahoo.com/login.cgi
-d选项用于指定发送请求时POST命令的数据

```sh
curl -X POST http://127.0.0.1:8000/person -d "first_name=hello&last_name=world" | python -m json.tool
```

python -m, -m将库中的python模块用作脚本去运行

将模块当做脚本去启动有什么用？
python xxx.py
python -m xxx.py
这是两种加载py文件的方式:
1叫做直接运行
2相当于import,叫做当做模块来启动


## git

### 删除Git中缓存的用户名和密码

运行一下命令缓存输入的用户名和密码：
git config --global credential.helper wincred
清除掉缓存在git中的用户名和密码
git credential-manager uninstall

### 恢复某个已修改的文件（撤销未提交的修改）
git checkout .(全部，或者指定文件来恢复部分)  //本地删除的记录恢复

### 基本命令

Git book：  
[Git 基础 ](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)

* git pull
    - 拉取远程分支更新到本地仓库
    - `git pull <远程主机名> <远程分支名>:<本地分支名>`，一般我们简写成 `git pull`
    - git pull = git fetch + git merge
    - git fetch不会进行合并，执行后需要手动执行git merge合并，而git pull拉取远程分之后直接与本地分支进行合并。
    - 强制覆盖本地：git pull --force
* git fetch
    - 更新远程代码到本地仓库
    - FETCH_HEAD指的是: 某个branch在服务器上的最新状态
        + 这个列表保存在 .Git/FETCH_HEAD 文件中, 其中每一行对应于远程服务器的一个分支。
        + 如果没有显式的指定远程分支, 则远程分支的master将作为默认的FETCH_HEAD
        + 如果指定了远程分支, 就将这个远程分支作为FETCH_HEAD
    - git fetch更新本地仓库的两种用法
        + 方法一
            * `git fetch origin master` #从远程的origin仓库的master分支下载代码到本地的origin master
            * `git log -p master.. origin/master` #比较本地的仓库和远程参考的区别
            * `git merge origin/master` #把远程下载下来的代码合并到本地仓库，远程的和本地的合并
        + 方法二
            * `git fetch origin master:temp` #从远程的origin仓库的master分支下载到本地并新建一个分支temp
            * `git diff temp`  #比较master分支和temp分支的不同
            * `git merge temp` #合并temp分支到master分支
            * `git branch -d temp` #删除temp
* git reset
    - git reset会将撤销点之后的操作都回退到暂存区中
    - git reset是直接删除指定的commit
* git revert
    - git revert 仅仅是撤销某次提交
    - git revert是用一次新的commit来回滚之前的commit

* 撤消操作
    - [2.4 Git 基础 - 撤消操作](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)

### git终端显示中文名为数字编码设置

在cygwin中，使用git add添加要提交的文件的时候，如果文件名是中文，会显示形如 274\232\350\256\256\346\200\273\347\273\223.png 的乱码。

解决方案：
在bash提示符下输入：
`git config --global core.quotepath false`
core.quotepath设为false的话，就不会对0x80以上的字符进行quote。中文显示正常。

### git 默认不区分文件名大小写

readme.md 改名为 Readme.md，git status并不会显示任何信息

* 配置git 使其对文件名大小写敏感
    - git config core.ignorecase false

## spdlog

使用，两种方式：
1. 只有头文件的方式(代码中不需要加spdlog.cpp)
  拷贝include/spdlog 到代码路径，编译时，添加-std=c++11
  这种方式不需要-DSPDLOG_COMPILED_LIB
2. 使用静态库方式(推荐,把spdlog.cpp编进代码，编译更快)
  拷贝src/spdlog.cpp到代码路径，将cpp一起编译，需要加宏-DSPDLOG_COMPILED_LIB和-std=c++11

日志等级： (从上到下越来越严重，默认日志等级及其更高等级会进行打印，默认info)
  trace
  debug
  info
  warn
  error
  critical

### 基本用法及说明

[spdlog学习笔记](https://blog.csdn.net/haojie_superstar/article/details/89383433)

#### logger
  日志记录器，通过传入一个或者多个sink给它进行记录一个或多个位置
  可以通过spdlog自身的函数方法创建logger，也可以手动创建(先创建一个或者多个sink，再将sink传给spdlog::logger的构造函数进行创建)
    自身方法使用工厂模式创建实例，e.g. spdlog::daily_logger_mt
    sink的命名空间层次为 sdplog::sinks::具体sink类型，e.g. spdlog::sinks:stdout_sink_mt

#### sink

  sink是实际将日志写入目标位置的对象。
  每一个sink仅应负责写一个目标文件（比如 file，console，db）
  并且每一个sink有专属的私有格式化器formatter实例。 (可以手动创建sink，传递给logger，实现多个sink写入)

可用sink：

rotating_file_sink 达到最大文件大小时，关闭文件，重命名文件并创建新文件。
    `spdlog::rotating_logger_mt使用该sink`
daily_file_sink  每天在一个特别的时间创建一个新的日志文件，并在文件名字上添加一个时间戳
    `spdlog::daily_logger_mt`
simple_file_sink 无任何限制的向一个日志文件中写入
    `spdlog::basic_logger_mt`
stdout_sink/stderr_sink with colors
    `spdlog::stdout_color_mt`
    `spdlog::color_logger_mt`
syslog_sink POSIX syslog(3) 发送日志到syslog
    `spdlog::syslog_logger`
dist_sink 将日志消息分发到其他接收器列表 **使用这个sink实现多个sink记日志**
    没有工厂模式返回logger，需要手动添加

```cpp
    auto distsink = std::make_shared<spdlog::sinks::dist_sink_mt>();
    distsink->add_sink(std::make_shared<spdlog::sinks::stdout_sink_mt>());
    distsink->add_sink(std::make_shared<spdlog::sinks::rotating_file_sink_mt>(filepath, 1024*1024*1, 3));
    auto mydistlogger = std::make_shared<spdlog::logger>("mydistlogger", distsink);
    spdlog::register_logger(mydistlogger);
```

**注意**：用户应该负责去创建任何他们需要的文件夹。spdlog除了文件**不会尝试创建任何文件夹**

spdlog::info
spdlog::error

#### 线程安全说明

* spdlog:: 命名空间下的是线程安全的

* 对于sinks，以 _mt 后缀结尾的是线程安全的，比如：daily_file_sink_mt
             以_st 后缀结尾的是非线程安全的，比如：daily_file_sink_st

  单线程的sink不可以在多线程中使用，它的速度会更快，因为没有锁竞争

1.  不同线程处理时以下函数不应该操作：
当loggers在不同的线程同时执行时，下述函数不应该被调用
  spdlog::set_error_handler(log_err_handler) // or logger->set_error_handler(log_err_handler);
logger在其它线程执行过程中，添加或移除sink是线程不安全的
  logger->sinks().push_back(new_sink);       // Don't do this if other thread is already using this logger

2. 要创建线程安全的loggers，使用带 _mt 后缀的工厂函数
  auto logger = spdlog::basic_logger_mt(...);

3. 要创建单线程的loggers，使用带 _st 后缀的工厂函数
  auto logger = spdlog::basic_logger_st(...);

#### 使用
spdlog支持使用最小集的方式，意味着你只用包含你实际需要的头文件，而不是全部，比如说你只需要使用 rotating logger，那么你只需要
`#include <spdlog/sinks/rotating_file_sink.h>`

对于异步特性，你还需要
`#include <spdlog/asynch.h>`

* 几种使用模式：
  返回智能指针 std::shared_ptr<logger>
    每一个logger中包含一个存有一个或多个 std::shared_ptr<spdlog::sink>的 vector
    logger在记录每一条日志时（如果是有效的级别），将会调用每一个std::shared_ptr<spdlog::sink>中的sink(log_msg)函数

```cpp
* stdout打印
    auto console = spdlog::stdout_logger_mt("console");

* 基本文件记录，只有一个，不循环使用不限制大小
    #include "spdlog/sinks/basic_file_sink.h"
    // Create basic file logger (not rotated) // support for basic file logging
    auto my_logger = spdlog::basic_logger_mt("basic_logger", "logs/basic.txt");

* rotate句柄，限制大小和备份数量
    #include "spdlog/sinks/rotating_file_sink.h" // support for rotating file logging
    // file rotating logger with 5mb size max and 3 rotated files，5MB大小，3个循环备份文件(即共4个日志文件) rotate循环，旋转
    auto file_logger = spdlog::rotating_logger_mt("file_logger", "myfilename", 1024 * 1024 * 5, 3);

* 异步logger 使用工厂函数创建异步logger(循环记日志时，每次异步logger不阻塞)
    #include "spdlog/sinks/daily_file_sink.h"
    #include <spdlog/asynch.h>  //异步logger加头文件
    auto async_file = spdlog::basic_logger_mt<spdlog::async_factory>("async_file_logger", "logs/async_log.txt");
  可以通过创建异步logger前调用以下函数来修改线程池个数和待写日志队列长度
    inline void init_thread_pool(size_t q_size, size_t thread_count)

* 创建一个由多个loggers共享同一个输出文件的sink

* auto console = spdlog::stdout_color_mt("xdconsole");
    #include "spdlog/sinks/stdout_color_sinks.h"

  使用spdlog::get("...")访问loggers
    (spdlog::get("xdconsole"))->info("test spdlog::get function")
  spdlog::get可能会拖慢你的程序，因为它内部维护了一把锁，所以要谨慎使用。
    一个很好的方法是建立一个std::shared_ptr<spdlog::logger>私有成员变量，并在构造函数中初始化
```

* 手动创建loggers

参考(上面的sink章节，dist_sink可创建写多个sink的logger)

```cpp
  auto sink = std::make_shared<spdlog::sinks::stdout_sink_mt>();
  auto my_logger= std::make_shared<spdlog::logger>("mylogger", sink);
  my_logger->info("etstesfdljk");
```

* 设置函数

```cpp
  //设置一个logger, 后续使用spdlog::info时，会使用该logger记录
  spdlog::set_default_logger(file_logger);

  //设置模式字符串
  set_pattern(pattern_string);
    //格式应用到所有被注册的logger
    spdlog::set_pattern("*** [%H:%M:%S %z] [thread %t] %v ***");
    //格式应用到具体的logger
    some_logger->set_pattern(">>>>>>>>> %H:%M:%S %z %v <<<<<<<<<");
    //格式应用到具体的logger某个特定sink
    some_logger->sinks()[1]->set_pattern("..");
```

  [spdlog学习笔记_模式标记](https://blog.csdn.net/haojie_superstar/article/details/89383433)
    %H %M %S %z, 时(0-23) 分 秒 时区(“+02:00”)
    %I 时(1-12), %e 毫秒; %f 微秒

    %Y 年(“2014”), %m 月; %d 日(1-31)
    %C 年(“14”); %B 月份全名(August); %A 星期全名(Thursday)


用SPDLOG_INFO/SPDLOG_TRACE 等宏定义记录才有：不能指定logger
    %@ 文件名:行号(my_file.cpp:123)
    %s 文件名
    %# 行号
    %! 函数名

    %P 进程id; %t 线程id

    %+ spdlog的默认格式 “[2014-10-31 23:46:59.678] [mylogger] [info] Some message”
    %v 用户要记的信息

      即 [%Y-%m-%d %H:%M:%S.%e] [%n] [%l] %v

    %^ “[mylogger] [info(green)] Some message”
    %L 日志等级缩写(“D”, “I”, etc)
    %l 日志等级(“debug”, “info”)
    %n logger名

    %% %号

  对齐
    右对齐
      %8l  ("    info")
    -左对齐
      %-8l ("info    ")
    =中间对齐
      %=8l ("  info  ")

[%Y-%m-%d %H:%M:%S.%e] %^

## 编译

### pkg-config 编译时找库 和 ldconfig 运行时找库
编译grpc, third_party少包, git checkout .
  `git submodule update --init`
编译项目pkg-config找不到库
  export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
运行项目找不到动态库，系统中添加路径，或LD_LIBRARY_PATH
  vi /etc/ld.so.conf，添加一行 /usr/local/lib，然后执行ldconfig

编译时提示未定义的引用，如果-l链接了，且路径已经配置或者-L已经指定，还有可能是:
-l链接库在引用库的函数文件之前，这样就会链接不到库，所以要保证链接库的顺序在引用它之前

#### pkg-config
[pkg-config 详解](https://blog.csdn.net/newchenxf/article/details/51750239)

pkg-config是一个linux下的命令，用于获得某一个库/模块的所有编译相关的信息。

```sh
pkg-config --cflags --libs libmongocxx 执行结果为：

-I/usr/local/include/mongocxx/v_noabi -I/usr/local/include/bsoncxx/v_noabi  -L/usr/local/lib -lmongocxx -lbsoncxx
```

> 如果你写了一个库，不管是静态的还是动态的，要提供给第三方使用，那除了给人家库/头文件，最好也写一个pc文件，这样别人使用就方便很多，不用自己再手动写依赖了你哪些库，只需要敲一个”pkg-config [YOUR_LIB] --libs --cflags”。

pkg-config信息两个来源
  第一种：取系统的/usr/lib下的所有*.pc文件。
  第二种：PKG_CONFIG_PATH环境变量所指向的路径下的所有*.pc文件。

## makefile

**注意！ `PRJ_DIR="${shell cd ..;pwd}"       #注释说明`, 这样注释处理会将空格也赋值给PRJ_DIR**

[Makefile编译目录下多个文件以及函数wildcard用法](https://blog.csdn.net/hunanchenxingyu/article/details/12205305)
[makefile 中字符串处理和文件处理函数](https://blog.csdn.net/qhexin/article/details/16951097)

```sh
1. wildcard
  找出目录和指定目录下所有的后缀为c和cpp的文件
  $(wildcard *.c, *.cpp, /***/***/*.c)
    C_SRC = $(wildcard *.c)
    同C_SRC=$(shell echo *.c)

2. foreach
  组合foreach查找多个路径
    SRC_FILES += $(foreach dir,$(SRC_DIR),$(wildcard $(dir)/*.cpp))

3. patsubst 模式字符串替换函数
  $(patsubst <pattern>,<replacement>,<text>)
    <pattern>可以包括通配符“%”，表示任意长度的字串
    如果<replacement>中也包含“%”，那么，<replacement>中的这个“%”将是<pattern>中的那个“%
    以“\%”来表示真实含义的"%"
  e.g.
      将所有的cpp文件的后缀替换为o文件
      CPP_OBJ = $(patsubst %cpp, %o, $(CPP_SRC))
        同CPP_OBJ=$(CPP_SRC:%.cpp=%.o)

4. notdir
  dir=$(notdir $(src)) 把带路径的文件去掉路径，只留文件名

5. subst 字符串替换函数
  $(subst <from>,<to>,<text>)
  e.g.
    $(subst ee,EE,feet on the street)， 将"feet on the street"中的"ee"替换为"EE"，若要替换为空则,,

  其他字符串处理：
    去空格函数——strip
    e.g.
      $(strip a b c ) 把字串“a b c ”去到开头和结尾的空格，结果是“a b c”。

    过滤函数——filter
      sources := foo.c bar.c baz.s ugh.h
      $(filter %.c %.s,$(sources))返回的值是“foo.c bar.c baz.s”。
    反过滤函数——filter-out
      objects=main1.o foo.o main2.o bar.o
      mains=main1.o main2.o
      $(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”
    排序函数——sort
      $(sort foo bar lose)返回“bar foo lose”
    取单词函数——word
      取第n个，从1开始数
      $(word 2, foo bar baz)返回值是“bar”
    取单词串函数——wordlist
      第几到第几个
      $(wordlist 2, 3, foo bar baz)返回值是“bar baz”
    单词个数统计函数——words
      $(words, foo bar baz)返回值是“3”
    首单词函数——firstword
      $(firstword foo bar)返回值是“foo”
  文件名操作函数：
    取目录函数——dir
      目录部分是指最后一个反斜杠（“/”）之前的部分。如果没有反斜杠，那么返回“./”
      $(dir src/foo.c hacks)返回值是“src/ ./”
    取文件函数——notdir
      非目录部分是指最后一个反斜杠（“/”）之后的部分
      $(notdir src/foo.c hacks)返回值是“foo.c hacks”
    取后缀函数——suffix
      如果文件没有后缀，则返回空字串
      $(suffix src/foo.c src-1.0/bar.c hacks)返回值是“.c .c
    取前缀函数——basename
      如果文件没有前缀，则返回空字串
      $(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar hacks”
    加后缀函数——addsuffix
      $(addsuffix .c,foo bar)返回值是“foo.c bar.c”
    加前缀函数——addprefix
      $(addprefix src/,foo bar)返回值是“src/foo src/bar”
    连接函数——join
      $(join <list1>,<list2>)
      如果<list1>的单词个数要比<list2>的多，那么，<list1>中的多出来的单词将保持原样。如果<list2>的单词个数要比<list1>多，那么，<list2>多出来的单词将被复制到list1中末尾
      $(join aaa bbb , 111 222 333)返回值是“aaa111 bbb222 333”
```

通配符$@、$^、$<

这三个分别表示：
$@          --代表目标文件(target)
$^            --代表所有的依赖文件(components)
$<           --代表第一个依赖文件(components中最左边的那个)。

```sh
main.out:main.o line1.o line2.o
  g++ -o $@ $^
main.o:main.c line1.h line2.h
  g++ -c $<
line1.o:line1.c line1.h
  g++ -c $<
line2.o:line2.c line2.h
  g++ -c $<
```

### ifeq语法

```
ifeq ($(CC),gcc)
    $(CC) -o foo $(objects) $(libs_for_gcc)
else
    $(CC) -o foo $(objects) $(normal_libs)
endif
```

## CMake

[在 linux 下使用 CMake 构建应用程序](https://www.ibm.com/developerworks/cn/linux/l-cn-cmake/)

1. 编写CMakeLists.txt
2. 执行cmake path生成Makefile(path时CMakeLists.txt所在目录)
3. 使用make进行编译

### CMakeLists.txt 的语法

由命令、注释和空格组成

其中命令是不区分大小写的,符号"#"后面的内容被认为是注释。

命令由命令名称、小括号和参数组成,参数之间使用空格进行间隔。 (注意VERSION大写)

```c
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
4 ADD_EXECUTABLE(main ${DIR_SRCS})
```
`aux_source_directory(<dir> <variable>)`
  命令会把参数 <dir> 中所有的源文件名称赋值给参数 <variable>

完成了文件 CMakeLists.txt 的编写后需要使用 cmake 或 ccmake 命令生成Makefile 。 ccmake 与命令 cmake 的不同之处在于 ccmake 提供了一个图形化的操作界面。

加子目录src，链接库Test，并将子目录编译成库(静态库.a)

```
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 ADD_SUBDIRECTORY( src )
4 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
5 ADD_EXECUTABLE(main ${DIR_SRCS}  )
6 TARGET_LINK_LIBRARIES( main Test )
```

子目录src中的CMakeLists.txt

```
1 AUX_SOURCE_DIRECTORY(. DIR_TEST1_SRCS)
2 ADD_LIBRARY ( Test ${DIR_TEST1_SRCS})
```

## linux

### history日志显示日期

.bashrc中设置环境变量:
export HISTTIMEFORMAT="%F %T `whoami` "

### man手册等级

1是普通的命令
2是系统调用,如open,write之类的(通过这个，至少可以很方便的查到调用这个函数，需要加什么头文件)
3是库函数,如printf,fread4是特殊文件,也就是/dev下的各种设备文件
5是指文件的格式,比如passwd, 就会说明这个文件中各个字段的含义; 比如man 5 proc, 说明进程信息伪文件系统
6是给游戏留的,由各个游戏自己定义
7是附件还有一些变量,比如向environ这种全局变量在这里就有说明
8是系统管理用的命令,这些命令只能由root使用,如ifconfig


### 重定向标准错误

`mv a.log back/ 2>tmp.log  (或者2>>tmp.log)`

将执行的错误信息输出重定向到日志tmp.log中，**注意，2>之间不能有空格**

这种情况下，错误信息只会打印到tmp.log中，若要打印到文件的同时，终端上也能打印(标准输出1)，则可使用tee：

```sh
mv a.log back/ 2>&1 | tee -a tmp.log
```

### tee

[tee命令](https://www.cnblogs.com/leezhxing/p/4092532.html)

tee命令读取**标准输入**，把这些内容同时**输出到标准输出**和**（多个）文件**中，tee命令可以重定向标准输出到多个文件。

在使用管道线时，前一个命令的**标准错误**输出不会被tee读取。

```sh
tee
    只输出到标准输出
tee file
    输出到标准输出的同时，保存到文件file中
    如果文件不存在，则创建；如果已经存在，则覆盖之。
tee -a file
    输出到标准输出的同时，追加到文件file中。
    如果已经存在，就在末尾追加内容，而不是覆盖。
tee -
    输出到标准输出两次
tee file1 file2
    同时保存到file1和file2中

ls "*" 2>&1 | tee -a ls.txt
    使用tee命令把标准错误输出也保存到文件
```

### history记录时间
export HISTTIMEFORMAT="%F %T `whoami` "

### vim
替换指定行之间  :10,15s/abc/hhh/g

把204到233间的" = "替换为"("
`:204,233s/ = /(/g`

204到233间 ");"替换为"));"
`:204,233s/\)\;/));/g`

查找以\结尾：
/\\$  (\\为'\'转义)

#### vim版本更新

卸载原来的
yum remove vim* -y

下载vim8.0
wget ftp://ftp.vim.org/pub/vim/unix/vim-8.0.tar.bz2
tar -jxf vim-8.0.tar.bz2
cd vim80

make
make install
插件安装

### rpm

* [Linux RPM包安装、卸载和升级（rpm命令）详解](http://c.biancheng.net/view/2872.html)
    - 父目录下也包含一些其他Linux配置安装类的介绍(RPM命名规则、yum和yum源、源码包安装升级等)

* rpm包安装
    - `rpm -ivh 包全名`
        + -i：安装（install）;
        + -v：显示更详细的信息（verbose）;
        + -h：打印 #，显示安装进度（hash）;
    - 默认安装位置
        + `/etc/` 配置文件安装目录
        + `/usr/bin/` 可执行的命令安装目录
        + `/usr/lib/` 程序所使用的函数库保存位置
        + `/usr/share/doc/` 基本的软件使用手册保存位置
        + `/usr/share/man/` 帮助文件保存位置
* 卸载
    - `rpm -e 包名`
    - RPM 软件包的卸载要考虑包之间的依赖性。
        + 例如，我们先安装的 httpd 软件包，后安装 httpd 的功能模块 mod_ssl 包，那么在卸载时，就必须先卸载 mod_ssl，然后卸载 httpd，否则会报错。
    - RPM 软件包的卸载命令支持使用“-nocteps”选项，即可以不检测依赖性直接卸载，但此方式`不推荐`大家使用，因为此操作很可能导致其他软件也无法征程使用。
* 升级
    - `rpm -Uvh 包全名`
        + -U（大写）选项的含义是：如果该软件没安装过则直接安装；若安装了则升级至最新版本。
        + 将当前已安装的包升级或新安装到一个新的RPM版本. 升级和 安装是一样的, 区别在于升级要将所有别的版本的包从系统移去
    - `rpm -Fvh 包全名`
        + -F（大写）选项的含义是：如果该软件没有安装，则不会安装，必须安装有较低版本才能升级。
        + 只有在系统存在一个更早版本的包时候才使用这种方式.

### find

查找目录 时跳过指定目录，使用prune(英 /pruːn/   删除；减少)
  (注意顺序，-path接源路径，后面跟-prune，再跟-o，后面再跟其他过滤选项，-print不能少)：
  `find . -path './util' -prune -o -type d -print`

过滤多个目录：
  `find . \( -path './util' -o -path './tradebot \) -prune -o -type d -print`

  -o 类似于 or,  或者;
  -a 类似于 and, 且

  (1) grep指定h文件类型查找hello字符串：
find . -type f -name '*.h' | xargs grep "hello"

查看端口 lsof -i:5000

* 排除目录下所有以md结尾的文件：
`find . -type f ! -name "*.md"`

* 排除多个：
`find . -type f ! -name "*.md" ! -name "*.o"`

* 正则表达式：
`find . -regex '.*\.md\|.*\.h\|.*\.cpp'`

### 统计文本行数

语法：wc [选项] 文件…

说明：该命令统计给定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。

    该命令各选项含义如下：

    　　- c 统计字节数
    　　- l 统计行数
    　　- w 统计字数

* `wc -lcw Makefile`

* 统计src目录下所有cpp文件代码行数(子目录也会统计)

`find src/ -name "*.cpp" |xargs cat|wc -l`

* 统计当前目录及子目录下文件行数
`find . -type f |xargs cat|wc -l`

* 统计当前目录及子目录下.h和.cpp文件行数
`find . -type f -name "*.h" -o -name "*.cpp" |xargs cat|wc -l`
`find . -type f -name "*.h" |xargs cat|wc -l`

* 统计src目录下所有cpp文件代码行数(过滤空行)

`find src/ -name "*.cpp" |xargs cat | grep -v ^$ | wc -l`

### unzip

unzip zip文件

### 目录排序

du -s -d1|sort -n      (h会影响排序，仅按数字来排的)

### grep 查找后去重

grep "#include <boost" -rn *|awk -F' ' '{print $2}'|sort|uniq  (注意要先sort，要不仅会去重相邻的)

### sort uniq 文件去重

对文件排序：  
sort test.csv (可>输出到新文件)

### echo 不换行

* echo -e 允许对下面列出的加反斜线转义的字符进行解释

```sh
  \n    换行符
  \c    禁止尾随的换行符
  \t    水平制表符
  等等

  echo -e "hello\n"  在原来基础上多加一个换行
  echo -e "hello\c"  不换行
```

* `echo -n "hello"` 也可指定不换行(-n 不输出行尾的换行符)

### 正则表达式

非：  volume:[^0] 匹配"volume:"后接非0的行

### ln

* 链接(或称连接也可，Linux man手册中翻译为"连接"，维基百科中"符号连接"会重定向到"符号链接")
    - [符号链接](https://zh.wikipedia.org/wiki/%E7%AC%A6%E5%8F%B7%E9%93%BE%E6%8E%A5)
    - `ln [-s] 目标 链接名称` 创建一个链接，指向"目标"
        + e.g. `ln -s ~/one/two three`, 创建符号链接(软链接)three，指向目录~/one/two
    - 符号链接(软连接，-s选项创建，Symbolic link or soft link)
        + 指向另一个不同路径文件的一个符号路径
        + 对符号链接文件进行读写的程序会表现得像直接对目标文件进行操作
        + 如果删除一个符号链接，它指向的目标文件不受影响。
        + 如果目标文件被移动、重命名或者删除，任何指向它的符号链接仍然存在，但是它们将会指向一个不复存在的文件。这种情况被有时被称为**被遗弃**。
            * /proc/进程号/fd 中`ls -l`，可看到文件描述符都是链接文件(l)，指向socket的文件在闪烁，说明指向不复存在的文件(被遗弃，此时链接文件背景颜色是高亮的)
    - 硬链接(hard link)
        + 存储了链接建立时它所指向文件的实际数据的文件副本
        + 原始文件被删除后，符号链接将失效，访问软链接时，会提示找不到文件，但硬链接文件还在，而且还保存有原始文件的内容。
        + 修改硬链接文件的内容时，原始文件(被链接的文件)也会被修改
        + `ln` 和标准的 `unlink()` 和 `link()` 函数执行完全一致的操作

### 时区

ll /etc/localtime 查看链接的时区文件

### systemctl

1. 查看系统当前默认启动项目的方法，不再是setup之类的了。
`systemctl list-unit-files`

* systemctl 和 `chkconfig` 区别
    - `systemctl`命令：是一个*systemd*工具，主要负责控制systemd系统和服务管理器。
        + [Systemd 入门教程：命令篇](http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html)
        + Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。
        + 由来：历史上，Linux 的启动一直采用init进程。这种方法有两个缺点。一是启动时间长。二是启动脚本复杂。
            * `/etc/init.d/` (`/etc/init.d`是指向`/etc/rc.d/init.d`的软链接)下面管理开机启动的服务，该目录下README文件做了历史说明(CentOS7)：systemd替换了传统的init脚本，"You are running a systemd-based OS where traditional init scripts have been replaced by native systemd services files"
        + Systemd 就是为了解决这些问题而诞生的。它的设计目标是，为系统的启动和管理提供一套完整的解决方案。
        + 使用了 Systemd，就不需要再用init了。Systemd 取代了initd，成为系统的第一个进程（PID 等于 1），其他进程都是它的子进程。
        + Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。
            * 系统管理
                - `systemctl` 是 Systemd 的主命令，用于管理系统。
                - `systemd-analyze`命令用于查看启动耗时。
                - `hostnamectl` 命令用于查看当前主机的信息。
                - `localectl` 命令用于查看本地化设置
                - `timedatectl`命令用于查看当前时区设置
                - `loginctl`命令用于查看当前登录的用户。
            * Unit
                - Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。Unit 一共分成12种。
                    + Service unit：系统服务
                    + Target unit：多个 Unit 构成的一个组
                    + Device Unit：硬件设备
                    + Mount Unit：文件系统的挂载点
                    + Socket Unit：进程间通信的 socket
                    + Swap Unit：swap 文件
                    + ...
                - `systemctl list-units`命令可以查看当前系统的所有 Unit 。
                - `systemctl status`命令用于查看系统状态和单个 Unit 的状态。
                - `systemctl start apache.service` 立即启动一个服务
                - `systemctl stop apache.service`
                - `systemctl restart apache.service`
                - `systemctl list-dependencies` 命令列出一个 Unit 的所有依赖。
                    + (Unit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。)
                    + `systemctl list-dependencies nginx.service`
                    + 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数：`systemctl list-dependencies --all nginx.service`
            * Unit配置文件
                - 每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。
                    + Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接(symbolic link，软链接)，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录。
                    + 配置文件的后缀名，就是该Unit的种类，比如sshd.socket。**如果省略，Systemd默认后缀名为.service**，所以sshd会被理解成sshd.service。(所以有时执行systemctl可以省略.service，但需要该服务类型确实是service)
                - `systemctl list-unit-files` 列出所有配置文件
                - `systemctl enable` 命令用于在上面两个目录之间，建立*符号链接关系*。如果配置文件里面设置了**开机启动**，该命令相当于激活开机启动。
                    + `systemctl enable docker.service` 开机启动docker服务
                - `systemctl disable` 命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动
                - 每个配置文件的状态，一共有四种(systemctl list-unit-files结果列表中各服务状态)。
                    + enabled：已建立启动链接
                    + disabled：没建立启动链接
                    + static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖
                    + masked：该配置文件被禁止建立启动链接
                - `systemctl status`
                    + 从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行systemctl status命令。
            * Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用`journalctl`一个命令，查看所有日志（内核日志和应用日志）
                - `journalctl` 查看所有日志（默认情况下 ，只保存本次启动的日志）
                - `journalctl -k` 查看内核日志（不显示应用日志）
                - `journalctl -b` 查看系统本次启动的日志
            * 争议
                - 事实上，现在还有很多人反对使用 Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反"keep simple, keep stupid"的Unix 哲学。
                - [systemd 为什么会有那么大的争议？](https://www.zhihu.com/question/25873473)
    - `service`命令：可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。
        + `service mysqld start/stop` 命令启动/关闭MySQL实例(非开机启动)
    - `chkconfig`命令：是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。
        + chkconfig命令主要用来更新（启动或停止）和查询系统服务的运行级信息。
        + 谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号链接。
        + `chkconfig --list` 查看开机自启动的服务
            * 只查看MySQL服务 `chkconfig --list mysqld`
            * 配置MySQL的开机自动启动 `chkconfig --add mysql`; `chkconfig mysqld on`
    - `systemctl` 实际上将 service 和 chkconfig 这两个命令整合到一起。在CentOS 7就开始被使用了。
        + 使某服务自动启动(开机启动)
            * 旧指令: `chkconfig --level 3 httpd on`, 新指令: `systemctl enable httpd.service`
        + 使某服务不自动启动
            * 旧指令: `chkconfig --level 3 httpd off`, 新指令: `systemctl disable httpd.service`
        + 检查服务状态
            * 旧指令: `service httpd status`, 新指令: `systemctl status httpd.service` `systemctl is-active httpd.service`(仅显示是否 Active)
        + 显示所有已设置开机启动的服务
            * 旧指令: `chkconfig --list`, 新指令: `systemctl list-units --type=service`
        + 启动/停止/重启某服务
            * 旧指令: `service httpd start/stop/restart`, 新指令: `systemctl start/stop/restart httpd.service`

运行`chkconfig --list`后结果有如下说明(CentOS)：

```
注：该输出结果只显示 SysV 服务，并不包含
原生 systemd 服务。SysV 配置数据
可能被原生 systemd 配置覆盖。

      要列出 systemd 服务，请执行 'systemctl list-unit-files'。
      查看在具体 target 启用的服务请执行
      'systemctl list-dependencies [target]'。
```

2. 取消mysqld的自启动
`systemctl disable mysqld`

查看状态，先status
`systemctl status mysqld.service`

### service

`systemctl status mysqld` 执行和 `service mysqld status` 类似

* service是一个shell脚本，其中包装了systemctl
    - `which service`执行获取完整路径：/usr/sbin/service
    - vi /usr/sbin/service 里面是shell脚本，基于systemctl执行命令

### cpu信息

* `lscpu`
    - 会列出CPU型号、名称、架构、频率、位数、大小端、逻辑CPU个数、每个核心支持的线程数、物理座数等

或者手动过滤查看：  
cpu信息在 /proc/cpuinfo中，根据grep过滤关键字，并配合uniq/sort/wc来过滤重复/排序/计数，统计各信息

* 查看物理CPU的个数(实际物理cpu的个数)

`cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l`

* 查看CPU是几核心(物理核数，每个cpu的物理核数，若有多个物理cpu，核心数都一样就一条记录)

`cat /proc/cpuinfo |grep "cores"|uniq`

* 查看逻辑CPU的个数(若该cpu支持超线程，则1个物理核对应2个逻辑核/线程。 若支持超线程则与物理核是两倍的关系)

`cat /proc/cpuinfo |grep "processor"|wc -l`

超线程计数可以理解为：一颗CPU当成两颗来用，将一颗具有超线程功能的物理CPU变成两颗逻辑CPU，而逻辑CPU对操作系统来说，跟物理CPU并没有什么区别。

超线程介绍：[图说超线程技术(Hyper-Threading Technology)](https://www.cnblogs.com/idorax/p/6884088.html)

获取开发环境配置：

```sh
echo -n "cpu个数: "
cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l
echo -n "cpu核数: "
cat /proc/cpuinfo |grep "cores"|uniq
echo -n "逻辑核数: "
cat /proc/cpuinfo |grep "processor"|wc -l

echo -n "操作系统: "
cat /etc/redhat-release
echo -n "gcc版本: "
gcc -v
```

### yum

* yum
    - yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。
    - 基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。
    - 命令形式一般如下：`yum [options] [command] [package ...]`
        + [options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为"yes"），-q（不显示安装的过程）等等。
        + [command]为所要进行的操作，[package ...]是操作的对象。
    - 安装
        + `yum install package1` 安装指定的安装包package1
        + `yum groupinsall group1` 安装程序组group1
    - 更新和升级
        + `yum update package1` 更新指定程序包package1
        + `yum check-update` 检查可更新的程序
        + `yum upgrade package1` 升级指定程序包package1
    - 查找和显示
        + `yum info package1` 显示安装包信息package1
            * e.g. `yum info sysstat`，结果里会展示：名称、架构、版本、大小、源、简介、协议、描述、已安装、可安装 等信息
        + `yum list` 显示所有已经安装和可以安装的程序包
        + `yum list package1` 显示指定程序包安装情况package1(会展示指定的已安装和可安装的包)
    - 删除程序
        + `yum remove package1` 或 `yum erase package1` 删除程序包package1
    - 清除缓存
        + `yum clean packages` 清除缓存目录下的软件包
    - [linux yum命令详解](cnblogs.com/chuncn/archive/2010/10/17/1853915.html)

## watch

`watch -n1 -d` -d高亮改变的位置

## valgrind

valgrind ./simulate_server --leak-check=full --show-leak-kinds=definite

## mysql
安装Mysql 8.0
[CentOS 7 安装 Mysql 8.0 教程](https://blog.csdn.net/danykk/article/details/80137223)
1）配置Mysql 8.0安装源
sudo rpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm
2）安装Mysql 8.0
sudo yum --enablerepo=mysql80-community install mysql-community-server

## samba 将linux映射为网络驱动
Samba
  Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成。
    SMB（Server Message Block）通信协议是微软（Microsoft）和英特尔(Intel)在1987年制定的协议，主要是作为Microsoft网络的通讯协议。SMB 是在会话层（session layer）和表示层（presentation layer）以及小部分应用层（application layer）的协议。

    SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。

Linux操作系统提供了 Samba服务，为了实现Window主机与Linux服务器之间的资源共享，Samba服务为两种不同的操作系统架起了一座桥梁，使 Linux 系统和Window系统之间能够实现互相通信。

[CentOS服务器的目录映射为Windows磁盘驱动器](https://blog.csdn.net/u010480282/article/details/80518836)

安装->修改配置文件->添加用户组、添加用户->开启服务, \\ip\自定义共享路径，或者/home/下的用户路径

/etc/samba/smb.conf

```
global中
  ; 新增配置begin
    encrypt passwords = yes
    smb passwd file = /etc/samba/smbpasswd
; 自定义共享名称
[xdroot]
    workgroup = samba
    netbios name = xd
    ; 共享描述
    comment = share root
    ; 共享路径
    path = /
    ;设置共享是否可浏览，如果no就表示隐藏，需要通过IP+共享名称进行访问
    browseable  =  yes
    ;设置共享是否具有可写权限
    writable = yes
    ;设置共享是否具有只读权限
    read only  = no
    printable = yes
```

#### 用户组和防火墙
将用户添加到用户组，而不离开原有组(-a选项)
usermod -a -G samba xd
smbpasswd -a xd

关闭防火墙 service firewalld stop
selinux

systemctl list-unit-files|grep firewalld

关闭开机启动
systemctl disable firewalld.service

## 给用户赋root权限

vi /etc/sudoers，找到下面位置并添加用户记录(输入`visudo`回车可编辑即该文件，sudoers本身是没有写权限的，先chmod +w，改完再chmod -w)

* 建议使用：`visudo` (上面chomd操作规避了权限问题)

```sh
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
新用户名 ALL=(ALL) ALL （添加这一行）
```

## centos7 mongodb c++驱动安装

翻译：
[mongodb c++ 驱动](https://www.jianshu.com/p/c982a2960175)
  1. 安装c驱动
  2. 下载最新的 mongocxx driver
     git clone https://github.com/mongodb/mongo-cxx-driver.git --branch releases/stable --depth 1
     cd mongo-cxx-driver/build
  3. 配置驱动
     cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local ..
  4. 编译和安装驱动
     若用默认的 MNMLSTC 的C++17 `make EP_mnmlstc_core` (实际安装未执行该步，不确定是否有影响，make正常安装成功)
     make && make install

[mongodb c 驱动](https://www.jianshu.com/p/d77680254418) (第一步安装c驱动，翻译链接)

```sh
  $ wget https://github.com/mongodb/mongo-c-driver/releases/download/1.13.0/mongo-c-driver-1.13.0.tar.gz
  $ tar xzf mongo-c-driver-1.13.0.tar.gz
  $ cd mongo-c-driver-1.13.0
  $ mkdir cmake-build
  $ cd cmake-build
  $ cmake -DENABLE_AUTOMATIC_INIT_AND_CLEANUP=OFF ..

  $ make
  $ make install
```

官网：
[Installing the mongocxx driver](http://mongocxx.org/mongocxx-v3/installation/)

**注意下载安装包最好到官网,博客中下载链接可能是很老的包**

## mongodb安装
[Linux平台安装MongoDB](https://www.runoob.com/mongodb/mongodb-linux-install.html)
curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.12.tgz   # 下载 (对应版本修改下)
tar -zxvf mongodb-linux-x86_64-3.0.6.tgz                                   # 解压
mv  mongodb-linux-x86_64-3.0.6/ /usr/local/mongodb                         # 将解压包拷贝到指定目录

MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中：

export PATH=<mongodb-install-directory>/bin:$PATH
<mongodb-install-directory> 为你 MongoDB 的安装路径。如本文的 /usr/local/mongodb 。

  创建数据库目录
MongoDB的数据存储在data目录的db目录下，但是这个目录在安装过程不会自动创建，所以你需要手动创建data目录，并在data目录中创建db目录。
`mkdir -p /data/db`

  命令行中运行 MongoDB 服务
`$ ./mongod`

MongoDB后台管理 Shell
如果你需要进入MongoDB后台管理，你需要先打开mongodb装目录的下的bin目录，然后执行mongo命令文件。

MongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。

当你进入mongoDB后台后，它默认会链接到 test 文档（数据库）：

```sh
$ cd /usr/local/mongodb/bin
$ ./mongo
MongoDB shell version: 3.0.6
connecting to: test
Welcome to the MongoDB shell.
……
```

## 灰度发布

参考百度百科：
[灰度发布](https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83)

* 灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。
    - 在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。
    - 灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。

* 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。

* 作用： 及早获得用户的意见反馈，完善产品功能，提升产品质量 让用户参与产品测试，加强与用户互动 降低产品升级所影响的用户范围

本质上灰度测试可以算作A/B测试的一种特例

> 灰度发布与互联网公司常用A/B测试似乎比较类似，国外互联网公司似乎并没有所谓的灰度发布的概念。
> 按照wikipedia中对A/B测试的定义，A/B测试又叫：A/B/N Testing、Multivariate Testing，因此本质上灰度测试可以算作A/B测试的一种特例。

* 步骤：
    - 1）定义目标
    - 2）选定策略：包括用户规模、发布频率、功能覆盖度、回滚策略、运营策略、新旧系统部署策略等
    - 3）筛选用户：包括用户特征、用户数量、用户常用功能、用户范围等
    - 4）部署系统：部署新系统、部署用户行为分析系统（web analytics）、设定分流规则、运营数据分析、分流规则微调
    - 5）发布总结：用户行为分析报告、用户问卷调查、社会化媒体意见收集、形成产品功能改进列表
    - 6）产品完善
    - 7）新一轮灰度发布或完整发布

## QT

[Qt Downloads](http://download.qt.io/archive/qt/) 环境搭建(官网的下载链接点击进去找不到界面)

## UML类图

[UML类图与类的关系详解](http://uml.org.cn/oobject/201104212.asp)

[UML——在Visual Studio 2013/2015中设计UML类图](https://www.cnblogs.com/SceneryHao/p/5355915.html)

Unified Modeling Language (UML)又称统一建模语言或标准建模语言。

简单说就是以图形方式表现模型，根据不同模型进行分类

常用 UML 动态图（5 个）：用例图，活动图，状态机图，序列图，通信图。
常用 UML 静态图（4 个）：类图，包图，部署图，构件图。

在所有UML图中，类图是使用频率最高的UML图。
类图用于描述系统中所包含的类以及它们之间的相互关系，帮助人们简化对系统的理解，它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。

类图主要关系有：泛化（Generalization）,  实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)

* 泛化（Generalization)
    - 【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。
    - 【代码体现】：类继承另一个类
    - 【箭头指向】：带三角箭头的实线，箭头指向父类

## sysctl

* sysctl
    - 参见man手册
    - 在运行时修改内核参数
    - 系统会从按顺序从一系列配置文件中加载配置
        + /run/sysctl.d/*.conf
        + /etc/sysctl.d/*.conf
        + /usr/local/lib/sysctl.d/*.conf
        + /usr/lib/sysctl.d/*.conf
        + /lib/sysctl.d/*.conf
        + /etc/sysctl.conf 这个配置在修改内核参数时也是经常用的
    - `sysctl -p[FILE]` 从指定的文件中加载配置，如果没有指定则默认从 /etc/sysctl.conf
    - `sysctl -a` 展示当前所有可用配置的值

## /etc/security/limits.conf

* /etc/security/limits.conf
    - limits.conf文件介绍
        + 是Linux PAM (插入式认证模块，Pluggable Authentication Modules)中 pam_limits.so 的配置文件
        + pam_limits模块对 `用户的会话` 进行 `资源限制`。
            * 一个shell的初始limits就是由pam_limits设定的
    - 配置格式：`<domain>        <type>  <item>  <value>`
        + e.g. `@root           hard    core    307200`
        + `<domain>` 可以指定用户(用户)、组(@组名)、`*`和`%`通配符
        + `<type>` 两种形式
            * "soft" 软限制
                - soft指的是当前系统生效的设置值，软限制也可以理解为警告值
            * "hard" 硬限制
                - hard表明系统中所能设定的最大值
                - soft的限制不能比hard限制高
                - 配置文件中用`-`表明同时设置了soft和hard的值。
            * **soft和hard需要都进行设置,才能生效**
        + `<item>` 项目
            * `ulimit -a`可以查看一些配置项，也可以通过ulimit临时设置配置项
        + `<value>` 取值
    - 配置文件说明可以参考：[/etc/security/limits.conf 详解与配置](https://www.cnblogs.com/operationhome/p/11966041.html)
    - 临时设置
        + `ulimit -SHn 65536` 重启后会失效(可以启动程序前进行一次设置，以免影响设备全局)
        + `ulimit` 命令
            * `-H` 和 `-S` 指定为所给资源设定的**硬性**和**柔性**限额
            * 针对对应的资源项，实际使用资源在达到设置的硬性限额后不能增加；达到设置的柔性限额后可以增加，直到与硬性限额相等。
            * 如果没有给出 `-H` 或 `-S` 选项，将同时设置硬性和柔性限额。
    - 永久配置
        + 配置到配置文件`/etc/security/limits.conf`或者 `/etc/security/limits.d/` 中
        + 重新生效：退出当前会话，重新登录；或者重启
* 注意
    - /etc/security/limits.d/ 下文件的相同配置可以覆盖 /etc/security/limits.conf
    - nofile不能设置 unlimited
    - nofile可以设置的最大值为 1048576(2**20)，设置的值大于该数，就会进行登录不了。
    - soft 设置的值 一定要小于或等于 hard 的值。(如果soft值更大，也只会限制为hard设置的值)
* 通过该配置的调整解决了zabbix远程命令启动的进程无法生成core文件的问题(hard限制的问题)
    - 试过：
        + 在.bashrc中添加 `ulimit -S -c unlimited`,`ulimit -c 307200`(300MB)
        + 启动程序前`ulimit -S -c unlimited`
        + `/etc/security/limits.conf`中添加root组限制，但是只开了soft
        + 环境和正常环境有点特别：配置了zabbix远程监控主机上的进程，当进程不存在时执行启动脚本进行启动
            * 本地终端启动进程，然后发送段错误信号`kill -s SEGV pid`，能正常生成core文件
            * 但是通过zabbix远程启动(sudo xxx.sh,zabbix添加进sudoers免密中)的进程，不能正常生成core
    - 原因是对`-S`和`-H`的理解模糊导致的问题(关于含义参见上面说明)
    - 解决方法一：最终在`limits.conf`中新增hard配置后解决(zabbix添加进了root组， 若没有添加进group保险起见可以单独配置zabbix组或者用户)
        + `@root               soft    core            307200`
        + `@root               hard    core            307200`
    - 解决方法二：意识到是由于hard项的配置问题，把`limits.conf`中配置还原后(即啥都不动)，在启动脚本中单独`ulimit -SH -c 307200`，也可正常生成core文件
    - 另外，需要注意环境变量的问题：通过重启来重新加载环境变量(或重新登录重新让.bashrc中的配置生效)，需要注意的是通过脚本操作时，其当前对应的环境变量与系统可能是不一样的(像crontab里根本就不用系统环境变量而需要其进行一下source)

## core

* 允许生成 core文件
    - [Linux生成core文件、core文件路径设置](https://blog.csdn.net/u011417820/article/details/71435031)
    - `ulimit -c 设置大小`
        + 注意在终端敲命令执行ulimit时，只会影响本终端，其他终端起的进程并不会受影响，所以在启动服务的终端设置
        + 在系统配置中修改：`/etc/security/limits.conf`，或者.bashrc中添加
    - `/etc/sysctl.conf`
        + 添加配置项：kernel.core_pattern="/corefile/core-%e-%p-%t"，然后`sysctl -p`生效，会改变`/proc/sys/kernel/core_pattern`中的值
        + `/proc/sys/kernel/core_pattern` 临时设置core文件保存位置和文件名格式
            * **重启后会恢复，完全生效需修改sysctl.conf**
        + "|/usr/libexec/abrt-hook-ccpp %s %c %p %u %g %t e %P %I %h" CentOS7默认内容
            * 注意最后的`/`后面是文件命名格式
            * `%p` 添加pid
            * `%u` 添加当前uid
            * `%g` 添加当前gid
            * `%s` 添加导致产生core的信号
            * `%t` 添加core文件生成时的unix时间
            * `%h` 添加主机名
            * `%e` 添加导致产生core的命令名(触发core生成的进程/线程名，不过名称可能不完整)(建议程序中单独设置线程名)
        + 通过echo来修改内容，vi修改貌似保存不了
            * `echo "/corefile/%e.core.%p.%t" > /proc/sys/kernel/core_pattern`
            * 注意设置的目录需要存在(提前新建好)，否则不会生成core文件
        + 由于corefile都比较大，需要监控生成core文件的个数，防止磁盘被占满
            * 建议的实践是固定一个存储位置(如/corefile/)并进行脚本监控个数，下面附自己写的监控脚本，脚本执行可添加到crontab中
    - `kill`
        + `kill -l` 打印信号列表，(man中提示在`/usr/include/linux/signal.h`也可找到，看了下内容只#define了两个宏。。)
        + `kill -s` 指定发送的信号，信号可以以*信号名*或者数字发送

```sh
#!/bin/bash
# check_core.sh 监控core文件
CORE_DIR=/corefile
CHECK_LOG_FILE=check.log

function check_create_dir()
{
    NEED_DIR=$1
    if [ ! -d ${NEED_DIR} ]; then
        mkdir ${NEED_DIR}
    fi
}

function check_log_size()
{
    MAX_LOG_SIZE=$((1024*1024*30))

    CHECK_SIZE_LOG_FILE=$1
    OPS_LOG_FILE_SIZE=`ls -l ${CHECK_SIZE_LOG_FILE} | awk -F' ' '{ print $5}'`
    echo "[$(date)], file[${CHECK_SIZE_LOG_FILE}] size:${OPS_LOG_FILE_SIZE}" >> ${CHECK_SIZE_LOG_FILE}
    # 大于30M则重新生成
    if [ $OPS_LOG_FILE_SIZE -gt ${MAX_LOG_SIZE} ]; then
        echo "[$(date)], file[${CHECK_SIZE_LOG_FILE}] size:${OPS_LOG_FILE_SIZE} over $((${MAX_LOG_SIZE}/1024/1024)) MB, recover" > ${CHECK_SIZE_LOG_FILE}
    fi
}


check_create_dir ${CORE_DIR}

cd ${CORE_DIR}
if [ $? -ne 0 ]; then
    echo "[$(date)], cd ${CORE_DIR} error, exit!"
    exit -1
fi
echo "[$(date)], cd ${CORE_DIR}" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}

# 过滤日志文件后的文件数量
corefile_num=`ls -I ${CHECK_LOG_FILE}|wc -l`
echo "[$(date)], file num:${corefile_num}" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}
# 超过n个core则只保留最近的n个
if [ ${corefile_num} -gt 3 ]; then
    echo "[$(date)], file num:${corefile_num} over 3!" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}
    filelist=`ls -I ${CHECK_LOG_FILE} -t`
    i=0
    for file in ${filelist}
    do
        ((i++))
        if [ $i -le 3 ]; then
            continue
        fi
        echo "[$(date)], rm:[$(file ${file})], i:$i" | tee -a ${CORE_DIR}/${CHECK_LOG_FILE}
        # 避免rm -rf ${a}/${b}形式的语句，防止a为空导致误操作/目录
        rm -rf ${file}
    done
fi

# 日志文件大小限制
check_log_size ${CORE_DIR}/${CHECK_LOG_FILE}
```

## gdb

* [gdb官网文档](http://www.gnu.org/software/gdb/documentation/)
    - [Debugging with GDB](https://sourceware.org/gdb/current/onlinedocs/gdb/)
        + 生成core：[10.19 How to Produce a Core File from Your Program](https://sourceware.org/gdb/current/onlinedocs/gdb/Core-File-Generation.html#Core-File-Generation)
        + core文件/core dump文件：记录正在运行的进程的内存映像及其进程状态的文件
        + 它的主要用途是对在调试器之外运行时崩溃的程序进行事后调试
        + 也可以从正在执行的程序生成一个core文件：
            * `usage:  gcore [-a] [-o filename] pid` 没有指定名称则默认"core.pid"
    - 支持语言：C/C++、Go、Objectiv-C、Rust 等(不怎么耳熟的未列)
        + [Supported Languages](https://sourceware.org/gdb/current/onlinedocs/gdb/Supported-Languages.html#Supported-Languages)

* gcc -g选项：以操作系统的本地格式(stabs, COFF, XCOFF, 或 DWARF). 产生调试信息. GDB 能够使用这些调试信息.

* 升级gcc 4.8.5
[CentOS升级gcc4.4.7到gcc4.8.5](https://blog.csdn.net/shine_journey/article/details/62039381)

* 断点
    - 添加
        + `break` / `b`, 四种形式
            * break line-number                    在执行给定行之前
            * break function-name                  在进入指定的函数之前
            * break line-or-function if condition  如果condition（条件）是真，程序到达指定行或函数时停止
            * break routine-name                   在指定例程的入口处设置断点
        + 可以在各个原文件中设置断点
            * break filename:line-number
            * break filename:function-name
        + 回车会在上一个位置再次设置一个端点
    - 查看
        + `info break`
    - 删除
        + `delete`
            * delete 5 (指定编号)
            * delete 1-10(连续的断点号)
        + `clear`
            * clear list.c:12           //删除文件：行号的所有断点
            * clear 12                  //删除行号的所有断点
            * clear list.c:list_delet   //删除文件：函数的所有断点
            * clear 删除断点是基于行的，不是把所有的断点都删除
    - 临时断点
        + 在使用gdb调试时，如果想让断点只生效一次，可以使用`tbreak`命令（缩写为`tb`），和设置断点的过程一样
            * 临时断点13显示:*del*, 普通断点:*keep*
    - 条件断点
        + `break 行号 if 条件`，意思是只有在条件满足的时候，断点才会被触发
        + `b 222 if i==100` (i为100时触发断点)
    - 忽略断点
        + 在设置了断点之后，可以使用命令`ignore 断点编号i cnt`来忽略断点，意思是接下来的cnt次编号为i的断点触发都不会让程序暂停，只有第cnt+1次断点触发才会让程序暂停

```sh
# 临时断点
Num     Type           Disp Enb Address            What
13      breakpoint     del  y   0x0000000000415383 in Thread_func(void*) at src/func.cpp:224
14      breakpoint     keep y   0x0000000000415353 in Thread_func(void*) at src/func.cpp:222
```

### 遇到过的问题记录

* 收到：signal SIGABRT，程序退出

```golang
//gdb程序报错退出
// (发现问题是root用户编译，用普通用户执行的，push_back()时就报这个退出了，奇葩问题奇葩操作...):
Program received signal SIGABRT, Aborted.

terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7ffff070f700 (LWP 12784)]
0x00007ffff5573207 in raise () from /lib64/libc.so.6

//bt查看:
(gdb) bt
#0  0x00007ffff5573207 in raise () from /lib64/libc.so.6
#1  0x00007ffff55748f8 in abort () from /lib64/libc.so.6
#2  0x00007ffff609d445 in __gnu_cxx::__verbose_terminate_handler () at ../../../../libstdc++-v3/libsupc++/vterminate.cc:95
#3  0x00007ffff609b5d6 in __cxxabiv1::__terminate (handler=<optimized out>)
    at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:38
#4  0x00007ffff609b603 in std::terminate () at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:48
#5  0x00007ffff609b823 in __cxxabiv1::__cxa_throw (obj=0x7fffe0013ce0, tinfo=0x7ffff6322b00 <typeinfo for std::bad_alloc>,
    dest=0x7ffff6099cd0 <std::bad_alloc::~bad_alloc()>) at ../../../../libstdc++-v3/libsupc++/eh_throw.cc:87
#6  0x00007ffff609bd1d in operator new (sz=18446744073709551600) at ../../../../libstdc++-v3/libsupc++/new_op.cc:56
#7  0x00000000004259e8 in __gnu_cxx::new_allocator<TestResult>::allocate (this=0x7ffff070eb20, __n=256204778801521550)
    at /usr/local/include/c++/4.8.5/ext/new_allocator.h:104
#8  0x0000000000421ec5 in std::_Vector_base<TestResult, std::allocator<TestResult> >::_M_allocate (
    this=0x7ffff070eb20, __n=256204778801521550) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:168
#9  0x0000000000525324 in std::vector<TestResult, std::allocator<TestResult> >::_M_emplace_back_aux<TestResult const&> (this=0x7ffff070eb20) at /usr/local/include/c++/4.8.5/bits/vector.tcc:404
#10 0x00000000005212d5 in std::vector<TestResult, std::allocator<TestResult> >::push_back (
    this=0x7ffff070eb20, __x=...) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:911
```


## 线程

* pthread_create 创建分离线程后，传入的参数应该立即(*应该usleep一定的时间*,e.g. 1ms), 在线程中新建存储区进行存储，不应该一直使用外部的地址。

## perf

* centos安装 `yum install perf`
* ubuntu安装 `apt install linux-tools-common`
* 需要以root用户运行
* `perf top [-g] -p 进程号`， 查看cpu使用率高问题
    - -g: Enables call-graph (stack chain/backtrace) recording，启用调用图记录
* `perf record [-o filename]` 和 `perf report`
    - `perf top` 虽然实时展示了系统的性能信息，但它的缺点是并不保存数据，也就无法用于离线或者后续的分析。
    - 而 `perf record` 则提供了保存数据的功能，保存后的数据，需要你用 `perf report` 解析展示
    - `perf record [-g]`，一段时间后按Ctrl+C终止采样； 再执行`perf report`，展示类似于perf top的报告
        + 在实际使用中，我们还经常为其加上-g参数，开启调用关系的采样，方便我们根据调用链来分析性能问题。
    - `-a` 来自所有CPU的全系统范围的收集
    - 可以配合sleep使用，自动记录一段时间 `perf record -a sleep 10` (记录10s)
        + **注意**： 此处若不加`-a`指定所有cpu，则跟踪到的只有`sleep`的调用堆栈
    - 可以配合`火焰图`对文件处理更直观地进行分析(后面有记录用法，按关键词`火焰图`搜索笔记)
* `perf script`
    - 读取`perf record`生成的perf.data文件，并展示跟踪输出，e.g. `perf script -i perf.data > perf.unfold`
    - `perf record` 生成的文件类型是`data`(二进制数据,`file perf.data`查看)，而`perf script`生成的文件类型是`ASCII text`
    - 语法格式：
        + `perf script [<options>]` 查看记录下来的perf.data文件对应的：工作负载的详细跟踪
            * -i 指定输入文件名(不指定则默认读取perf.data)
        + 还可以运行一组预录制的脚本，它们以各种方式聚合和汇总原始跟踪数据：
            * `perf script [<options>] record <script> [<record-options>] <command>`
                - <script>指定跟踪的脚本，可以通过：`perf script --list`或`perf script -l` 查看可用的脚本名
            * `perf script [<options>] report <script> [script-args]`
            * man perf script查看更多用法和选项

* `while(1) {dosomething();}`，或者直接`while(1) {}` cpu使用率100%问题
    - Unix系统使用cpu通过时间片轮转(而Windows则属于抢占式的，进程主动放弃使用CPU)，while(1){}会持续占用cpu，导致cpu使用率很高
    - 在while体中添加usleep(1000)，即sleep 1ms，cpu使用率大大降低
    - 在while体中，若当次不执行任何操作，建议添加一个短的等待时间(**包含不满足继续条件直接continue,不执行任何其他语句的情况**)
    - 中断
        + 内核统计程序占的CPU是通过时钟中断完成的，当时钟中断发生时候，通过IP记数器(程序计数器PC)找到发生前正在运行的程序。
        + 程序不做事情时，进入内核中的 idle() 程序，等待中断唤醒。而该程序使CPU处于休息状态，将CPU的系统时钟频率调整到很低，此时会比较省电，风扇不转，然后在这个状态下循环等待

>理想情况下，假设原本执行一次循环只需要消耗10个CPU周期的话，如果不进行阻塞，2Ghz的CPU在一秒内会执行2*10^9/10=2*10^8次的循环，然而在1秒内执行那么多次循环对我们的程序一点帮助都没有，还会抢占CPU资源；而阻塞该程序1ms后，相当于每进行一次循环后就让出1ms的运算资源，也就是让出2*10^6个cpu周期，原本占用100%的程序只会占用不到1万次CPU周期，这对于2Ghz的CPU来说几乎是0负担的。 [CPU占用率100%](https://cloud.tencent.com/developer/article/1327007)

## strace

strace -p进程号或者线程号

## stress

* stress是一个Linux系统压力测试工具，可模拟CPU、IO、内存负载
    - 先`yum install -y epel-release`, 再 `yum install -y stress`
        + EPEL (Extra Packages for Enterprise Linux)是基于Fedora的一个项目，为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux.
        + 首先我们需要安装一个叫”epel-release”的软件包，这个软件包会自动配置yum的软件仓库。当然你也可以不安装这个包，自己配置软件仓库也是一样的。 软件仓库配置目录在：`/etc/yum.repos.d/`

* 使用
    - `-t N` 或 `--timeout N`：运行秒数
    - `-c N` 或 `--cpu N`：产生多个处理sqrt()函数的CPU进程
        + `stress -c 2 -t 10` 其两个进程测CPU，跑10s
    - `-i N` 或 `--io N`：产生多个处理sync()函数的磁盘I/O进程
    - `-m N` 或 `--vm N`：产生多个处理malloc()/free()内存分配函数的进程
        + `--vm-bytes B`：指定内存的byte数为B，默认值是256MB
        + `--vm-hang N`：指定malloc分配的内存多少秒后free()释放掉，默认不释放，0无效
    - `-d N` 或 `--hdd N`：产生多个处理write()/unlink()的进程
        + `--hdd-bytes B`：指定每个hdd进程处理的byte字节数，默认1GB

## mpstat

[mpstat命令](https://man.linuxde.net/mpstat)

* mpstat
    - mpstat命令指令主要用于多CPU环境下，它显示各个可用CPU的状态信息，包括硬件软件中断信息。
    - 这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。
    - 包含在 sysstat 软件包中，`yum info sysstat`查看该软件包信息(CentOS)
    - `mpstat [ -A ] [ -u ] [ -V ] [ -I { SUM | CPU | SCPU | ALL } ] [ -P { cpu [,...] | ON | ALL } ] [ interval [ count ] ]` (最后两个参数用于指定间隔和次数)
    - `mpstat (选项) (参数)`
        + 选项-P：指定CPU编号，指定-P ALL 则显示所有逻辑CPU列表，并会显示一个all的统计
        + 参数 间隔时间：每次报告的间隔时间（秒）；
        + 参数 次数：显示报告的次数。
        + e.g. `mpstat -P ALL 5 2` 所有CPU，间隔5S，只显示2次(参数和选项均为可选)
    - 当mpstat不带参数时，输出为从系统启动以来的平均值，*默认打印CPU*使用报告
    - The mpstat command can be used both on SMP and UP machines
        + UP（Uni-Processor）：系统只有一个处理器单元，即单核CPU系统
        + SMP（Symmetric Multi-Processors）：系统有多个处理器单元。各个处理器之间共享总线，内存等等。 在操作系统看来，各个处理器之间没有区别。
    - 更新sysstat包：新版本中(11.5.5版本以后)才开始有 %iowait列，下载github上的最新版本，目前12.3.1
        + 链接：[github](https://github.com/sysstat/sysstat)
        + `yum remove sysstat`，然后解压后编译安装 `./configure; make; make install`

```sh
[➜ /home/xd/ ]$ mpstat -P ALL 3 #间隔3s，该虚拟机环境有两个逻辑CPU
Linux 3.10.0-957.el7.x86_64 (localhost.localdomain)     2019年11月25日     _x86_64_    (2 CPU)

13时56分13秒  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
13时56分16秒  all   48.71    0.00    0.00    0.00    0.00    0.17    0.00    0.00    0.00   51.11
13时56分16秒    0   91.17    0.00    0.00    0.00    0.00    0.35    0.00    0.00    0.00    8.48
13时56分16秒    1    8.31    0.00    0.33    0.00    0.00    0.33    0.00    0.00    0.00   91.03
```

* 含义
    - CPU CPU编号(all为平均)
    - %usr
        + 在用户态的CPU使用率
    - %nice
        + 在用户态以nice等级执行时的CPU使用率
            * nice/renice设置nice值为非0时，CPU跑在%nice等级上，看mpstat里%usr的使用率会比较小，大部分使用率在%nice列
            * nice默认0时，%nice列是0.00
    - %sys
        + 内核态的CPU使用率(注意不包含硬件和软件中断的时间)
    - %iowait
        + 系统有未完成的磁盘IO请求时，CPU闲置状态的时间百分比
    - %irq
        + CPU为服务硬件中断的时间百分比
    - %soft
        + CPU为服务软件中断的时间百分比
    - %steal
        + 管理程序为另一个虚拟处理器提供服务时，虚拟CPU非自愿等待所花费的时间百分比
    - %guest
        + CPU运行一个虚拟处理器花费的时间百分比
    - %gnice
        + CPU运行一个设置了nice的客户机花费的时间百分比
    - %idle
        + CPU处于空闲状态且系统没有未完成的磁盘I/O请求时的时间百分比

## pidstat

* pidstat
    - [pidstat 命令详解](https://www.jianshu.com/p/3991c0dba094)
    - 报告Linux任务的统计数据
    - `pidstat [ 选项 ] [ <时间间隔> ] [ <次数> ]`
    - 选项
        + `-p` 指定进程号
        + -u 默认，显示各个进程的cpu使用统计
            * `UID       PID   %usr %system  %guest   %wait    %CPU   CPU  Command`
            * UID:被监视任务的真实用户标识号;
            * %usr:用户态CPU使用率; %system:内核态CPU使用率; %guest:运行在虚拟机中的CPU使用率
            * %wait: 等待运行的CPU使用率; %CPU: 总的CPU使用率; CPU: CPU号
        + -d，显示各进程IO使用情况
            * `UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command`
            * 每秒从磁盘读取的KB、写入磁盘KB、任务取消的写入磁盘的KB(当任务截断脏的pagecache的时候会发生)、io延迟
        + -r，显示页面错误和内存使用情况
            * `UID       PID   minflt/s  majflt/s     VSZ     RSS   %MEM  Command`
            * minflt/s: 每秒 次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数
            * majflt/s: 每秒 主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时， 相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生
            * VSZ: 该进程使用的虚拟内存(以kB为单位)
            * RSS(常驻集大小): 该进程使用的物理内存(非交换物理内存，以kB为单位)
            * %MEM: 该进程使用内存的百分比
        + -w，显示每个进程的上下文切换情况
            * `UID       PID   cswch/s nvcswch/s  Command`
        + -t，显示选择任务的线程的统计信息外的额外信息
            * `UID      TGID       TID   cswch/s nvcswch/s  Command`
            * TGID:线程组leader的标识号;
            * TID:被监控的线程标识号
        + -l，显示命令名和所有参数(Command列会展示完整的执行命令)
            * e.g. Command列显示完整的`pidstat -l 2`，不加-l则只显示`pidstat`
    - pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。(**不加-t则不统计线程，注意**)

## vmstat

* vmstat
    - 报告虚拟内存的统计信息
    - vmstat  对系统的进程情况、内存使用情况、交换页和I/O块使用情况、中断以及CPU使用情况进行统计并报告相应的信息。
    - 需要特别关注的四列内容：
        + cs（context switch）是每秒上下文切换的次数
        + in（interrupt）则是每秒中断的次数
        + r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
        + b（Blocked）则是处于不可中断睡眠状态的进程数。
    - vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用 `pidstat` 了
        + 加上 -w 选项 `pidstat -w 2`
        + 两列内容是我们的重点关注对象
            * 一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数
                - **自愿上下文切换**，是指进程无法获取所需资源，导致的上下文切换。
                - 比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
            * 另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。
                - **非自愿上下文切换**，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。
                - 比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

* `vmstat`结果示例:

```
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 9  0      0 672340   2116 561728    0    0     0     0 2742  266 99  1  0  0  0
 8  0      0 672204   2116 561736    0    0     0     0 2754  254 99  1  0  0  0
```

* `pidstat -w 2`结果示例：

```
15时28分58秒   UID       PID   cswch/s nvcswch/s  Command
15时29分00秒     0         9      4.48      0.00  rcu_sched
15时29分00秒     0        14      0.50      0.00  ksoftirqd/1
```

## ps 各项释义

* ps选项
    - 接受三种风格的选项(不同类型的选项可以自由混合，但是可能会出现冲突)
        + UNIX options，前面必须有一个破折号"-" (dash)
        + BSD options，不能使用破折号
        + GNU long options，前面有两个破折号"--"
    - 注意`ps -aux` 和 `ps aux` 是不同的
        + POSIX and UNIX标准里，`ps -aux`表示打印用户"x"的所有进程，如果"x"不存在则可能解释为`ps aux`，表现是不固定的所以不应该依赖这种方式
    - 自己平常习惯UNIX风格`ps -fe` (相对aux少了进程状态、但是多了PPID)
        + `-e`, Select all processes. Identical to -A，选择所有进程，和-A相同
        + `-f`, 全格式化列表
        + `-o`, 用户自定义输出格式，如：`ps -eo pid,state,tname,time,command`
    - 使用`ps aux` (BSD风格，注意不能使用破折号)
        + `ps aux`多显示一个进程状态和会话相关的状态，很有价值。参考：[Linux性能优化实践笔记](https://github.com/xiaodongQ/devNoteBackup/blob/master/%E5%90%84%E8%AF%AD%E8%A8%80%E8%AE%B0%E5%BD%95/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.md)，笔记中搜索关键字："系统中出现大量不可中断进程和僵尸进程怎么办"
        + 关于`会话`，本笔记里有记录，搜索关键字：`防止关闭终端进程退出` 或 `SIGHUP`
        + 执行结果 `ps aux`
            * `USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND`
            * `root         1  0.0  0.2 125856  4428 ?        Ss   12月23   0:25 /usr/lib/systemd/syst`
        + 部分项释义
            * STAT 进程状态，参考下面的man中含义
                - `S`表示进程状态，后面的`s`表示这个进程是一个会话的领导进程
                - BSD风格才会展示，"对于BSD格式，当使用stat关键字时，可能会显示其他字符"
                    + `<` 高优先级(优先于其他用户)
                    + `N` 低优先级(优先级低于其他用户)
                    + `L` 有页锁定到内存中(用于实时和自定义IO)
                    + `s` 是一个会话的领导进程
                    + `l` 是多线程的
                    + `+` 前台进程组

```sh
[➜ /home/xd/ ]$ ps -lp9467
F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
1 R  1000  9467  9466 99  80   0 -  1827 -      pts/4    00:36:24 stress
```

* 含义
    - 查看man手册
    - F(PROCESS FLAGS): flags associated with the process，进程相关的标志
        + `1    forked but didn't exec` fork但不执行
        + `4    used super-user privileges` 使用超级用户权限
    - S(PROCESS STATE CODES): 进程状态
        + R    running or runnable (on run queue)，运行或者可运行状态
        + D    (Disk Sleep)uninterruptible sleep (usually IO)，不可中断睡眠状态(一般在跟硬件交互，最常见的是等待硬件设备的 I/O 响应)
        + S    interruptible sleep (waiting for an event to complete)，可中断的的sleep
        + Z    defunct ("zombie") process, terminated but not reaped by its parent，僵尸进程
        + T    stopped by job control signal，任务控制信号中止
        + t    stopped by debugger during the tracing
        + X    dead (should never be seen)，进程消亡，不会看到进程的该状态
        + W    paging (not valid since the 2.6.xx kernel)，2.6内核版本之后无效
    - UID 进程号
    - PPID 父进程号
    - C(pcpu) CPU使用率
    - PRI
        + 进程优先级，值越*小*优先级越*高*
        + 一般启动进程的PRI为 20
    - NI 进程nice值
        + 表示进程可被执行的优先级的修正数值
        + PRI值越小越快被执行，那么加入nice值后，将会使得PRI变为：`PRI(new)=PRI(old)+nice` (即通过nice/renice修改nice会改变PRI)
        + 当nice值为负值的时候，那么该程序新PRI值将变小，即其优先级会变高，则其越快被执行
        + 进程的nice值不是进程的优先级，它们不是一个概念，但是进程nice值会影响到进程的优先级变化
    - ADDR
    - SZ
        + size in physical pages of the core image of the process，映射到内存中的页面, 这些页面仅由进程单独使用，进程实际占用的内存数
        + VSZ
            * virtual memory size of the process in KiB (1024-byte units), 进程的虚拟内存大小(KB)
        + RSS
            * resident set size, the non-swapped physical memory that a task has used (in kiloBytes), 常驻集大小，任务使用的非交换物理内存(KB)
            * This is usually at least 20 KiB of memory that is always resident，通常有20KB常驻内存
    - WCHAN
        + address of the kernel function where the process is sleeping 进程正在休眠的内核函数的地址，运行中的进程将显示'-'
    - TTY
        + tty ==> 泛指所有终端(Terminal)
        + 它是 Teletype(或者TeletypeWriter)的缩写，中文翻译：电传打字机
    - TIME
        + accumulated cpu time, user + system，累计cpu时间，用户+系统
    - 另外还有
        + PGID 进程组ID(也是进程组领导进程的进程号)
        + SID  会话ID(也是会话的领导进程的进程号)
        + TPGID 控制终端进程组ID(当前前台进程组的ID)
        + 进程、进程组、会话的关系参考本笔记中的` 会话`

* 修改进程优先级的命令主要有两个：`nice`, `renice`
    - [linux进程优先级、进程nice值](https://blog.csdn.net/codestinity/article/details/7496962)
    - `nice` 改变程序执行的优先权等级
        + 语法：`nice [-n <优先等级>][--help][--version][执行指令]`
            * -n 设置欲执行的指令的优先权等级，等级的范围从[-20, 19]，其中-20最高，19最低 (即值越小，进程优先级越高)
    - `renice` renice指令可重新调整程序执行的优先权等级。
        + e.g. `renice -5 -p 5200`, 将5200进程的nice设置为-5
    - 也可以在`top`中，输入`r`，对指定PID进行nice的调整设置

* 僵尸进程
    - 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。
    - 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为**僵尸进程**。
    - 危害：如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。
* 孤儿进程
    - 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
    - 孤儿进程不会导致资源浪费

## top

* 释义
    - `us`, user: 未设置nice的用户进程运行占用的时间百分比
    - `sy`, system: 内核进程运行占用时间百分比
    - `ni`, nice: 设置了nice的用户进程运行占用的时间百分比
    - `wa`, IO-wait: 等待I/O完成占用的时间百分比
    - `hi` 服务硬件中断占用的时间百分比
    - `hi` 服务软件中断占用的时间百分比
    - `st` 虚拟机窃取的时间百分比

```sh
# 按下数字 1 切换到所有 CPU 的使用情况，观察一会儿按 Ctrl+C 结束
$ top
top - 05:56:23 up 17 days, 16:45,  2 users,  load average: 2.00, 1.68, 1.39
Tasks: 247 total,   1 running,  79 sleeping,   0 stopped, 115 zombie
%Cpu0  :  0.0 us,  0.7 sy,  0.0 ni, 38.9 id, 60.5 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  0.0 us,  0.7 sy,  0.0 ni,  4.7 id, 94.6 wa,  0.0 hi,  0.0 si,  0.0 st
...

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 4340 root      20   0   44676   4048   3432 R   0.3  0.0   0:00.05 top
 4345 root      20   0   37280  33624    860 D   0.3  0.0   0:00.01 app
 4344 root      20   0   37280  33624    860 D   0.3  0.4   0:00.01 app
    1 root      20   0  160072   9416   6752 S   0.0  0.1   0:38.59 systemd
...
```

## htop

[htop使用详解](https://www.cnblogs.com/yqsun/p/5396363.html)

官网安装：https://sourceforge.net/projects/htop/ , 下载tar.gz文件解压，./configure; make; make install

* 比较
    - 两者相比起来，top比较繁琐
    - 默认支持图形界面的鼠标操作
    - 可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行
    - 杀进程时不需要输入进程号等

* htop每列内容与top差不多，多了不少便捷的操作
    - 可以通过鼠标进行点击操作，最下方栏列出了F1~F10，都可以通过鼠标点击，当然也可以按键盘按键
    - `S` (或`F2`) 进行一些htop的设置，里面可以用鼠标操作(按快捷键会自动修改里面的配置)
        + Meters (htop顶端的显示项)
            * 分左右两边, 从Available meters中选择，F5添加到左边，F6添加到右边(最下面有操作提示信息)
            * 在对应的选项上按回车，可以选择该项展示的方式: LED会模拟液晶屏显示/Bar显示进度条/Text文本
            * 本设置：添加hostname(文本), Clock(文本，显示时间)
        + Display options (显示选项)
            * 可以设置线程是否展示、线程名称是否展示等(可以勾选显示线程名)
            * 本设置：取消用户线程隐藏、不同颜色显示线程、显示线程名、高亮程序基本名称
        + Colors 设置显示颜色，默认颜色挺舒服的
        + Columns 选择主面板要展示的列，默认的列是跟top保持一致的，可以定制选择加一些列
            * 本设置：添加读和写io、忽略信号
        + **设置是本用户生效**
    - `/` (或`F3`) 可搜索进程名，光标会跳到进程位置
    - `\` (或`F4`) 过滤进程，和F3类似，不过过滤后只显示该进程
        + 退出该模式则再次按下`\` (可以看到输入还是上次的关键字)，需要再Esc退出(此时回车只会退出本次输入)
    - `t` (或`F5`) 显示树形结构
    - `k` (或`F9`) 对进程传递信号，按下后左边会多出一个信号列表视图(右边视图停留在选择的进程)，可用鼠标或上下键选择要传递的信号
    - `q` (或`F10`) 退出htop
    - `u` 选择展示列表中某个用户的进程，要退出则再按u后选所有用户
    - `H` 显示或隐藏用户线程，默认是显示(默认显示进程名，可以设置显示线程名，不过`\`过滤时就只能过滤显示进程名，线程名不一样则显示不了，可以配合ps -Tp或者top -Hp找到对应线程号，再到htop中查看跟踪)
    - `M`/`P`/`T` 按内存/CPU/TIME+ 排序，用`I` 来倒转排序顺序
    - `s` 对选择的进程来用`strace`追踪

## 防止关闭终端进程退出(SIGHUP)

* 关闭是由于 SIGHUP 信号
    - [解决Linux关闭终端（关闭SSH等）后运行的程序或者服务自动停止【后台运行程序】](https://www.cnblogs.com/bohaoist/p/4965103.html)

* 一些概念(以及进程、进程组、会话的关系):
    - 参考：[前台进程组、孤儿进程组、会话、控制终端](https://blog.csdn.net/hmsiwtv/article/details/7901711)
        + `PGID` 进程组ID(也是进程组领导进程的进程号)
        + `SID`  会话ID(也是会话的领导进程的进程号)
        + `TPGID` 控制终端进程组ID(当前前台进程组的ID)
    - `控制终端（controlling terminal）`
        + 会话可以有一个单独的控制终端
        + `控制进程`（controlling process）
            * 与控制终端连接的会话首进程叫做控制进程
    - `会话（session）`
        + 一个或多个进程组的集合，有唯一一个`会话首进程`（session leader）。
        + 一般由一个`会话首进程`、一个`前台进程组`、一个`后台进程组`组成。
        + 会话ID为首进程的ID(PID)
        + `会话首进程`
            * 新建会话时，会话中的唯一进程，其PID=SID
    - `进程组（process group）`：
        + 一个或多个进程的集合，进程组属于一个`会话`
            * fork()并不改变进程组ID
            * 每一个进程组有唯一一个进程组ID，即`进程组长`的进程ID。
        + `进程组组长`
            * `PID`与`PGID`相等的进程。
            * 组长可以改变子进程的进程组ID，使其转移到另一进程组。
            * e.g. 一个shell进程（以自己环境里的`zsh`为例，原链接中是`bash`，若演示环境是bash则找进程名`bash`即可），当使用管道线时，如`echo "hello" | cat`，zsh以第一个命令的进程ID为该管道线内所有进程设置进程组ID。此时`echo`和`cat`的进程组ID都设置成echo的进程ID
                - 执行`echo "hello" | cat`时，`ps`监测不到对应的进程，可以使用`execsnoop`监测短时进程，参考笔记中查找`execsnoop`：[Linux性能优化实践.md](https://github.com/xiaodongQ/devNoteBackup/blob/master/%E5%90%84%E8%AF%AD%E8%A8%80%E8%AE%B0%E5%BD%95/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5.md)
                - 通过`execsnoop`还发现了zsh终端每次执行命令时还获取了一些git相关的状态信息用于展示(zsh的git插件)
                - 根据结果中`cat`执行的父进程PID，可以看到其进程名为`-zsh`，`ps aux`显示进程`STAT`为：`Ss`，`s`表示一个会话的领导进程。追踪父进程最终能找到`systemd(进程号为1)`
        + `前台进程组`
            * 当前与终端交互的进程称为前台进程组。 该进程组中的进程能够向终端设备进行`读、写`操作的进程组。
            * 前台进程组的进程其 `TPGID = PGID`，常常可以通过比较它们来判断前后台进程组。
        + `后台进程组`
            * 一个会话中，除前台进程组、会话首进程以外的所有进程组。
            * 该进程组中的进程能够向终端设备`写`，*但是当试图`读`终端设备时，将会收到SIGTTIN信号*，并停止。
            * 前台进程组ID只能有一个，而后台进程组同时可存在多个。
            * 后台进程组的PGID≠TPGID。

* 挂断信号（SIGHUP）
    - 挂断信号（SIGHUP）默认的动作是终止程序
    - 当终端接口检测到网络连接断开，会将挂断信号发送给控制进程（会话首进程）
    - 如果会话首进程终止，则该信号发送到该会话*前台进程组*

* 关闭shell终端不终止进程
    - 使用后台运行命令&，并不能摆脱ssh进程组控制，还是会发送 SIGHUP 使进程组关闭
    - 为了能够再注销以后 依然能后台运行，可以使用`nohup`命令，忽略所有挂断（SIGHUP）信号
    - `nohup ./server > /dev/null 2>&1 &`, 不关心输出则重定向到/dev/null，不指定输出位置会自动生成nohup.out
    - nohup忽略之后，关闭终端后，原终端运行进程的父进程即kill了，会变成孤儿进程，由init进程(进程号1)接收

获取正在执行的shell自身进程号：`$$`

看门狗脚本检查：

```sh
#!/bin/bash
# monitor_server.sh, 执行时为防止关闭终端受NOHUP影响，使用 "nohup ./monitor_server.sh > /dev/null 2>&1 &" 运行

server=testServer

start_server()
{
    serverpid=`ps -fe|grep testServer | grep -v gdb|grep -v grep |awk '{print $2}'`
    kill -9 $(serverpid)
    ./testServer &
}

monitornum=`ps -fe|grep "monitor_server.sh"| grep -v vi|grep -v grep |grep -v $$ |awk '{print $2}'|wc -l`
if [ $monitornum -gt 0 ]; then
    date | tee -a run.log
    echo "already exist monitor, exit" | tee -a run.log
    exit 1
fi

while true
do
    num=`ps -fe|grep testServer | grep -v gdb|grep -v grep |awk '{print $2}'|wc -l`
    if [ $num -eq 0 ]; then
        start_server
        date | tee -a run.log
        echo "restart $(server)" | tee -a run.log
    fi
    sleep 5
done
```

## pstack & gstack

* pstack
    - `which pstack` 路径为 /usr/bin/pstack
    - `ll /usr/bin/pstack`，得到 `lrwxrwxrwx. 1 root root 6 8月  22 20:26 /usr/bin/pstack -> gstack`，可知pstack实际是指向gstack的软链接

* gstack
    - `which gstack` 路径为 /usr/bin/gstack
    - `vim /usr/bin/gstack` 打开gstack，可以看到它实际是一个脚本，其包装了gdb bt，并用sed对gdb bt的输出结果做了过滤而已

## pstree

* pstree
    - `pstree 选项 [pid, user]`
        + 可以接pid只显示该pid信息 或 接user只显示该用户信息
    - 以树状图的方式展现进程之间的派生关系，显示效果比较直观。
    - `pstree -cpus pid` 不精简显示(c)、显示进程号(p)、显示用户(u)、显示父进程树(s)
    - 选项
        + `-a`：显示每个程序的完整指令，包含路径，参数或是常驻服务的标示；
        + `-c`：不使用精简标示法；(默认会精简显示，多个相同的进程名会显示为`2*[sshd───zsh]`形式)
        + `-h`：列出树状图时，特别标明`现在执行`的程序；
        + `-H PID` 高亮指定进程号和其祖先(和-h不能同时用)
        + `-n` 输出时按`PID`排序
            * `-N type` 指定以什么类型来排序(ipc, mnt, net, pid, user, uts)
        + `-p` 显示进程号
        + `-u` 显示用户名(uid)
        + `-s` 显示父进程(当指定pid时可以一并把父进程树显示出来)
        + `pstree 用户` 显示基于指定用户的进程树

## last 命令

* last
    - last命令用于显示最近登录的用户列表
    - last向后检索/var/log/wtmp文件(也可-f指定检索文件)，并显示自这个文件创建以来所有登录（退出）系统的用户列表。
    - 选项
        + `-a` 在最后一列显示主机名(不-a时主机名也会显示，显示在别的列而不是最后一列，-R指定不显示该列)
        + `-i` 显示远程主机(即非本机)的IP地址
        + `-d` 显示远程主机(即非本机)的主机名
        + `-x` 显示系统关机记录和运行级别改变
            * 相比没有-x会多显示运行级别改变的日志。
            * 开机之后，runlevel会变，可以此判断开机；关机则可根据关键词reboot过滤，或者直接 `last reboot`也可
        + 命名后面空格+用户名，可以只显示指定用户的登录退出记录 e.g. `last xd -ai`
            * `last reboot` 每次系统重新**启动**时，*虚用户:reboot*都会被记录到日志中。所以`last reboot`会列出自日志文件创建以来的所有重新启动的日志记录。

`last -axi`执行结果截取：

```sh
root     pts/2        Mon Dec  9 09:01   still logged in    192.168.50.204
root     pts/1        Mon Dec  9 09:00 - 12:27  (03:26)     192.168.50.234
# 运行级别修改，此处系统启动后进入图形GUI模式(runlevel 5)
runlevel (to lvl 5)   Mon Dec  9 08:59 - 14:57  (05:58)     0.0.0.0
root     pts/0        Mon Dec  9 08:59 - 13:45  (04:46)     192.168.50.234
# 系统启动，虚用户reboot被记录(没有关闭机器的记录是因为直接操作机器电源关闭的，而不是reboot)
reboot   system boot  Mon Dec  9 08:58 - 14:57  (05:59)     0.0.0.0
root     pts/2        Fri Dec  6 18:50 - 02:04  (07:13)     192.168.50.204
root     pts/1        Fri Dec  6 18:50 - 02:03  (07:13)     192.168.50.204
# 系统启动
runlevel (to lvl 5)   Fri Dec  6 18:48 - 08:59 (2+14:11)    0.0.0.0
root     pts/0        Fri Dec  6 18:48 - 02:03  (07:15)     192.168.50.204
# 系统启动
reboot   system boot  Fri Dec  6 18:47 - 14:57 (2+20:10)    0.0.0.0
# 系统关闭，此处手动敲了reboot
shutdown system down  Fri Dec  6 18:47 - 18:47  (00:00)     0.0.0.0
root     pts/7        Fri Dec  6 16:20 - down   (02:26)     192.168.50.234
root     pts/3        Fri Dec  6 15:48 - down   (02:58)     192.168.50.204
```

## 运行级别

* Linux系统的7个运行级别(runlevel)
    - 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动
    - 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆
    - 运行级别2：多用户状态(没有NFS)
    - 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式
    - 运行级别4：系统未使用，保留
    - 运行级别5：X11控制台，登陆后进入图形GUI模式
    - 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动

* `/etc/rc.d/init.d`
    - `/etc/rc.d/init.d`下有许多服务器脚本程序，一般称为服务(service)
    - `/etc/init.d` 是指向 `/etc/rc.d/init.d`的软链接
    - 在/etc/rc.d下有7个名为rcN.d的目录(N为0-7)，对应系统的7个运行级别
        + rcN.d目录下都是一些符号链接文件，这些链接文件都指向init.d目录下的service脚本文件
        + 命名规则为K+nn+服务名或S+nn+服务名，其中nn为两位数字，e.g. `K90network -> ../init.d/network`
            * 对于以K开头的文件，系统将终止对应的服务
            * 对于以S开头的文件，系统将启动对应的服务
        + 系统会根据指定的运行级别进入对应的rcN.d目录，并按照文件名顺序检索目录下的链接文件
    - 查看运行级别用：`runlevel`
        + e.g. 本地CentOS虚拟机执行结果：`N 3`，命令行模式
    - 进入其它运行级别用：`init N`
        + `init 0`为关机，`init 6`为重启系统(默认运行级别不能设为6，否则不能正常启动)
        + 现在的Linux系统安装完后就运行在第5个级别，即系统启动后直接进入图形界面，而不用在字符模式下登录后用startx或者xinit 来起动图形界面。
        + 默认运行等级设置：`/etc/inittab`，使用systemd后不再使用该配置文件
            * `systemctl get-default` 查看
            * `systemctl set-default TARGET.target` 设置
        + 在任何运行级别，用户都可用init 命令来切换到其他运行级别


## crontab

linux系统由 cron (crond) 这个系守护进程服务来控制循环运行的例行性计划任务

crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。

* Linux下的任务调度分为两类，系统任务调度和用户任务调度。
    - 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。
    - 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。

* crontab
    - `-l` 显示当前crontab
    - `-r` 移除, `-i`去掉移除时的提示
    - `-e` 编辑

* cron 的主配置文件是 /etc/crontab
* 当我们要增加全局性的计划任务时，一种方式是直接修改/etc/crontab。但是，一般不建议这样做，/etc/cron.d目录就是为了解决这种问题而创建的。
    - 增加一项定时的备份任务，我们可以这样处理：在/etc/cron.d目录下新建文件backup.sh
    - cron进程执行时，就会自动扫描该目录下的所有文件，按照文件中的时间设定执行后面的命令。
    - cron执行时，也就是要读取三个地方的配置文件：一是`/etc/crontab`，二是`/etc/cron.d`目录下的所有文件，三是每个用户的配置文件
* 日志
    - linux(计划任务执行记录): /var/log/cron.log
    - mail任务(如果计划任务执行出错，mail中的信息比较详细): /var/spool/mail/root 或者 /var/mail/root(用户名)
        + `/var/mail` 是 指向 `/var/spool/mail`目录 的软链接
* crontab -e报找不到vi问题
    - 可以在.bashrc中设置环境变量`VISUAL`或者`EDITOR`为vi的路径，注意需要绝对路径，e.g. `export EDITOR=/usr/local/bin/vim`
    - `EDITOR`历史上用于更早期的编辑器，`VISUAL`用于比较高级的编辑器(如vi/emacs)，不过目前两者是兼容的，如果在bash终端调用一个编辑器，bash先会找`VISUAL`指定的编辑器，如果失败则会找`EDITOR`指定的编辑器
    - 参考：[VISUAL vs. EDITOR – what’s the difference?](https://unix.stackexchange.com/questions/4859/visual-vs-editor-what-s-the-difference)

/etc/crontab文件：

```sh
# 前四行是用来配置crond任务运行的环境变量
# 第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root

# For details see man 4 crontabs

# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name  command to be executed
```

在以上各个字段中，还可以使用以下特殊字符：

- 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。
- 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”
- 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”
- 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。

对于命名：如果是自己新建的crontab文件，命名成 "crontab", "crontab.xd"，用vim打开都能显示语法高亮;
而"crontab_xd", "xd_crontab", "crontab_xd.xd"则不行。 使用crontab.用户名方式命名

### 环境变量问题

不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点：

1）脚本中涉及文件路径时写全局路径；

2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如：

```sh
cat start_cbp.sh

#!/bin/sh
source /etc/profile
export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf
/usr/local/jboss-4.0.5/bin/run.sh -c mev &
```

3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如：

```
0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh
```

### 部分用法示例：

更多实例查看上面的链接

* 每隔两分钟执行

  `*/2 * * * * cmd`

* 每小时的奇数分钟执行，（0不执行，1执行）

  `1-59/2 * * * * cmd`

* 每天18:00至23:00间每隔30分钟

  `0,30 18-23 * * * cmd`

  `0-59/30 18-23 * * * cmd`

> * `A,B,C` A或B或C
* `A-B` A到B之间
* `*/A` 每A分钟（小时等）

* 两小时运行一次，注意分钟要设置值

  `* */2 * * * cmd （错误）`
  `0 */2 * * * cmd （正确）`


## SMTP

## DNS

[DNS详解: A记录,子域名,CNAME别名,PTR,MX,TXT,SRV,TTL](https://yq.aliyun.com/articles/611293)

A记录 A (Address) 记录是用来指定主机名（或域名）对应的IP地址记录。

## netstat

* netstat
    - `netstat -anp`
    - `netstat -nptul` 所有监听的连接
        + `-t` [--tcp|-t]
        + `-u` [--udp|-u]
        + `-l` [--listening|-l] 只显示正在侦听的套接字
        + `-p` [--program|-p]   显示套接字所属进程的PID和名称
        + `-n` [--numeric|-n]   显示数字形式地址而不是去解析主机、端口或用户名。
            * 前面描述`ps`时写过选项的风格
                - UNIX options，前面必须有一个破折号"-"
                - BSD options，不能使用破折号
                - GNU long options，前面有两个破折号"--"

## 负载均衡

LB集群是load balance 集群的简写，负载均衡集群
LVS是一个实现负载均衡集群的开源软件项目
LVS架构从逻辑上可分为调度层(Director)、server集群层(Real server)和共享存储层


golang consul-grpc服务注册与发现

## Ubuntu安装

* 镜像源
  - [中科大](http://mirrors.ustc.edu.cn/ubuntu-releases/) 速度挺快的

## Linux Kernel

* 下载源码
    - [linux内核源码下载地址](http://ftp.sjtu.edu.cn/sites/ftp.kernel.org/pub/linux/kernel/)
        + http://ftp.sjtu.edu.cn/sites/ftp.kernel.org/pub/linux/kernel/
    - tar.xz类型解压，分两步
        + `xz -d xxx.xz` 得到.tar文件
        + `tar -xvf xxx.tar` 解压

## 火焰图(Flame Graph)

* 火焰图
    - 参考：[Linux下用火焰图进行性能分析](https://blog.csdn.net/gatieme/article/details/78885908)
        + 其中红/蓝差分火焰图原文来自"Brendan Gregg"：[Differential Flame Graphs](http://www.brendangregg.com/blog/2014-11-09/differential-flame-graphs.html)
        + 关于"Brendan Gregg"：[Brendan Gregg: 一个实战派大神](https://book.douban.com/review/7894012/)
    - 常见的火焰图类型有 `On-CPU`, `Off-CPU`, 还有 Memory, Hot/Cold, Differential 等等.
    - 纵向表示调用栈的`深度`, 横向表示`消耗的时间`. 因为调用栈在横向会按照字母排序, 并且同样的调用栈会做合并, 所以一个格子的宽度越大越说明其`可能是瓶颈`
    - 什么时候使用 On-CPU 火焰图? 什么时候使用 Off-CPU 火焰图呢?
        + 取决于当前的瓶颈到底是什么, 如果是 CPU 则使用 On-CPU 火焰图, 如果是 IO 或锁则使用 Off-CPU 火焰图. 如果无法确定, 那么可以通过压测工具来确认 :
            * 通过压测工具看看能否让 CPU 使用率趋于饱和, 如果能那么使用 On-CPU 火焰图, 如果不管怎么压, CPU 使用率始终上不来, 那么多半说明程序被 IO 或锁卡住了, 此时适合使用 Off-CPU 火焰图.
            * 关于压测工具的选择, 如果选择 `ab` 的话, 那么务必记得开启 `-k`(允许KeepAlive) 选项, 以避免耗尽系统的可用端口.
            * 除了`ab`外，http压测工具还可以选择`wrk`/`locust`/`Jmeter`，`wrk`比`ab`功能更强大(使用了一些操作系统特定的高性能I/O机制, 比如 select, epoll, kqueue 等。其实它是复用了 redis 的 `ae 异步事件驱动框架`)
                - `wrk`可参考：[性能测试工具 wrk 安装与使用](https://www.cnblogs.com/savorboard/p/wrk.html)
        + 如果还是确认不了, 那么不妨 On-CPU 火焰图和 Off-CPU 火焰图都搞搞, 正常情况下它们的差异会比较大, 如果两张火焰图长得差不多, 那么通常认为 CPU 被其它进程抢占了.
    - 使用：
        + 获取GitHub：[brendangregg/FlameGraph](https://github.com/brendangregg/FlameGraph)
        + 生成和创建火焰图需要如下几个步骤
            * 捕获堆栈：使用 perf/systemtap/dtrace 等工具抓取程序的运行堆栈
                - `perf record -a -F 99 -p 3887 -g sleep 30` (-F每秒采集99次，-g记录调用栈，`-a`和`[-- ]sleep`搭配)
                    + 注意此处相比原链接中加了`-a`选项(全CPU全系统范围收集)，要不只会抓取到sleep的调用堆栈
                    + 可以用`perf report -n [--stdio]` 在终端查看(`-n`显示每个符号的样本数，`--stdio`使用stdio接口， 会展开显示结果)
            * 折叠堆栈：用上面的trace工具(perf/systemtap/dtrace等)抓取的系统和程序运行每一时刻的堆栈信息, 对他们进行分析组合, 将重复的堆栈累计在一起, 从而体现出负载和关键路径，使用FlameGraph 中的 `stackcollapse` 程序
                - `perf script -i perf.data > perf.unfold`，用`perf script`对`perf.data`进行解析(不用`-i`则默认会解析perf.data)
                    + `perf record` 生成的文件类型是`data`(二进制数据,`file perf.data`查看)，而`perf script`生成的文件类型是`ASCII text`
                - `./stackcollapse-perf.pl perf.unfold > perf.folded`，将perf解析出的内容 perf.unfold 中的符号进行折叠
            * 生成火焰图：分析 stackcollapse 输出的堆栈信息生成火焰图，使用`flamegraph.pl`
                - `./flamegraph.pl perf.folded > perf.svg`
                - 之后就可以用浏览器打开火焰图(.svg)进行分析了
        + 可以简化：`perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl > process.svg`
        + `SVG格式(Scalable Vector Graphics)`：可缩放的矢量图形，基于XML（Extensible Markup Language），由World Wide Web Consortium（W3C）联盟进行开发的。
            * 用来描述二维矢量及矢量/栅格图形。
            * SVG图形是可交互的和动态的，可以在SVG文件中嵌入动画元素或通过脚本来定义动画。
            * 用户可以设计高分辨率的Web图形页面，可以直接用代码来描绘图像，可以用任何文字处理工具打开SVG图像，通过改变部分代码来使图像具有交互功能，并可以随时插入到HTML中通过浏览器来观看。
            * 可以任意放大图形显示，但绝不会以牺牲图像质量为代价；
    - 分析：
        + 火焰图含义：火焰图是基于 `stack` 信息生成的 SVG 图片, 用来展示 CPU 的调用栈。
            * y 轴表示调用栈, 每一层都是一个函数. 调用栈越深, 火焰就越高, 顶部就是正在执行的函数, 下方都是它的父函数.
            * x 轴表示抽样数, 如果一个函数在 x 轴占据的宽度越宽, 就表示它被抽到的次数多, 即执行的时间长
                - *注意*, x 轴不代表时间, 而是所有的调用栈合并后, 按字母顺序排列的
            * 火焰图就是看顶层的哪个函数占据的宽度最大. 只要有 "平顶"(plateaus), 就表示该函数可能存在性能问题。
            * 颜色没有特殊含义, 因为火焰图表示的是 CPU 的繁忙程度, 所以一般选择暖色调
        + 互动性：火焰图是 SVG 图片, 可以与用户互动.
            * 鼠标悬浮：火焰的每一层都会标注函数名, 鼠标悬浮时会显示完整的函数名、抽样抽中的次数、占据总抽样次数的百分比。
            * 点击放大：在某一层点击，火焰图会水平放大，该层会占据所有宽度，显示详细信息。
            * 搜索：按下 `Ctrl+F` 会显示一个搜索框，用户可以输入关键词或正则表达式，所有符合条件的函数名会高亮显示.
                - 和浏览器自身的`Ctrl+F`不一样，颜色是svg中定义的，`Ctrl+i`可以切换是否取消大小写
    - 红/蓝差分火焰图
        + 对于修改程序前后的**性能回退问题**，使用`红/蓝差分火焰图(red/blue differential flame graphs)`快速找到根因。 如果在修改前后或者不同时期和场景下的火焰图之间, 不断切换对比来找出问题所在，这样会很繁琐。
        + `红/蓝差分火焰图`使用两种颜色来表示状态：
            * 红色表示增长
            * 蓝色表示衰减
        + 分析步骤如下：
            * 抓取修改前的堆栈 profile1 文件
                - `perf record -a -g -o perf1.data sleep 30` (注意需要`-a`)
                - `perf script -i perf1.data | stackcollapse-perf.pl > perfdiff1.folded`
            * 取修改后(或不同时期/场景)的堆栈 profile2 文件
                - `perf record -a -g -o perf2.data sleep 30`
                - `perf script -i perf2.data | stackcollapse-perf.pl > perfdiff2.folded`
            * 生成红蓝差分火焰图
                - a. `difffolded.pl -n perfdiff1.folded perfdiff2.folded | flamegraph.pl > diff.svg`
                    + `difffolded.pl` 只能对 "折叠" 过的堆栈 profile 文件进行操作
                    + "折叠操作"由`stackcollapse 系列`脚本完成
                - b. `difffolded.pl -n perfdiff2.folded perfdiff1.folded | flamegraph.pl --negate > diff2.svg`
                - 生成差分比较时，折叠文件的前后顺序不同是有影响的(上面的a和b)
                    + a: 宽度是以修改前profile文件为基准，颜色表明将要发生的情况
                    + b: 宽度是以修改后profile文件为基准，颜色表明已经发生的情况
                    + 功能验证测试时，可以同时生成这两张图进行对比

