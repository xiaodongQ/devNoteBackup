[TOC]


## Tips

开发过程过程中注意空格影响！
  makefile字符串赋值给变量时末尾空格(编辑器尽量开启空格和tab显示)


## REST

REST API: 即Representational State Transfer(表述性状态转移)的缩写
其优点如下：

* 在RESTful架构中，每一个URL代表一种资源；
* 客户端和服务器之间，传递这种资源的某种表现层；
* 客户端通过四个HTTP指令，对服务器端资源进行操作，实现“表现层状态转化”。 建议开发者使用REST API进行币币交易或者资产提现等操作。

## WebSocket API

WebSocket API: WebSocket是HTML5一种新的协议(Protocol)。

>它实现了客户端与服务器全双工通信，使得数据可以快速地双向传播。

通过一次简单的握手就可以建立客户端和服务器连接，服务器根据业务规则可以主动推送信息给客户端。

其优点如下：

* 客户端和服务器进行数据传输时，请求头信息比较小，大概2个字节;
* 客户端和服务器皆可以主动地发送数据给对方；
* 不需要多次创建TCP请求和销毁，节约宽带和服务器的资源。 强烈建议开发者使用WebSocket API获取**市场行情**和**买卖深度**等信息。

## TCP

TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

[gRPC服务发现&负载均衡](https://segmentfault.com/a/1190000008672912)

## windows 命令

tasklist 查看进程
tasklist|findstr "9108"

win10开机内存使用就80%：关闭快速启动

[windows 10如何关闭快速启动](https://jingyan.baidu.com/article/ca00d56c7a40e6e99febcf4f.html)

## curl

* `curl -o` 指定写到文件名
    - e.g. `curl -o ./test.jpg http://mirrors.aliyun.com/repo/testjpg`

* curl -X

>curl -X 123.45.67.89:1080 Yahoo
-X选项用于指定代理（服务器和端口号）

>curl -d "user=nickwolfe&password=12345" http://www.yahoo.com/login.cgi
-d选项用于指定发送请求时POST命令的数据

```sh
curl -X POST http://127.0.0.1:8000/person -d "first_name=hello&last_name=world" | python -m json.tool
```

python -m, -m将库中的python模块用作脚本去运行

将模块当做脚本去启动有什么用？
python xxx.py
python -m xxx.py
这是两种加载py文件的方式:
1叫做直接运行
2相当于import,叫做当做模块来启动


## git

### 删除Git中缓存的用户名和密码

运行一下命令缓存输入的用户名和密码：
git config --global credential.helper wincred
清除掉缓存在git中的用户名和密码
git credential-manager uninstall

### 恢复某个已修改的文件（撤销未提交的修改）
git checkout .(全部，或者指定文件来恢复部分)  //本地删除的记录恢复

### 基本命令

Git book：  
[Git 基础 ](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)

* git pull
    - 拉取远程分支更新到本地仓库
    - `git pull <远程主机名> <远程分支名>:<本地分支名>`，一般我们简写成 `git pull`
    - git pull = git fetch + git merge
    - git fetch不会进行合并，执行后需要手动执行git merge合并，而git pull拉取远程分之后直接与本地分支进行合并。
    - 强制覆盖本地：git pull --force
* git fetch
    - 更新远程代码到本地仓库
    - FETCH_HEAD指的是: 某个branch在服务器上的最新状态
        + 这个列表保存在 .Git/FETCH_HEAD 文件中, 其中每一行对应于远程服务器的一个分支。
        + 如果没有显式的指定远程分支, 则远程分支的master将作为默认的FETCH_HEAD
        + 如果指定了远程分支, 就将这个远程分支作为FETCH_HEAD
    - git fetch更新本地仓库的两种用法
        + 方法一
            * `git fetch origin master` #从远程的origin仓库的master分支下载代码到本地的origin master
            * `git log -p master.. origin/master` #比较本地的仓库和远程参考的区别
            * `git merge origin/master` #把远程下载下来的代码合并到本地仓库，远程的和本地的合并
        + 方法二
            * `git fetch origin master:temp` #从远程的origin仓库的master分支下载到本地并新建一个分支temp
            * `git diff temp`  #比较master分支和temp分支的不同
            * `git merge temp` #合并temp分支到master分支
            * `git branch -d temp` #删除temp
* git reset
    - git reset会将撤销点之后的操作都回退到暂存区中
    - git reset是直接删除指定的commit
* git revert
    - git revert 仅仅是撤销某次提交
    - git revert是用一次新的commit来回滚之前的commit

* 撤消操作
    - [2.4 Git 基础 - 撤消操作](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)

### git终端显示中文名为数字编码设置

在cygwin中，使用git add添加要提交的文件的时候，如果文件名是中文，会显示形如 274\232\350\256\256\346\200\273\347\273\223.png 的乱码。

解决方案：
在bash提示符下输入：
`git config --global core.quotepath false`
core.quotepath设为false的话，就不会对0x80以上的字符进行quote。中文显示正常。

### git 默认不区分文件名大小写

readme.md 改名为 Readme.md，git status并不会显示任何信息

* 配置git 使其对文件名大小写敏感
    - git config core.ignorecase false

## spdlog

使用，两种方式：
1. 只有头文件的方式(代码中不需要加spdlog.cpp)
  拷贝include/spdlog 到代码路径，编译时，添加-std=c++11
  这种方式不需要-DSPDLOG_COMPILED_LIB
2. 使用静态库方式(推荐,把spdlog.cpp编进代码，编译更快)
  拷贝src/spdlog.cpp到代码路径，将cpp一起编译，需要加宏-DSPDLOG_COMPILED_LIB和-std=c++11

日志等级： (从上到下越来越严重，默认日志等级及其更高等级会进行打印，默认info)
  trace
  debug
  info
  warn
  error
  critical

### 基本用法及说明

[spdlog学习笔记](https://blog.csdn.net/haojie_superstar/article/details/89383433)

#### logger
  日志记录器，通过传入一个或者多个sink给它进行记录一个或多个位置
  可以通过spdlog自身的函数方法创建logger，也可以手动创建(先创建一个或者多个sink，再将sink传给spdlog::logger的构造函数进行创建)
    自身方法使用工厂模式创建实例，e.g. spdlog::daily_logger_mt
    sink的命名空间层次为 sdplog::sinks::具体sink类型，e.g. spdlog::sinks:stdout_sink_mt

#### sink

  sink是实际将日志写入目标位置的对象。
  每一个sink仅应负责写一个目标文件（比如 file，console，db）
  并且每一个sink有专属的私有格式化器formatter实例。 (可以手动创建sink，传递给logger，实现多个sink写入)

可用sink：

rotating_file_sink 达到最大文件大小时，关闭文件，重命名文件并创建新文件。
    `spdlog::rotating_logger_mt使用该sink`
daily_file_sink  每天在一个特别的时间创建一个新的日志文件，并在文件名字上添加一个时间戳
    `spdlog::daily_logger_mt`
simple_file_sink 无任何限制的向一个日志文件中写入
    `spdlog::basic_logger_mt`
stdout_sink/stderr_sink with colors
    `spdlog::stdout_color_mt`
    `spdlog::color_logger_mt`
syslog_sink POSIX syslog(3) 发送日志到syslog
    `spdlog::syslog_logger`
dist_sink 将日志消息分发到其他接收器列表 **使用这个sink实现多个sink记日志**
    没有工厂模式返回logger，需要手动添加

```cpp
    auto distsink = std::make_shared<spdlog::sinks::dist_sink_mt>();
    distsink->add_sink(std::make_shared<spdlog::sinks::stdout_sink_mt>());
    distsink->add_sink(std::make_shared<spdlog::sinks::rotating_file_sink_mt>(filepath, 1024*1024*1, 3));
    auto mydistlogger = std::make_shared<spdlog::logger>("mydistlogger", distsink);
    spdlog::register_logger(mydistlogger);
```

**注意**：用户应该负责去创建任何他们需要的文件夹。spdlog除了文件**不会尝试创建任何文件夹**

spdlog::info
spdlog::error

#### 线程安全说明

* spdlog:: 命名空间下的是线程安全的

* 对于sinks，以 _mt 后缀结尾的是线程安全的，比如：daily_file_sink_mt
             以_st 后缀结尾的是非线程安全的，比如：daily_file_sink_st

  单线程的sink不可以在多线程中使用，它的速度会更快，因为没有锁竞争

1.  不同线程处理时以下函数不应该操作：
当loggers在不同的线程同时执行时，下述函数不应该被调用
  spdlog::set_error_handler(log_err_handler) // or logger->set_error_handler(log_err_handler);
logger在其它线程执行过程中，添加或移除sink是线程不安全的
  logger->sinks().push_back(new_sink);       // Don't do this if other thread is already using this logger

2. 要创建线程安全的loggers，使用带 _mt 后缀的工厂函数
  auto logger = spdlog::basic_logger_mt(...);

3. 要创建单线程的loggers，使用带 _st 后缀的工厂函数
  auto logger = spdlog::basic_logger_st(...);

#### 使用
spdlog支持使用最小集的方式，意味着你只用包含你实际需要的头文件，而不是全部，比如说你只需要使用 rotating logger，那么你只需要
`#include <spdlog/sinks/rotating_file_sink.h>`

对于异步特性，你还需要
`#include <spdlog/asynch.h>`

* 几种使用模式：
  返回智能指针 std::shared_ptr<logger>
    每一个logger中包含一个存有一个或多个 std::shared_ptr<spdlog::sink>的 vector
    logger在记录每一条日志时（如果是有效的级别），将会调用每一个std::shared_ptr<spdlog::sink>中的sink(log_msg)函数

```cpp
* stdout打印
    auto console = spdlog::stdout_logger_mt("console");

* 基本文件记录，只有一个，不循环使用不限制大小
    #include "spdlog/sinks/basic_file_sink.h"
    // Create basic file logger (not rotated) // support for basic file logging
    auto my_logger = spdlog::basic_logger_mt("basic_logger", "logs/basic.txt");

* rotate句柄，限制大小和备份数量
    #include "spdlog/sinks/rotating_file_sink.h" // support for rotating file logging
    // file rotating logger with 5mb size max and 3 rotated files，5MB大小，3个循环备份文件(即共4个日志文件) rotate循环，旋转
    auto file_logger = spdlog::rotating_logger_mt("file_logger", "myfilename", 1024 * 1024 * 5, 3);

* 异步logger 使用工厂函数创建异步logger(循环记日志时，每次异步logger不阻塞)
    #include "spdlog/sinks/daily_file_sink.h"
    #include <spdlog/asynch.h>  //异步logger加头文件
    auto async_file = spdlog::basic_logger_mt<spdlog::async_factory>("async_file_logger", "logs/async_log.txt");
  可以通过创建异步logger前调用以下函数来修改线程池个数和待写日志队列长度
    inline void init_thread_pool(size_t q_size, size_t thread_count)

* 创建一个由多个loggers共享同一个输出文件的sink

* auto console = spdlog::stdout_color_mt("xdconsole");
    #include "spdlog/sinks/stdout_color_sinks.h"

  使用spdlog::get("...")访问loggers
    (spdlog::get("xdconsole"))->info("test spdlog::get function")
  spdlog::get可能会拖慢你的程序，因为它内部维护了一把锁，所以要谨慎使用。
    一个很好的方法是建立一个std::shared_ptr<spdlog::logger>私有成员变量，并在构造函数中初始化
```

* 手动创建loggers

参考(上面的sink章节，dist_sink可创建写多个sink的logger)

```cpp
  auto sink = std::make_shared<spdlog::sinks::stdout_sink_mt>();
  auto my_logger= std::make_shared<spdlog::logger>("mylogger", sink);
  my_logger->info("etstesfdljk");
```

* 设置函数

```cpp
  //设置一个logger, 后续使用spdlog::info时，会使用该logger记录
  spdlog::set_default_logger(file_logger);

  //设置模式字符串
  set_pattern(pattern_string);
    //格式应用到所有被注册的logger
    spdlog::set_pattern("*** [%H:%M:%S %z] [thread %t] %v ***");
    //格式应用到具体的logger
    some_logger->set_pattern(">>>>>>>>> %H:%M:%S %z %v <<<<<<<<<");
    //格式应用到具体的logger某个特定sink
    some_logger->sinks()[1]->set_pattern("..");
```

  [spdlog学习笔记_模式标记](https://blog.csdn.net/haojie_superstar/article/details/89383433)
    %H %M %S %z, 时(0-23) 分 秒 时区(“+02:00”)
    %I 时(1-12), %e 毫秒; %f 微秒

    %Y 年(“2014”), %m 月; %d 日(1-31)
    %C 年(“14”); %B 月份全名(August); %A 星期全名(Thursday)


用SPDLOG_INFO/SPDLOG_TRACE 等宏定义记录才有：不能指定logger
    %@ 文件名:行号(my_file.cpp:123)
    %s 文件名
    %# 行号
    %! 函数名

    %P 进程id; %t 线程id

    %+ spdlog的默认格式 “[2014-10-31 23:46:59.678] [mylogger] [info] Some message”
    %v 用户要记的信息

      即 [%Y-%m-%d %H:%M:%S.%e] [%n] [%l] %v

    %^ “[mylogger] [info(green)] Some message”
    %L 日志等级缩写(“D”, “I”, etc)
    %l 日志等级(“debug”, “info”)
    %n logger名

    %% %号

  对齐
    右对齐
      %8l  ("    info")
    -左对齐
      %-8l ("info    ")
    =中间对齐
      %=8l ("  info  ")

[%Y-%m-%d %H:%M:%S.%e] %^

## 编译

### pkg-config 编译时找库 和 ldconfig 运行时找库
编译grpc, third_party少包, git checkout .
  `git submodule update --init`
编译项目pkg-config找不到库
  export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
运行项目找不到动态库，系统中添加路径，或LD_LIBRARY_PATH
  vi /etc/ld.so.conf，添加一行 /usr/local/lib，然后执行ldconfig

编译时提示未定义的引用，如果-l链接了，且路径已经配置或者-L已经指定，还有可能是:
-l链接库在引用库的函数文件之前，这样就会链接不到库，所以要保证链接库的顺序在引用它之前

#### pkg-config
[pkg-config 详解](https://blog.csdn.net/newchenxf/article/details/51750239)

pkg-config是一个linux下的命令，用于获得某一个库/模块的所有编译相关的信息。

```sh
pkg-config --cflags --libs libmongocxx 执行结果为：

-I/usr/local/include/mongocxx/v_noabi -I/usr/local/include/bsoncxx/v_noabi  -L/usr/local/lib -lmongocxx -lbsoncxx
```

> 如果你写了一个库，不管是静态的还是动态的，要提供给第三方使用，那除了给人家库/头文件，最好也写一个pc文件，这样别人使用就方便很多，不用自己再手动写依赖了你哪些库，只需要敲一个”pkg-config [YOUR_LIB] --libs --cflags”。

pkg-config信息两个来源
  第一种：取系统的/usr/lib下的所有*.pc文件。
  第二种：PKG_CONFIG_PATH环境变量所指向的路径下的所有*.pc文件。

## makefile

**注意！ `PRJ_DIR="${shell cd ..;pwd}"       #注释说明`, 这样注释处理会将空格也赋值给PRJ_DIR**

[Makefile编译目录下多个文件以及函数wildcard用法](https://blog.csdn.net/hunanchenxingyu/article/details/12205305)
[makefile 中字符串处理和文件处理函数](https://blog.csdn.net/qhexin/article/details/16951097)

```sh
1. wildcard
  找出目录和指定目录下所有的后缀为c和cpp的文件
  $(wildcard *.c, *.cpp, /***/***/*.c)
    C_SRC = $(wildcard *.c)
    同C_SRC=$(shell echo *.c)

2. foreach
  组合foreach查找多个路径
    SRC_FILES += $(foreach dir,$(SRC_DIR),$(wildcard $(dir)/*.cpp))

3. patsubst 模式字符串替换函数
  $(patsubst <pattern>,<replacement>,<text>)
    <pattern>可以包括通配符“%”，表示任意长度的字串
    如果<replacement>中也包含“%”，那么，<replacement>中的这个“%”将是<pattern>中的那个“%
    以“\%”来表示真实含义的"%"
  e.g.
      将所有的cpp文件的后缀替换为o文件
      CPP_OBJ = $(patsubst %cpp, %o, $(CPP_SRC))
        同CPP_OBJ=$(CPP_SRC:%.cpp=%.o)

4. notdir
  dir=$(notdir $(src)) 把带路径的文件去掉路径，只留文件名

5. subst 字符串替换函数
  $(subst <from>,<to>,<text>)
  e.g.
    $(subst ee,EE,feet on the street)， 将"feet on the street"中的"ee"替换为"EE"，若要替换为空则,,

  其他字符串处理：
    去空格函数——strip
    e.g.
      $(strip a b c ) 把字串“a b c ”去到开头和结尾的空格，结果是“a b c”。

    过滤函数——filter
      sources := foo.c bar.c baz.s ugh.h
      $(filter %.c %.s,$(sources))返回的值是“foo.c bar.c baz.s”。
    反过滤函数——filter-out
      objects=main1.o foo.o main2.o bar.o
      mains=main1.o main2.o
      $(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”
    排序函数——sort
      $(sort foo bar lose)返回“bar foo lose”
    取单词函数——word
      取第n个，从1开始数
      $(word 2, foo bar baz)返回值是“bar”
    取单词串函数——wordlist
      第几到第几个
      $(wordlist 2, 3, foo bar baz)返回值是“bar baz”
    单词个数统计函数——words
      $(words, foo bar baz)返回值是“3”
    首单词函数——firstword
      $(firstword foo bar)返回值是“foo”
  文件名操作函数：
    取目录函数——dir
      目录部分是指最后一个反斜杠（“/”）之前的部分。如果没有反斜杠，那么返回“./”
      $(dir src/foo.c hacks)返回值是“src/ ./”
    取文件函数——notdir
      非目录部分是指最后一个反斜杠（“/”）之后的部分
      $(notdir src/foo.c hacks)返回值是“foo.c hacks”
    取后缀函数——suffix
      如果文件没有后缀，则返回空字串
      $(suffix src/foo.c src-1.0/bar.c hacks)返回值是“.c .c
    取前缀函数——basename
      如果文件没有前缀，则返回空字串
      $(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar hacks”
    加后缀函数——addsuffix
      $(addsuffix .c,foo bar)返回值是“foo.c bar.c”
    加前缀函数——addprefix
      $(addprefix src/,foo bar)返回值是“src/foo src/bar”
    连接函数——join
      $(join <list1>,<list2>)
      如果<list1>的单词个数要比<list2>的多，那么，<list1>中的多出来的单词将保持原样。如果<list2>的单词个数要比<list1>多，那么，<list2>多出来的单词将被复制到list1中末尾
      $(join aaa bbb , 111 222 333)返回值是“aaa111 bbb222 333”
```

通配符$@、$^、$<

这三个分别表示：
$@          --代表目标文件(target)
$^            --代表所有的依赖文件(components)
$<           --代表第一个依赖文件(components中最左边的那个)。

```sh
main.out:main.o line1.o line2.o
  g++ -o $@ $^
main.o:main.c line1.h line2.h
  g++ -c $<
line1.o:line1.c line1.h
  g++ -c $<
line2.o:line2.c line2.h
  g++ -c $<
```

### ifeq语法

```
ifeq ($(CC),gcc)
    $(CC) -o foo $(objects) $(libs_for_gcc)
else
    $(CC) -o foo $(objects) $(normal_libs)
endif
```

## CMake

[在 linux 下使用 CMake 构建应用程序](https://www.ibm.com/developerworks/cn/linux/l-cn-cmake/)

1. 编写CMakeLists.txt
2. 执行cmake path生成Makefile(path时CMakeLists.txt所在目录)
3. 使用make进行编译

### CMakeLists.txt 的语法

由命令、注释和空格组成

其中命令是不区分大小写的,符号"#"后面的内容被认为是注释。

命令由命令名称、小括号和参数组成,参数之间使用空格进行间隔。 (注意VERSION大写)

```c
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
4 ADD_EXECUTABLE(main ${DIR_SRCS})
```
`aux_source_directory(<dir> <variable>)`
  命令会把参数 <dir> 中所有的源文件名称赋值给参数 <variable>

完成了文件 CMakeLists.txt 的编写后需要使用 cmake 或 ccmake 命令生成Makefile 。 ccmake 与命令 cmake 的不同之处在于 ccmake 提供了一个图形化的操作界面。

加子目录src，链接库Test，并将子目录编译成库(静态库.a)

```
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 ADD_SUBDIRECTORY( src )
4 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
5 ADD_EXECUTABLE(main ${DIR_SRCS}  )
6 TARGET_LINK_LIBRARIES( main Test )
```

子目录src中的CMakeLists.txt

```
1 AUX_SOURCE_DIRECTORY(. DIR_TEST1_SRCS)
2 ADD_LIBRARY ( Test ${DIR_TEST1_SRCS})
```

## linux

### history日志显示日期

.bashrc中设置环境变量:
export HISTTIMEFORMAT="%F %T `whoami` "

### man手册等级

1是普通的命令
2是系统调用,如open,write之类的(通过这个，至少可以很方便的查到调用这个函数，需要加什么头文件)
3是库函数,如printf,fread4是特殊文件,也就是/dev下的各种设备文件
5是指文件的格式,比如passwd, 就会说明这个文件中各个字段的含义; 比如man 5 proc, 说明进程信息伪文件系统
6是给游戏留的,由各个游戏自己定义
7是附件还有一些变量,比如向environ这种全局变量在这里就有说明
8是系统管理用的命令,这些命令只能由root使用,如ifconfig


### 重定向标准错误

`mv a.log back/ 2>tmp.log  (或者2>>tmp.log)`

将执行的错误信息输出重定向到日志tmp.log中，**注意，2>之间不能有空格**

这种情况下，错误信息只会打印到tmp.log中，若要打印到文件的同时，终端上也能打印(标准输出1)，则可使用tee：

```sh
mv a.log back/ 2>&1 | tee -a tmp.log
```

### tee

[tee命令](https://www.cnblogs.com/leezhxing/p/4092532.html)

tee命令读取**标准输入**，把这些内容同时**输出到标准输出**和**（多个）文件**中，tee命令可以重定向标准输出到多个文件。

在使用管道线时，前一个命令的**标准错误**输出不会被tee读取。

```sh
tee
    只输出到标准输出
tee file
    输出到标准输出的同时，保存到文件file中
    如果文件不存在，则创建；如果已经存在，则覆盖之。
tee -a file
    输出到标准输出的同时，追加到文件file中。
    如果已经存在，就在末尾追加内容，而不是覆盖。
tee -
    输出到标准输出两次
tee file1 file2
    同时保存到file1和file2中

ls "*" 2>&1 | tee -a ls.txt
    使用tee命令把标准错误输出也保存到文件
```

### history记录时间
export HISTTIMEFORMAT="%F %T `whoami` "

### vim
替换指定行之间  :10,15s/abc/hhh/g

把204到233间的" = "替换为"("
`:204,233s/ = /(/g`

204到233间 ");"替换为"));"
`:204,233s/\)\;/));/g`

查找以\结尾：
/\\$  (\\为'\'转义)

#### vim版本更新

卸载原来的
yum remove vim* -y

下载vim8.0
wget ftp://ftp.vim.org/pub/vim/unix/vim-8.0.tar.bz2
tar -jxf vim-8.0.tar.bz2
cd vim80

make
make install
插件安装

### find

查找目录 时跳过指定目录，使用prune(英 /pruːn/   删除；减少)
  (注意顺序，-path接源路径，后面跟-prune，再跟-o，后面再跟其他过滤选项，-print不能少)：
  `find . -path './util' -prune -o -type d -print`

过滤多个目录：
  `find . \( -path './util' -o -path './tradebot \) -prune -o -type d -print`

  -o 类似于 or,  或者;
  -a 类似于 and, 且

  (1) grep指定h文件类型查找hello字符串：
find . -type f -name '*.h' | xargs grep "hello"

查看端口 lsof -i:5000

* 排除目录下所有以md结尾的文件：
`find . -type f ! -name "*.md"`

* 排除多个：
`find . -type f ! -name "*.md" ! -name "*.o"`

* 正则表达式：
`find . -regex '.*\.md\|.*\.h\|.*\.cpp'`

### 统计文本行数

语法：wc [选项] 文件…

说明：该命令统计给定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。

    该命令各选项含义如下：

    　　- c 统计字节数
    　　- l 统计行数
    　　- w 统计字数

* `wc -lcw Makefile`

* 统计src目录下所有cpp文件代码行数(子目录也会统计)

`find src/ -name "*.cpp" |xargs cat|wc -l`

* 统计当前目录及子目录下文件行数
`find . -type f |xargs cat|wc -l`

* 统计当前目录及子目录下.h和.cpp文件行数
`find . -type f -name "*.h" -o -name "*.cpp" |xargs cat|wc -l`
`find . -type f -name "*.h" |xargs cat|wc -l`

* 统计src目录下所有cpp文件代码行数(过滤空行)

`find src/ -name "*.cpp" |xargs cat | grep -v ^$ | wc -l`

### unzip

unzip zip文件

### 目录排序

du -s -d1|sort -n      (h会影响排序，仅按数字来排的)

### grep 查找后去重

grep "#include <boost" -rn *|awk -F' ' '{print $2}'|sort|uniq  (注意要先sort，要不仅会去重相邻的)

### sort uniq 文件去重

对文件排序：  
sort test.csv (可>输出到新文件)

### echo 不换行

* echo -e 允许对下面列出的加反斜线转义的字符进行解释

```sh
  \n    换行符
  \c    禁止尾随的换行符
  \t    水平制表符
  等等

  echo -e "hello\n"  在原来基础上多加一个换行
  echo -e "hello\c"  不换行
```

* `echo -n "hello"` 也可指定不换行(-n 不输出行尾的换行符)

### 正则表达式

非：  volume:[^0] 匹配"volume:"后接非0的行

### ln

* 链接(或称连接也可，Linux man手册中翻译为"连接"，维基百科中"符号连接"会重定向到"符号链接")
    - [符号链接](https://zh.wikipedia.org/wiki/%E7%AC%A6%E5%8F%B7%E9%93%BE%E6%8E%A5)
    - `ln [-s] 目标 链接名称` 创建一个链接，指向"目标"
        + e.g. `ln -s ~/one/two three`, 创建符号链接(软链接)three，指向目录~/one/two
    - 符号链接(软连接，-s选项创建，Symbolic link or soft link)
        + 指向另一个不同路径文件的一个符号路径
        + 对符号链接文件进行读写的程序会表现得像直接对目标文件进行操作
        + 如果删除一个符号链接，它指向的目标文件不受影响。
        + 如果目标文件被移动、重命名或者删除，任何指向它的符号链接仍然存在，但是它们将会指向一个不复存在的文件。这种情况被有时被称为**被遗弃**。
            * /proc/进程号/fd 中`ls -l`，可看到文件描述符都是链接文件(l)，指向socket的文件在闪烁，说明指向不复存在的文件(被遗弃，此时链接文件背景颜色是高亮的)
    - 硬链接(hard link)
        + 存储了链接建立时它所指向文件的实际数据的文件副本
        + 原始文件被删除后，符号链接将失效，访问软链接时，会提示找不到文件，但硬链接文件还在，而且还保存有原始文件的内容。
        + 修改硬链接文件的内容时，原始文件(被链接的文件)也会被修改
        + `ln` 和标准的 `unlink()` 和 `link()` 函数执行完全一致的操作

## 时区

ll /etc/localtime 查看链接的时区文件

### systemctl

1. 查看系统当前默认启动项目的方法，不再是setup之类的了。
`systemctl list-unit-files`

* systemctl 和 `chkconfig` 区别
    - `systemctl`命令：是一个*systemd*工具，主要负责控制systemd系统和服务管理器。
        + [Systemd 入门教程：命令篇](http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html)
        + Systemd 是 Linux 系统工具，用来启动守护进程，已成为大多数发行版的标准配置。
        + 由来：历史上，Linux 的启动一直采用init进程。这种方法有两个缺点。一是启动时间长。二是启动脚本复杂。
            * `/etc/init.d/` (`/etc/init.d`是指向`/etc/rc.d/init.d`的软链接)下面管理开机启动的服务，该目录下README文件做了历史说明(CentOS7)：systemd替换了传统的init脚本，"You are running a systemd-based OS where traditional init scripts have been replaced by native systemd services files"
        + Systemd 就是为了解决这些问题而诞生的。它的设计目标是，为系统的启动和管理提供一套完整的解决方案。
        + 使用了 Systemd，就不需要再用init了。Systemd 取代了initd，成为系统的第一个进程（PID 等于 1），其他进程都是它的子进程。
        + Systemd 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。
            * 系统管理
                - `systemctl` 是 Systemd 的主命令，用于管理系统。
                - `systemd-analyze`命令用于查看启动耗时。
                - `hostnamectl` 命令用于查看当前主机的信息。
                - `localectl` 命令用于查看本地化设置
                - `timedatectl`命令用于查看当前时区设置
                - `loginctl`命令用于查看当前登录的用户。
            * Unit
                - Systemd 可以管理所有系统资源。不同的资源统称为 Unit（单位）。Unit 一共分成12种。
                    + Service unit：系统服务
                    + Target unit：多个 Unit 构成的一个组
                    + Device Unit：硬件设备
                    + Mount Unit：文件系统的挂载点
                    + Socket Unit：进程间通信的 socket
                    + Swap Unit：swap 文件
                    + ...
                - `systemctl list-units`命令可以查看当前系统的所有 Unit 。
                - `systemctl status`命令用于查看系统状态和单个 Unit 的状态。
                - `systemctl start apache.service` 立即启动一个服务
                - `systemctl stop apache.service`
                - `systemctl restart apache.service`
                - `systemctl list-dependencies` 命令列出一个 Unit 的所有依赖。
                    + (Unit 之间存在依赖关系：A 依赖于 B，就意味着 Systemd 在启动 A 的时候，同时会去启动 B。)
                    + `systemctl list-dependencies nginx.service`
                    + 上面命令的输出结果之中，有些依赖是 Target 类型（详见下文），默认不会展开显示。如果要展开 Target，就需要使用--all参数：`systemctl list-dependencies --all nginx.service`
            * Unit配置文件
                - 每一个 Unit 都有一个配置文件，告诉 Systemd 怎么启动这个 Unit 。
                    + Systemd 默认从目录/etc/systemd/system/读取配置文件。但是，里面存放的大部分文件都是符号链接(symbolic link，软链接)，指向目录/usr/lib/systemd/system/，真正的配置文件存放在那个目录。
                    + 配置文件的后缀名，就是该Unit的种类，比如sshd.socket。**如果省略，Systemd默认后缀名为.service**，所以sshd会被理解成sshd.service。(所以有时执行systemctl可以省略.service，但需要该服务类型确实是service)
                - `systemctl list-unit-files` 列出所有配置文件
                - `systemctl enable` 命令用于在上面两个目录之间，建立*符号链接关系*。如果配置文件里面设置了**开机启动**，该命令相当于激活开机启动。
                    + `systemctl enable docker.service` 开机启动docker服务
                - `systemctl disable` 命令用于在两个目录之间，撤销符号链接关系，相当于撤销开机启动
                - 每个配置文件的状态，一共有四种(systemctl list-unit-files结果列表中各服务状态)。
                    + enabled：已建立启动链接
                    + disabled：没建立启动链接
                    + static：该配置文件没有[Install]部分（无法执行），只能作为其他配置文件的依赖
                    + masked：该配置文件被禁止建立启动链接
                - `systemctl status`
                    + 从配置文件的状态无法看出，该 Unit 是否正在运行。这必须执行systemctl status命令。
            * Systemd 统一管理所有 Unit 的启动日志。带来的好处就是，可以只用`journalctl`一个命令，查看所有日志（内核日志和应用日志）
                - `journalctl` 查看所有日志（默认情况下 ，只保存本次启动的日志）
                - `journalctl -k` 查看内核日志（不显示应用日志）
                - `journalctl -b` 查看系统本次启动的日志
            * 争议
                - 事实上，现在还有很多人反对使用 Systemd，理由就是它过于复杂，与操作系统的其他部分强耦合，违反"keep simple, keep stupid"的Unix 哲学。
                - [systemd 为什么会有那么大的争议？](https://www.zhihu.com/question/25873473)
    - `service`命令：可以启动、停止、重新启动和关闭系统服务，还可以显示所有系统服务的当前状态。
        + `service mysqld start/stop` 命令启动/关闭MySQL实例(非开机启动)
    - `chkconfig`命令：是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。
        + chkconfig命令主要用来更新（启动或停止）和查询系统服务的运行级信息。
        + 谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号链接。
        + `chkconfig --list` 查看开机自启动的服务
            * 只查看MySQL服务 `chkconfig --list mysqld`
            * 配置MySQL的开机自动启动 `chkconfig --add mysql`; `chkconfig mysqld on`
    - `systemctl` 实际上将 service 和 chkconfig 这两个命令整合到一起。在CentOS 7就开始被使用了。
        + 使某服务自动启动(开机启动)
            * 旧指令: `chkconfig --level 3 httpd on`, 新指令: `systemctl enable httpd.service`
        + 使某服务不自动启动
            * 旧指令: `chkconfig --level 3 httpd off`, 新指令: `systemctl disable httpd.service`
        + 检查服务状态
            * 旧指令: `service httpd status`, 新指令: `systemctl status httpd.service` `systemctl is-active httpd.service`(仅显示是否 Active)
        + 显示所有已设置开机启动的服务
            * 旧指令: `chkconfig --list`, 新指令: `systemctl list-units --type=service`
        + 启动/停止/重启某服务
            * 旧指令: `service httpd start/stop/restart`, 新指令: `systemctl start/stop/restart httpd.service`

运行`chkconfig --list`后结果有如下说明(CentOS)：

```
注：该输出结果只显示 SysV 服务，并不包含
原生 systemd 服务。SysV 配置数据
可能被原生 systemd 配置覆盖。

      要列出 systemd 服务，请执行 'systemctl list-unit-files'。
      查看在具体 target 启用的服务请执行
      'systemctl list-dependencies [target]'。
```

2. 取消mysqld的自启动
`systemctl disable mysqld`

查看状态，先status
`systemctl status mysqld.service`

### service

`systemctl status mysqld` 执行和 `service mysqld status` 类似

* service是一个shell脚本，其中包装了systemctl
    - `which service`执行获取完整路径：/usr/sbin/service
    - vi /usr/sbin/service 里面是shell脚本，基于systemctl执行命令

### cpu信息

* `lscpu`
    - 会列出CPU型号、名称、架构、频率、位数、大小端、逻辑CPU个数、每个核心支持的线程数、物理座数等

或者手动过滤查看：  
cpu信息在 /proc/cpuinfo中，根据grep过滤关键字，并配合uniq/sort/wc来过滤重复/排序/计数，统计各信息

* 查看物理CPU的个数(实际物理cpu的个数)

`cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l`

* 查看CPU是几核心(物理核数，每个cpu的物理核数，若有多个物理cpu，核心数都一样就一条记录)

`cat /proc/cpuinfo |grep "cores"|uniq`

* 查看逻辑CPU的个数(若该cpu支持超线程，则1个物理核对应2个逻辑核/线程。 若支持超线程则与物理核是两倍的关系)

`cat /proc/cpuinfo |grep "processor"|wc -l`

超线程计数可以理解为：一颗CPU当成两颗来用，将一颗具有超线程功能的物理CPU变成两颗逻辑CPU，而逻辑CPU对操作系统来说，跟物理CPU并没有什么区别。

超线程介绍：[图说超线程技术(Hyper-Threading Technology)](https://www.cnblogs.com/idorax/p/6884088.html)

获取开发环境配置：

```sh
echo -n "cpu个数: "
cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l
echo -n "cpu核数: "
cat /proc/cpuinfo |grep "cores"|uniq
echo -n "逻辑核数: "
cat /proc/cpuinfo |grep "processor"|wc -l

echo -n "操作系统: "
cat /etc/redhat-release
echo -n "gcc版本: "
gcc -v
```

### yum

* yum
    - yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。
    - 基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。
    - 命令形式一般如下：`yum [options] [command] [package ...]`
        + [options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为"yes"），-q（不显示安装的过程）等等。
        + [command]为所要进行的操作，[package ...]是操作的对象。
    - 安装
        + `yum install package1` 安装指定的安装包package1
        + `yum groupinsall group1` 安装程序组group1
    - 更新和升级
        + `yum update package1` 更新指定程序包package1
        + `yum check-update` 检查可更新的程序
        + `yum upgrade package1` 升级指定程序包package1
    - 查找和显示
        + `yum info package1` 显示安装包信息package1
            * e.g. `yum info sysstat`，结果里会展示：名称、架构、版本、大小、源、简介、协议、描述、已安装、可安装 等信息
        + `yum list` 显示所有已经安装和可以安装的程序包
        + `yum list package1` 显示指定程序包安装情况package1(会展示指定的已安装和可安装的包)
    - 删除程序
        + `yum remove package1` 或 `yum erase package1` 删除程序包package1
    - 清除缓存
        + `yum clean packages` 清除缓存目录下的软件包
    - [linux yum命令详解](cnblogs.com/chuncn/archive/2010/10/17/1853915.html)

## watch

`watch -n1 -d` -d高亮改变的位置

## valgrind

valgrind ./simulate_server --leak-check=full --show-leak-kinds=definite

## mysql
安装Mysql 8.0
[CentOS 7 安装 Mysql 8.0 教程](https://blog.csdn.net/danykk/article/details/80137223)
1）配置Mysql 8.0安装源
sudo rpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm
2）安装Mysql 8.0
sudo yum --enablerepo=mysql80-community install mysql-community-server

## samba 将linux映射为网络驱动
Samba
  Samba是在Linux和UNIX系统上实现SMB协议的一个免费软件，由服务器及客户端程序构成。
    SMB（Server Message Block）通信协议是微软（Microsoft）和英特尔(Intel)在1987年制定的协议，主要是作为Microsoft网络的通讯协议。SMB 是在会话层（session layer）和表示层（presentation layer）以及小部分应用层（application layer）的协议。

    SMB（Server Messages Block，信息服务块）是一种在局域网上共享文件和打印机的一种通信协议，它为局域网内的不同计算机之间提供文件及打印机等资源的共享服务。

Linux操作系统提供了 Samba服务，为了实现Window主机与Linux服务器之间的资源共享，Samba服务为两种不同的操作系统架起了一座桥梁，使 Linux 系统和Window系统之间能够实现互相通信。

[CentOS服务器的目录映射为Windows磁盘驱动器](https://blog.csdn.net/u010480282/article/details/80518836)

安装->修改配置文件->添加用户组、添加用户->开启服务, \\ip\自定义共享路径，或者/home/下的用户路径

/etc/samba/smb.conf

```
global中
  ; 新增配置begin
    encrypt passwords = yes
    smb passwd file = /etc/samba/smbpasswd
; 自定义共享名称
[xdroot]
    workgroup = samba
    netbios name = xd
    ; 共享描述
    comment = share root
    ; 共享路径
    path = /
    ;设置共享是否可浏览，如果no就表示隐藏，需要通过IP+共享名称进行访问
    browseable  =  yes
    ;设置共享是否具有可写权限
    writable = yes
    ;设置共享是否具有只读权限
    read only  = no
    printable = yes
```

#### 用户组和防火墙
将用户添加到用户组，而不离开原有组(-a选项)
usermod -a -G samba xd
smbpasswd -a xd

关闭防火墙 service firewalld stop
selinux

systemctl list-unit-files|grep firewalld

关闭开机启动
systemctl disable firewalld.service

## 给用户赋root权限

vi /etc/sudoers，找到下面位置并添加用户记录(输入`visudo`回车可编辑即该文件，sudoers本身是没有写权限的，先chmod +w，改完再chmod -w)

* 建议使用：`visudo` (上面chomd操作规避了权限问题)

```sh
## Allow root to run any commands anywhere
root ALL=(ALL) ALL
新用户名 ALL=(ALL) ALL （添加这一行）
```

## centos7 mongodb c++驱动安装

翻译：
[mongodb c++ 驱动](https://www.jianshu.com/p/c982a2960175)
  1. 安装c驱动
  2. 下载最新的 mongocxx driver
     git clone https://github.com/mongodb/mongo-cxx-driver.git --branch releases/stable --depth 1
     cd mongo-cxx-driver/build
  3. 配置驱动
     cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local ..
  4. 编译和安装驱动
     若用默认的 MNMLSTC 的C++17 `make EP_mnmlstc_core` (实际安装未执行该步，不确定是否有影响，make正常安装成功)
     make && make install

[mongodb c 驱动](https://www.jianshu.com/p/d77680254418) (第一步安装c驱动，翻译链接)

```sh
  $ wget https://github.com/mongodb/mongo-c-driver/releases/download/1.13.0/mongo-c-driver-1.13.0.tar.gz
  $ tar xzf mongo-c-driver-1.13.0.tar.gz
  $ cd mongo-c-driver-1.13.0
  $ mkdir cmake-build
  $ cd cmake-build
  $ cmake -DENABLE_AUTOMATIC_INIT_AND_CLEANUP=OFF ..

  $ make
  $ make install
```

官网：
[Installing the mongocxx driver](http://mongocxx.org/mongocxx-v3/installation/)

**注意下载安装包最好到官网,博客中下载链接可能是很老的包**

## mongodb安装
[Linux平台安装MongoDB](https://www.runoob.com/mongodb/mongodb-linux-install.html)
curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.12.tgz   # 下载 (对应版本修改下)
tar -zxvf mongodb-linux-x86_64-3.0.6.tgz                                   # 解压
mv  mongodb-linux-x86_64-3.0.6/ /usr/local/mongodb                         # 将解压包拷贝到指定目录

MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中：

export PATH=<mongodb-install-directory>/bin:$PATH
<mongodb-install-directory> 为你 MongoDB 的安装路径。如本文的 /usr/local/mongodb 。

  创建数据库目录
MongoDB的数据存储在data目录的db目录下，但是这个目录在安装过程不会自动创建，所以你需要手动创建data目录，并在data目录中创建db目录。
`mkdir -p /data/db`

  命令行中运行 MongoDB 服务
`$ ./mongod`

MongoDB后台管理 Shell
如果你需要进入MongoDB后台管理，你需要先打开mongodb装目录的下的bin目录，然后执行mongo命令文件。

MongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。

当你进入mongoDB后台后，它默认会链接到 test 文档（数据库）：

```sh
$ cd /usr/local/mongodb/bin
$ ./mongo
MongoDB shell version: 3.0.6
connecting to: test
Welcome to the MongoDB shell.
……
```

## 灰度发布

参考百度百科：
[灰度发布](https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83)

* 灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。
    - 在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。
    - 灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。

* 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。

* 作用： 及早获得用户的意见反馈，完善产品功能，提升产品质量 让用户参与产品测试，加强与用户互动 降低产品升级所影响的用户范围

本质上灰度测试可以算作A/B测试的一种特例

> 灰度发布与互联网公司常用A/B测试似乎比较类似，国外互联网公司似乎并没有所谓的灰度发布的概念。
> 按照wikipedia中对A/B测试的定义，A/B测试又叫：A/B/N Testing、Multivariate Testing，因此本质上灰度测试可以算作A/B测试的一种特例。

* 步骤：
    - 1）定义目标
    - 2）选定策略：包括用户规模、发布频率、功能覆盖度、回滚策略、运营策略、新旧系统部署策略等
    - 3）筛选用户：包括用户特征、用户数量、用户常用功能、用户范围等
    - 4）部署系统：部署新系统、部署用户行为分析系统（web analytics）、设定分流规则、运营数据分析、分流规则微调
    - 5）发布总结：用户行为分析报告、用户问卷调查、社会化媒体意见收集、形成产品功能改进列表
    - 6）产品完善
    - 7）新一轮灰度发布或完整发布

## QT

[Qt Downloads](http://download.qt.io/archive/qt/) 环境搭建(官网的下载链接点击进去找不到界面)

## UML类图

[UML类图与类的关系详解](http://uml.org.cn/oobject/201104212.asp)

[UML——在Visual Studio 2013/2015中设计UML类图](https://www.cnblogs.com/SceneryHao/p/5355915.html)

Unified Modeling Language (UML)又称统一建模语言或标准建模语言。

简单说就是以图形方式表现模型，根据不同模型进行分类

常用 UML 动态图（5 个）：用例图，活动图，状态机图，序列图，通信图。
常用 UML 静态图（4 个）：类图，包图，部署图，构件图。

在所有UML图中，类图是使用频率最高的UML图。
类图用于描述系统中所包含的类以及它们之间的相互关系，帮助人们简化对系统的理解，它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。

类图主要关系有：泛化（Generalization）,  实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)

* 泛化（Generalization)
    - 【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。
    - 【代码体现】：类继承另一个类
    - 【箭头指向】：带三角箭头的实线，箭头指向父类


## gdb

gcc -g选项：以操作系统的本地格式(stabs, COFF, XCOFF, 或 DWARF). 产生调试信息. GDB 能够使用这些调试信息.

* 升级gcc 4.8.5
[CentOS升级gcc4.4.7到gcc4.8.5](https://blog.csdn.net/shine_journey/article/details/62039381)

* 断点
    - 添加
        + `break` / `b`, 四种形式
            * break line-number                    在执行给定行之前
            * break function-name                  在进入指定的函数之前
            * break line-or-function if condition  如果condition（条件）是真，程序到达指定行或函数时停止
            * break routine-name                   在指定例程的入口处设置断点
        + 可以在各个原文件中设置断点
            * break filename:line-number
            * break filename:function-name
        + 回车会在上一个位置再次设置一个端点
    - 查看
        + `info break`
    - 删除
        + `delete`
            * delete 5 (指定编号)
            * delete 1-10(连续的断点号)
        + `clear`
            * clear list.c:12           //删除文件：行号的所有断点
            * clear 12                  //删除行号的所有断点
            * clear list.c:list_delet   //删除文件：函数的所有断点
            * clear 删除断点是基于行的，不是把所有的断点都删除
    - 临时断点
        + 在使用gdb调试时，如果想让断点只生效一次，可以使用`tbreak`命令（缩写为`tb`），和设置断点的过程一样
            * 临时断点13显示:*del*, 普通断点:*keep*
    - 条件断点
        + `break 行号 if 条件`，意思是只有在条件满足的时候，断点才会被触发
        + `b 222 if i==100` (i为100时触发断点)
    - 忽略断点
        + 在设置了断点之后，可以使用命令`ignore 断点编号i cnt`来忽略断点，意思是接下来的cnt次编号为i的断点触发都不会让程序暂停，只有第cnt+1次断点触发才会让程序暂停

```sh
# 临时断点
Num     Type           Disp Enb Address            What
13      breakpoint     del  y   0x0000000000415383 in Thread_func(void*) at src/func.cpp:224
14      breakpoint     keep y   0x0000000000415353 in Thread_func(void*) at src/func.cpp:222
```

### 问题

收到：signal SIGABRT，程序退出

```golang
//gdb程序报错退出
// (发现问题是root用户编译，用普通用户执行的，push_back()时就报这个退出了，奇葩问题奇葩操作...):
Program received signal SIGABRT, Aborted.

terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7ffff070f700 (LWP 12784)]
0x00007ffff5573207 in raise () from /lib64/libc.so.6

//bt查看:
(gdb) bt
#0  0x00007ffff5573207 in raise () from /lib64/libc.so.6
#1  0x00007ffff55748f8 in abort () from /lib64/libc.so.6
#2  0x00007ffff609d445 in __gnu_cxx::__verbose_terminate_handler () at ../../../../libstdc++-v3/libsupc++/vterminate.cc:95
#3  0x00007ffff609b5d6 in __cxxabiv1::__terminate (handler=<optimized out>)
    at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:38
#4  0x00007ffff609b603 in std::terminate () at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:48
#5  0x00007ffff609b823 in __cxxabiv1::__cxa_throw (obj=0x7fffe0013ce0, tinfo=0x7ffff6322b00 <typeinfo for std::bad_alloc>,
    dest=0x7ffff6099cd0 <std::bad_alloc::~bad_alloc()>) at ../../../../libstdc++-v3/libsupc++/eh_throw.cc:87
#6  0x00007ffff609bd1d in operator new (sz=18446744073709551600) at ../../../../libstdc++-v3/libsupc++/new_op.cc:56
#7  0x00000000004259e8 in __gnu_cxx::new_allocator<TestResult>::allocate (this=0x7ffff070eb20, __n=256204778801521550)
    at /usr/local/include/c++/4.8.5/ext/new_allocator.h:104
#8  0x0000000000421ec5 in std::_Vector_base<TestResult, std::allocator<TestResult> >::_M_allocate (
    this=0x7ffff070eb20, __n=256204778801521550) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:168
#9  0x0000000000525324 in std::vector<TestResult, std::allocator<TestResult> >::_M_emplace_back_aux<TestResult const&> (this=0x7ffff070eb20) at /usr/local/include/c++/4.8.5/bits/vector.tcc:404
#10 0x00000000005212d5 in std::vector<TestResult, std::allocator<TestResult> >::push_back (
    this=0x7ffff070eb20, __x=...) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:911
```


## 线程

* pthread_create 创建分离线程后，传入的参数应该立即(*应该usleep一定的时间*,e.g. 1ms), 在线程中新建存储区进行存储，不应该一直使用外部的地址。

## perf

* centos安装 `yum install perf`
* ubuntu安装 `apt install linux-tools-common`
* 需要以root用户运行
* `perf top [-g] -p 进程号`， 查看cpu使用率高问题
    - -g: Enables call-graph (stack chain/backtrace) recording，启用调用图记录

* `while(1) {dosomething();}`，或者直接`while(1) {}` cpu使用率100%问题
    - Unix系统使用cpu通过时间片轮转(而Windows则属于抢占式的，进程主动放弃使用CPU)，while(1){}会持续占用cpu，导致cpu使用率很高
    - 在while体中添加usleep(1000)，即sleep 1ms，cpu使用率大大降低
    - 在while体中，若当次不执行任何操作，建议添加一个短的等待时间(**包含不满足继续条件直接continue,不执行任何其他语句的情况**)
    - 中断
        + 内核统计程序占的CPU是通过时钟中断完成的，当时钟中断发生时候，通过IP记数器(程序计数器PC)找到发生前正在运行的程序。
        + 程序不做事情时，进入内核中的 idle() 程序，等待中断唤醒。而该程序使CPU处于休息状态，将CPU的系统时钟频率调整到很低，此时会比较省电，风扇不转，然后在这个状态下循环等待

>理想情况下，假设原本执行一次循环只需要消耗10个CPU周期的话，如果不进行阻塞，2Ghz的CPU在一秒内会执行2*10^9/10=2*10^8次的循环，然而在1秒内执行那么多次循环对我们的程序一点帮助都没有，还会抢占CPU资源；而阻塞该程序1ms后，相当于每进行一次循环后就让出1ms的运算资源，也就是让出2*10^6个cpu周期，原本占用100%的程序只会占用不到1万次CPU周期，这对于2Ghz的CPU来说几乎是0负担的。 [CPU占用率100%](https://cloud.tencent.com/developer/article/1327007)

## strace

strace -p进程号或者线程号

## stress

* stress是一个Linux系统压力测试工具，可模拟CPU、IO、内存负载
    - 先`yum install -y epel-release`, 再 `yum install -y stress`
        + EPEL (Extra Packages for Enterprise Linux)是基于Fedora的一个项目，为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux.
        + 首先我们需要安装一个叫”epel-release”的软件包，这个软件包会自动配置yum的软件仓库。当然你也可以不安装这个包，自己配置软件仓库也是一样的。 软件仓库配置目录在：`/etc/yum.repos.d/`

* 使用
    - `-t N` 或 `--timeout N`：运行秒数
    - `-c N` 或 `--cpu N`：产生多个处理sqrt()函数的CPU进程
        + `stress -c 2 -t 10` 其两个进程测CPU，跑10s
    - `-i N` 或 `--io N`：产生多个处理sync()函数的磁盘I/O进程
    - `-m N` 或 `--vm N`：产生多个处理malloc()/free()内存分配函数的进程
        + `--vm-bytes B`：指定内存的byte数为B，默认值是256MB
        + `--vm-hang N`：指定malloc分配的内存多少秒后free()释放掉，默认不释放，0无效
    - `-d N` 或 `--hdd N`：产生多个处理write()/unlink()的进程
        + `--hdd-bytes B`：指定每个hdd进程处理的byte字节数，默认1GB

## mpstat

[mpstat命令](https://man.linuxde.net/mpstat)

* mpstat
    - mpstat命令指令主要用于多CPU环境下，它显示各个可用CPU的状态信息，包括硬件软件中断信息。
    - 这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。
    - 包含在 sysstat 软件包中，`yum info sysstat`查看该软件包信息(CentOS)
    - `mpstat [ -A ] [ -u ] [ -V ] [ -I { SUM | CPU | SCPU | ALL } ] [ -P { cpu [,...] | ON | ALL } ] [ interval [ count ] ]` (最后两个参数用于指定间隔和次数)
    - `mpstat (选项) (参数)`
        + 选项-P：指定CPU编号，指定-P ALL 则显示所有逻辑CPU列表，并会显示一个all的统计
        + 参数 间隔时间：每次报告的间隔时间（秒）；
        + 参数 次数：显示报告的次数。
        + e.g. `mpstat -P ALL 5 2` 所有CPU，间隔5S，只显示2次(参数和选项均为可选)
    - 当mpstat不带参数时，输出为从系统启动以来的平均值，*默认打印CPU*使用报告
    - The mpstat command can be used both on SMP and UP machines
        + UP（Uni-Processor）：系统只有一个处理器单元，即单核CPU系统
        + SMP（Symmetric Multi-Processors）：系统有多个处理器单元。各个处理器之间共享总线，内存等等。 在操作系统看来，各个处理器之间没有区别。
    - 更新sysstat包：新版本中(11.5.5版本以后)才开始有 %iowait列，下载github上的最新版本，目前12.3.1
        + 链接：[github](https://github.com/sysstat/sysstat)
        + `yum remove sysstat`，然后解压后编译安装 `./configure; make; make install`

```sh
[➜ /home/xd/ ]$ mpstat -P ALL 3 #间隔3s，该虚拟机环境有两个逻辑CPU
Linux 3.10.0-957.el7.x86_64 (localhost.localdomain)     2019年11月25日     _x86_64_    (2 CPU)

13时56分13秒  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
13时56分16秒  all   48.71    0.00    0.00    0.00    0.00    0.17    0.00    0.00    0.00   51.11
13时56分16秒    0   91.17    0.00    0.00    0.00    0.00    0.35    0.00    0.00    0.00    8.48
13时56分16秒    1    8.31    0.00    0.33    0.00    0.00    0.33    0.00    0.00    0.00   91.03
```

* 含义
    - CPU CPU编号(all为平均)
    - %usr
        + 在用户态的CPU使用率
    - %nice
        + 在用户态以nice等级执行时的CPU使用率
            * nice/renice设置nice值为非0时，CPU跑在%nice等级上，看mpstat里%usr的使用率会比较小，大部分使用率在%nice列
            * nice默认0时，%nice列是0.00
    - %sys
        + 内核态的CPU使用率(注意不包含硬件和软件中断的时间)
    - %iowait
        + 系统有未完成的磁盘IO请求时，CPU闲置状态的时间百分比
    - %irq
        + CPU为服务硬件中断的时间百分比
    - %soft
        + CPU为服务软件中断的时间百分比
    - %steal
        + 管理程序为另一个虚拟处理器提供服务时，虚拟CPU非自愿等待所花费的时间百分比
    - %guest
        + CPU运行一个虚拟处理器花费的时间百分比
    - %gnice
        + CPU运行一个设置了nice的客户机花费的时间百分比
    - %idle
        + CPU处于空闲状态且系统没有未完成的磁盘I/O请求时的时间百分比

## pidstat

* pidstat
    - [pidstat 命令详解](https://www.jianshu.com/p/3991c0dba094)
    - 报告Linux任务的统计数据
    - `pidstat [ 选项 ] [ <时间间隔> ] [ <次数> ]`
    - 选项
        + `-p` 指定进程号
        + -u 默认，显示各个进程的cpu使用统计
            * `UID       PID   %usr %system  %guest   %wait    %CPU   CPU  Command`
            * UID:被监视任务的真实用户标识号;
            * %usr:用户态CPU使用率; %system:内核态CPU使用率; %guest:运行在虚拟机中的CPU使用率
            * %wait: 等待运行的CPU使用率; %CPU: 总的CPU使用率; CPU: CPU号
        + -d，显示各进程IO使用情况
            * `UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command`
            * 每秒从磁盘读取的KB、写入磁盘KB、任务取消的写入磁盘的KB(当任务截断脏的pagecache的时候会发生)、io延迟
        + -r，显示页面错误和内存使用情况
            * `UID       PID   minflt/s  majflt/s     VSZ     RSS   %MEM  Command`
            * minflt/s: 每秒 次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数
            * majflt/s: 每秒 主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时， 相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生
            * VSZ: 该进程使用的虚拟内存(以kB为单位)
            * RSS(常驻集大小): 该进程使用的物理内存(非交换物理内存，以kB为单位)
            * %MEM: 该进程使用内存的百分比
        + -w，显示每个进程的上下文切换情况
            * `UID       PID   cswch/s nvcswch/s  Command`
        + -t，显示选择任务的线程的统计信息外的额外信息
            * `UID      TGID       TID   cswch/s nvcswch/s  Command`
            * TGID:线程组leader的标识号;
            * TID:被监控的线程标识号
        + -l，显示命令名和所有参数(Command列会展示完整的执行命令)
            * e.g. Command列显示完整的`pidstat -l 2`，不加-l则只显示`pidstat`
    - pidstat 默认显示进程的指标数据，加上 -t 参数后，才会输出线程的指标。(**不加-t则不统计线程，注意**)

## vmstat

* vmstat
    - 报告虚拟内存的统计信息
    - vmstat  对系统的进程情况、内存使用情况、交换页和I/O块使用情况、中断以及CPU使用情况进行统计并报告相应的信息。
    - 需要特别关注的四列内容：
        + cs（context switch）是每秒上下文切换的次数
        + in（interrupt）则是每秒中断的次数
        + r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
        + b（Blocked）则是处于不可中断睡眠状态的进程数。
    - vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用 `pidstat` 了
        + 加上 -w 选项 `pidstat -w 2`
        + 两列内容是我们的重点关注对象
            * 一个是 cswch ，表示每秒自愿上下文切换（voluntary context switches）的次数
                - **自愿上下文切换**，是指进程无法获取所需资源，导致的上下文切换。
                - 比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
            * 另一个则是 nvcswch ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。
                - **非自愿上下文切换**，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。
                - 比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。

* `vmstat`结果示例:

```
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 9  0      0 672340   2116 561728    0    0     0     0 2742  266 99  1  0  0  0
 8  0      0 672204   2116 561736    0    0     0     0 2754  254 99  1  0  0  0
```

* `pidstat -w 2`结果示例：

```
15时28分58秒   UID       PID   cswch/s nvcswch/s  Command
15时29分00秒     0         9      4.48      0.00  rcu_sched
15时29分00秒     0        14      0.50      0.00  ksoftirqd/1
```

## ps各项释义

* ps选项
    - 接受三种风格的选项(不同类型的选项可以自由混合，但是可能会出现冲突)
        + UNIX options，前面必须有一个破折号"-"
        + BSD options，不能使用破折号
        + GNU long options，前面有两个破折号"--"
    - 注意`ps -aux` 和 `ps aux` 是不同的
        + POSIX and UNIX标准里，`ps -aux`表示打印用户"x"的所有进程，如果"x"不存在则可能解释为`ps aux`，表现是不固定的所以不应该依赖这种方式
    - 自己平常习惯UNIX风格`ps -fe`
        + `-e`, Select all processes. Identical to -A，选择所有进程，和-A相同
        + `-f`, 全格式化列表
        + `-o`, 用户自定义输出格式，如：`ps -eo pid,state,tname,time,command`

```sh
[➜ /home/xd/ ]$ ps -lp9467
F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
1 R  1000  9467  9466 99  80   0 -  1827 -      pts/4    00:36:24 stress
```

* 含义
    - 查看man手册
    - F(PROCESS FLAGS): flags associated with the process，进程相关的标志
        + `1    forked but didn't exec` fork但不执行
        + `4    used super-user privileges` 使用超级用户权限
    - S(PROCESS STATE CODES): 进程的状态
        + D    uninterruptible sleep (usually IO)，不可中断状态(最常见的是等待硬件设备的 I/O 响应)
        + R    running or runnable (on run queue)，运行或者可运行状态
        + S    interruptible sleep (waiting for an event to complete)，可中断的的sleep
        + T    stopped by job control signal，任务控制信号中止
        + t    stopped by debugger during the tracing
        + W    paging (not valid since the 2.6.xx kernel)，2.6内核版本之后无效
        + X    dead (should never be seen)，看不到该状态
        + Z    defunct ("zombie") process, terminated but not reaped by its parent，僵尸进程
    - UID 进程号
    - PPID 父进程号
    - C(pcpu) CPU使用率
    - PRI
        + 进程优先级，值越*小*优先级越*高*
        + 一般启动进程的PRI为 20
    - NI 进程nice值
        + 表示进程可被执行的优先级的修正数值
        + PRI值越小越快被执行，那么加入nice值后，将会使得PRI变为：`PRI(new)=PRI(old)+nice` (即通过nice/renice修改nice会改变PRI)
        + 当nice值为负值的时候，那么该程序新PRI值将变小，即其优先级会变高，则其越快被执行
        + 进程的nice值不是进程的优先级，它们不是一个概念，但是进程nice值会影响到进程的优先级变化
    - ADDR
    - SZ
        + size in physical pages of the core image of the process，映射到内存中的页面, 这些页面仅由进程单独使用，进程实际占用的内存数
        + VSZ
            * virtual memory size of the process in KiB (1024-byte units), 进程的虚拟内存大小(KB)
        + RSS
            * resident set size, the non-swapped physical memory that a task has used (in kiloBytes), 常驻集大小，任务使用的非交换物理内存(KB)
            * This is usually at least 20 KiB of memory that is always resident，通常有20KB常驻内存
    - WCHAN
        + address of the kernel function where the process is sleeping 进程正在休眠的内核函数的地址，运行中的进程将显示'-'
    - TTY
        + tty ==> 泛指所有终端(Terminal)
        + 它是 Teletype(或者TeletypeWriter)的缩写，中文翻译：电传打字机
    - TIME
        + accumulated cpu time, user + system，累计cpu时间，用户+系统

* 修改进程优先级的命令主要有两个：`nice`, `renice`
    - [linux进程优先级、进程nice值](https://blog.csdn.net/codestinity/article/details/7496962)
    - `nice` 改变程序执行的优先权等级
        + 语法：`nice [-n <优先等级>][--help][--version][执行指令]`
            * -n 设置欲执行的指令的优先权等级，等级的范围从[-20, 19]，其中-20最高，19最低 (即值越小，进程优先级越高)
    - `renice` renice指令可重新调整程序执行的优先权等级。
        + e.g. `renice -5 -p 5200`, 将5200进程的nice设置为-5
    - 也可以在`top`中，输入`r`，对指定PID进行nice的调整设置

* 僵尸进程
    - 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。
    - 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为**僵尸进程**。
    - 危害：如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。
* 孤儿进程
    - 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
    - 孤儿进程不会导致资源浪费

## htop

[htop使用详解](https://www.cnblogs.com/yqsun/p/5396363.html)

官网安装：https://sourceforge.net/projects/htop/ , 下载tar.gz文件解压，./configure; make; make install

* 比较
    - 两者相比起来，top比较繁琐
    - 默认支持图形界面的鼠标操作
    - 可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行
    - 杀进程时不需要输入进程号等

* htop每列内容与top差不多，多了不少便捷的操作
    - 可以通过鼠标进行点击操作，最下方栏列出了F1~F10，都可以通过鼠标点击，当然也可以按键盘按键
    - `S` (或`F2`) 进行一些htop的设置，里面可以用鼠标操作(按快捷键会自动修改里面的配置)
        + Meters (htop顶端的显示项)
            * 分左右两边, 从Available meters中选择，F5添加到左边，F6添加到右边(最下面有操作提示信息)
            * 在对应的选项上按回车，可以选择该项展示的方式: LED会模拟液晶屏显示/Bar显示进度条/Text文本
            * 本设置：添加hostname(文本), Clock(文本，显示时间)
        + Display options (显示选项)
            * 可以设置线程是否展示、线程名称是否展示等(可以勾选显示线程名)
            * 本设置：取消用户线程隐藏、不同颜色显示线程、显示线程名、高亮程序基本名称
        + Colors 设置显示颜色，默认颜色挺舒服的
        + Columns 选择主面板要展示的列，默认的列是跟top保持一致的，可以定制选择加一些列
            * 本设置：添加读和写io、忽略信号
        + **设置是本用户生效**
    - `/` (或`F3`) 可搜索进程名，光标会跳到进程位置
    - `\` (或`F4`) 过滤进程，和F3类似，不过过滤后只显示该进程
        + 退出该模式则再次按下`\` (可以看到输入还是上次的关键字)，需要再Esc退出(此时回车只会退出本次输入)
    - `t` (或`F5`) 显示树形结构
    - `k` (或`F9`) 对进程传递信号，按下后左边会多出一个信号列表视图(右边视图停留在选择的进程)，可用鼠标或上下键选择要传递的信号
    - `q` (或`F10`) 退出htop
    - `u` 选择展示列表中某个用户的进程，要退出则再按u后选所有用户
    - `H` 显示或隐藏用户线程，默认是显示(默认显示进程名，可以设置显示线程名，不过`\`过滤时就只能过滤显示进程名，线程名不一样则显示不了，可以配合ps -Tp或者top -Hp找到对应线程号，再到htop中查看跟踪)
    - `M`/`P`/`T` 按内存/CPU/TIME+ 排序，用`I` 来倒转排序顺序
    - `s` 对选择的进程来用`strace`追踪

## 关闭终端进程退出

* 关闭是由于 SIGHUP 信号
    - [解决Linux关闭终端（关闭SSH等）后运行的程序或者服务自动停止【后台运行程序】](https://www.cnblogs.com/bohaoist/p/4965103.html)
    - [前台进程组、孤儿进程组、会话、控制终端](https://blog.csdn.net/hmsiwtv/article/details/7901711)


一些概念：

* 进程组（process group）：
    - 一个或多个进程的集合，每一个进程组有唯一一个进程组ID，即进程组长进程的ID。
* 会话期（session）
    - 一个或多个进程组的集合，有唯一一个会话期首进程（session leader）。
    - 会话期ID为首进程的ID
* 控制终端（controlling terminal）
    - 会话期可以有一个单独的控制终端
* 控制进程（controlling process）
    - 与控制终端连接的会话期首进程叫做控制进程
* 当前与终端交互的进程称为前台进程组。其余进程组称为后台进程组

* 挂断信号（SIGHUP）
    - 挂断信号（SIGHUP）默认的动作是终止程序
    - 当终端接口检测到网络连接断开，会将挂断信号发送给控制进程（会话期首进程）
    - 如果会话期首进程终止，则该信号发送到该会话期*前台进程组*

* 关闭shell终端不终止进程
    - 使用后台运行命令&，并不能摆脱ssh进程组控制，还是会发送 SIGHUP 使进程组关闭
    - 为了能够再注销以后 依然能后台运行，可以使用`nohup`命令，忽略所有挂断（SIGHUP）信号
    - `nohup ./server > /dev/null 2>&1 &`, 不关心输出则重定向到/dev/null，不指定输出位置会自动生成nohup.out
    - nohup忽略之后，关闭终端后，原终端运行进程的父进程即kill了，会变成孤儿进程，由init进程(进程号1)接收

获取正在执行的shell自身进程号：`$$`

看门狗脚本检查：

```sh
#!/bin/bash
# monitor_server.sh, 执行时为防止关闭终端受NOHUP影响，使用 "nohup ./monitor_server.sh > /dev/null 2>&1 &" 运行

server=testServer

start_server()
{
    serverpid=`ps -fe|grep testServer | grep -v gdb|grep -v grep |awk '{print $2}'`
    kill -9 $(serverpid)
    ./testServer &
}

monitornum=`ps -fe|grep "monitor_server.sh"| grep -v vi|grep -v grep |grep -v $$ |awk '{print $2}'|wc -l`
if [ $monitornum -gt 0 ]; then
    date | tee -a run.log
    echo "already exist monitor, exit" | tee -a run.log
    exit 1
fi

while true
do
    num=`ps -fe|grep testServer | grep -v gdb|grep -v grep |awk '{print $2}'|wc -l`
    if [ $num -eq 0 ]; then
        start_server
        date | tee -a run.log
        echo "restart $(server)" | tee -a run.log
    fi
    sleep 5
done
```

## pstack & gstack

* pstack
    - `which pstack` 路径为 /usr/bin/pstack
    - `ll /usr/bin/pstack`，得到 `lrwxrwxrwx. 1 root root 6 8月  22 20:26 /usr/bin/pstack -> gstack`，可知pstack实际是指向gstack的软链接

* gstack
    - `which gstack` 路径为 /usr/bin/gstack
    - `vim /usr/bin/gstack` 打开gstack，可以看到它实际是一个脚本，其包装了gdb bt，并用sed对gdb bt的输出结果做了过滤而已

## last 命令

* last
    - last命令用于显示最近登录的用户列表
    - last向后检索/var/log/wtmp文件(也可-f指定检索文件)，并显示自这个文件创建以来所有登录（退出）系统的用户列表。
    - 选项
        + `-a` 在最后一列显示主机名(不-a时主机名也会显示，显示在别的列而不是最后一列，-R指定不显示该列)
        + `-i` 显示远程主机(即非本机)的IP地址
        + `-d` 显示远程主机(即非本机)的主机名
        + `-x` 显示系统关机记录和运行级别改变
            * 相比没有-x会多显示运行级别改变的日志。
            * 开机之后，runlevel会变，可以此判断开机；关机则可根据关键词reboot过滤，或者直接 `last reboot`也可
        + 命名后面空格+用户名，可以只显示指定用户的登录退出记录 e.g. `last xd -ai`
            * `last reboot` 每次系统重新**启动**时，*虚用户:reboot*都会被记录到日志中。所以`last reboot`会列出自日志文件创建以来的所有重新启动的日志记录。

`last -axi`执行结果截取：

```sh
root     pts/2        Mon Dec  9 09:01   still logged in    192.168.50.204
root     pts/1        Mon Dec  9 09:00 - 12:27  (03:26)     192.168.50.234
# 运行级别修改，此处系统启动后进入图形GUI模式(runlevel 5)
runlevel (to lvl 5)   Mon Dec  9 08:59 - 14:57  (05:58)     0.0.0.0
root     pts/0        Mon Dec  9 08:59 - 13:45  (04:46)     192.168.50.234
# 系统启动，虚用户reboot被记录(没有关闭机器的记录是因为直接操作机器电源关闭的，而不是reboot)
reboot   system boot  Mon Dec  9 08:58 - 14:57  (05:59)     0.0.0.0
root     pts/2        Fri Dec  6 18:50 - 02:04  (07:13)     192.168.50.204
root     pts/1        Fri Dec  6 18:50 - 02:03  (07:13)     192.168.50.204
# 系统启动
runlevel (to lvl 5)   Fri Dec  6 18:48 - 08:59 (2+14:11)    0.0.0.0
root     pts/0        Fri Dec  6 18:48 - 02:03  (07:15)     192.168.50.204
# 系统启动
reboot   system boot  Fri Dec  6 18:47 - 14:57 (2+20:10)    0.0.0.0
# 系统关闭，此处手动敲了reboot
shutdown system down  Fri Dec  6 18:47 - 18:47  (00:00)     0.0.0.0
root     pts/7        Fri Dec  6 16:20 - down   (02:26)     192.168.50.234
root     pts/3        Fri Dec  6 15:48 - down   (02:58)     192.168.50.204
```

## 运行级别

* Linux系统的7个运行级别(runlevel)
    - 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动
    - 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆
    - 运行级别2：多用户状态(没有NFS)
    - 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式
    - 运行级别4：系统未使用，保留
    - 运行级别5：X11控制台，登陆后进入图形GUI模式
    - 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动

* `/etc/rc.d/init.d`
    - `/etc/rc.d/init.d`下有许多服务器脚本程序，一般称为服务(service)
    - `/etc/init.d` 是指向 `/etc/rc.d/init.d`的软链接
    - 在/etc/rc.d下有7个名为rcN.d的目录(N为0-7)，对应系统的7个运行级别
        + rcN.d目录下都是一些符号链接文件，这些链接文件都指向init.d目录下的service脚本文件
        + 命名规则为K+nn+服务名或S+nn+服务名，其中nn为两位数字，e.g. `K90network -> ../init.d/network`
            * 对于以K开头的文件，系统将终止对应的服务
            * 对于以S开头的文件，系统将启动对应的服务
        + 系统会根据指定的运行级别进入对应的rcN.d目录，并按照文件名顺序检索目录下的链接文件
    - 查看运行级别用：`runlevel`
        + e.g. 本地CentOS虚拟机执行结果：`N 3`，命令行模式
    - 进入其它运行级别用：`init N`
        + `init 0`为关机，`init 6`为重启系统(默认运行级别不能设为6，否则不能正常启动)
        + 现在的Linux系统安装完后就运行在第5个级别，即系统启动后直接进入图形界面，而不用在字符模式下登录后用startx或者xinit 来起动图形界面。
        + 默认运行等级设置：`/etc/inittab`，使用systemd后不再使用该配置文件
            * `systemctl get-default` 查看
            * `systemctl set-default TARGET.target` 设置
        + 在任何运行级别，用户都可用init 命令来切换到其他运行级别


## crontab

linux系统由 cron (crond) 这个系守护进程服务来控制循环运行的例行性计划任务

crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。

* Linux下的任务调度分为两类，系统任务调度和用户任务调度。
    - 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。
    - 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。

* crontab
    - `-l` 显示当前crontab
    - `-r` 移除, `-i`去掉移除时的提示
    - `-e` 编辑

* cron 的主配置文件是 /etc/crontab
* 当我们要增加全局性的计划任务时，一种方式是直接修改/etc/crontab。但是，一般不建议这样做，/etc/cron.d目录就是为了解决这种问题而创建的。
    - 增加一项定时的备份任务，我们可以这样处理：在/etc/cron.d目录下新建文件backup.sh
    - cron进程执行时，就会自动扫描该目录下的所有文件，按照文件中的时间设定执行后面的命令。
    - cron执行时，也就是要读取三个地方的配置文件：一是`/etc/crontab`，二是`/etc/cron.d`目录下的所有文件，三是每个用户的配置文件
* 日志
    - linux(计划任务执行记录): /var/log/cron.log
    - mail任务(如果计划任务执行出错，mail中的信息比较详细): /var/spool/mail/root 或者 /var/mail/root(用户名)
        + `/var/mail` 是 指向 `/var/spool/mail`目录 的软链接
* crontab -e报找不到vi问题
    - 可以在.bashrc中设置环境变量`VISUAL`或者`EDITOR`为vi的路径，注意需要绝对路径，e.g. `export EDITOR=/usr/local/bin/vim`
    - `EDITOR`历史上用于更早期的编辑器，`VISUAL`用于比较高级的编辑器(如vi/emacs)，不过目前两者是兼容的，如果在bash终端调用一个编辑器，bash先会找`VISUAL`指定的编辑器，如果失败则会找`EDITOR`指定的编辑器
    - 参考：[VISUAL vs. EDITOR – what’s the difference?](https://unix.stackexchange.com/questions/4859/visual-vs-editor-what-s-the-difference)

/etc/crontab文件：

```sh
# 前四行是用来配置crond任务运行的环境变量
# 第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。
SHELL=/bin/bash
PATH=/sbin:/bin:/usr/sbin:/usr/bin
MAILTO=root

# For details see man 4 crontabs

# Example of job definition:
# .---------------- minute (0 - 59)
# |  .------------- hour (0 - 23)
# |  |  .---------- day of month (1 - 31)
# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...
# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat
# |  |  |  |  |
# *  *  *  *  * user-name  command to be executed
```

在以上各个字段中，还可以使用以下特殊字符：

- 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。
- 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”
- 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”
- 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。

对于命名：如果是自己新建的crontab文件，命名成 "crontab", "crontab.xd"，用vim打开都能显示语法高亮;
而"crontab_xd", "xd_crontab", "crontab_xd.xd"则不行。 使用crontab.用户名方式命名

### 环境变量问题

不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点：

1）脚本中涉及文件路径时写全局路径；

2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如：

```sh
cat start_cbp.sh

#!/bin/sh
source /etc/profile
export RUN_CONF=/home/d139/conf/platform/cbp/cbp_jboss.conf
/usr/local/jboss-4.0.5/bin/run.sh -c mev &
```

3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如：

```
0 * * * * . /etc/profile;/bin/sh /var/www/java/audit_no_count/bin/restart_audit.sh
```

### 部分用法示例：

更多实例查看上面的链接

* 每隔两分钟执行

  `*/2 * * * * cmd`

* 每小时的奇数分钟执行，（0不执行，1执行）

  `1-59/2 * * * * cmd`

* 每天18:00至23:00间每隔30分钟

  `0,30 18-23 * * * cmd`

  `0-59/30 18-23 * * * cmd`

> * `A,B,C` A或B或C
* `A-B` A到B之间
* `*/A` 每A分钟（小时等）

* 两小时运行一次，注意分钟要设置值

  `* */2 * * * cmd （错误）`
  `0 */2 * * * cmd （正确）`

## Zabbix

[Zabbix 3.0 从入门到精通(zabbix使用详解)](https://www.cnblogs.com/clsn/p/7885990.html)

* 网站/服务器 的可用性 和 监控内容
    - 高可靠性(高可用)，HA(High Avaiable)
    - 一个衡量可靠性的标准——X个9，X代表数字3~5
        + X个9表示在软件系统1年时间的使用过程中，系统可以正常使用时间与总时间（1年）之比
            * 1个9：`(1-90%)*365=36.5天`，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是36.5天
            * 2个9：`(1-99%)*365=3.65天`，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是3.65天
            * 3个9：`(1-99.9%)*365*24=8.76小时`，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是8.76小时
            * 4个9：`(1-99.99%)*365*24=0.876小时=52.6分钟`，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是52.6分钟
            * 5个9：`(1-99.999%)*365*24*60=5.26分钟`，表示该软件系统在连续运行1年时间里最多可能的业务中断时间是5.26分钟
            * 6个9：`(1-99.9999%)*365*24*60*60=31秒`，示该软件系统在连续运行1年时间里最多可能的业务中断时间是31秒
    - 监控内容
        + 监控硬件，温度/风扇转速等：ipmitool
        + cpu相关：lscpu、uptime、top、htop vmstat mpstat
        + 内存：free
        + 磁盘：df、dd、iotop
        + 网络：iftop、netthogs
    - 监控工具总览
        + mrtg 流量监控出图
        + nagios 监控
        + cacti 流量监控出图
        + zabbix 监控+出图

### Zabbix介绍

- 介绍
    + `Zabbix` 是由 `Alexei Vladishev` 开发的一种网络监视、管理系统，基于 Server-Client架构。可用于监视各种网络服务、服务器和网络机器等状态。
        * `Alexei Vladishev` 是 `Zabbix LLC` 公司的CEO兼创始人
    + Server 端基于 C语言、Web 管理端 frontend 则是基于 PHP 所制作的
    + 在客户端如 UNIX, Windows 中安装 Zabbix Agent 之后，可监视 CPU Load、网络使用状况、硬盘容量等各种状态。而就算没有安装 Agent 在监视对象中，Zabbix 也可以经由 SNMP、TCP、ICMP、利用 IPMI、SSH、telnet 对目标进行监视。
    + 另外，Zabbix 包含 XMPP 等各种 Item 警示功能。
- Zabbix 主要由2部分构成 zabbix server和 zabbix agent
- 安装(Zabbix 3.0)
    + 安装zabbix源

### 官网文档

[Zabbix 产品手册](https://www.zabbix.com/documentation/4.0/zh/manual)

* 介绍
    - Zabbix 由 Alexei Vladishev 创建，目前由其成立的公司—— Zabbix SIA 积极的持续开发更新维护， 并为用户提供技术支持服务。
    - Zabbix 是一个企业级分布式开源监控解决方案。
    - Zabbix 软件能够监控众多网络参数和服务器的健康度、完整性。
    - Zabbix 使用灵活的告警机制，允许用户为几乎任何事件配置基于邮件的告警。
    - Zabbix 基于存储的数据提供出色的报表和数据可视化功能。
    - Zabbix 支持主动轮询（polling）和被动捕获（trapping）。Zabbix所有的报表、统计数据和配置参数都可以通过基于 Web 的前端页面进行访问。
    - Zabbix 是免费的。Zabbix 是根据 GPL 通用公共许可证的第二版编写和发布的。这意味着产品源代码是免费发布的，可供公共使用。
* Zabbix 概述
    - `Zabbix server` 是 Zabbix软件的核心组件，agent 向其报告可用性、系统完整性信息和统计信息。server也是存储所有配置信息、统计信息和操作信息的核心存储库。
    - `数据库` 所有配置信息以及 Zabbix 采集到的数据都被存储在数据库中。
    - `Web 界面` 为了从任何地方和任何平台轻松访问 Zabbix ，我们提供了基于 web 的界面。该界面是 Zabbix server 的一部分，通常（但不一定）和 Zabbix server 运行在同一台物理机器上。
    - `Zabbix proxy` 可以代替 Zabbix server采集性能和可用性数据。(Zabbix proxy在Zabbix的部署是可选部分，可分担单个server负载)
    - `Zabbix agents` 部署在被监控目标上，用于主动监控本地资源和应用程序，并将收集的数据发送给 Zabbix server。
    - `数据流` 如果您想要收到类似“X个server上CPU负载过高”这样的告警
        + 首先为 Server X 创建一个主机条目
        + 其次创建一个用于监控其 CPU的监控项
        + 最后创建一个触发器（trigger），用来触发 CPU负载过高这个动作（action），并将其发送到您的邮箱里
        + 虽然这些步骤看起来很繁琐，但是使用模板的话，实际操作非常简单。也正是由于这种设计，使得 Zabbix 的配置变得更加灵活易用。
* 定义(Zabbix中常用术语的含义)
    - [2. 定义](https://www.zabbix.com/documentation/4.0/zh/manual/definitions)
    - 主机（host）
        + 你想要监控的联网设备，有IP/DNS。
    - 主机组（host group)
        + 主机的逻辑组；可能包含主机和模板。
    - 监控项（item）
        + 你想要从主机接收的特定数据，一个度量（metrics）/指标数据
    - 值预处理（value preprocessing）
        + 存入数据库之前，转化/预处理接收到的指标数据
    - 触发器（trigger）
        + 触发器是一个逻辑表达式，用来定义问题阈值和“评估”监控项接收到的数据
        + 当接收到的数据高于阈值时，触发器从“OK”变成“Problem”状态。当接收到的数据低于阈值时，触发器保留/返回“OK”的状态。
    - 事件（event）
        + 发生的需要注意的事件，例如触发器状态改变、自动发现/监控代理自动注册
    - 异常（problems）
        + 处在“异常”状态的触发器
    - 异常状态更新（problem update）
        + Zabbix提供的异常管理选项，例如添加评论、确认异常、改变严重级别或者手动关闭等。
    - 动作（action）
        + 预先定义的应对事件的动作
        + 一个动作由操作(例如发出通知)和条件(什么时间进行操作)组成
    - 远程命令（remote command）
        +  预定义好的，满足特定条件的情况下，可以在被监控主机上自动执行的命令。
    - 模版（template）
        + 被应用到一个或多个主机上的一整套实体组合（如监控项，触发器，图形，聚合图形，应用，LLD，Web场景等）。
        + 模版的应用使得主机上的监控任务部署快捷方便；也可以使监控任务的批量修改更加简单。模版是直接关联到每台单独的主机上。
    - 仪表板（dashboard）
        + 自定义的web前端模块中，用于重要的概要和可视化信息展示的单元， 我们称之为组件（widget）。
    - 组件（widget）
        + Dashboard中用来展示某种信息和数据的可视化组件（概览、map、图表、时钟等）。
    - Zabbix API
        + Zabbix API允许用户使用JSON RPC协议来创建、更新和获取Zabbix对象（如主机、监控项、图表等）信息或者执行任何其他的自定义的任务
    - Zabbix server
        + Zabbix软件的核心进程，执行监控操作，与Zabbix proxies和Agents进行交互、触发器计算、发送告警通知；也是数据的中央存储库
    - Zabbix agent
        + 部署在监控对象上的进程，能够主动监控本地资源和应用
    - Zabbix proxy
        + 代替Zabbix Server采集数据，从而分担Zabbix Server负载的进程
    - agent自动注册（agent auto-registration）
        + Zabbix agent自己自动注册为一个主机，并且开始监控的自动执行进程。

#### 安装

- 四种方法
    + 从 发行包 安装；
    + 下载最新的归档源码包并 编译它；
    + 从 容器 中安装；
    + 下载 Zabbix 应用。
- 从发行包(二进制包)安装(CentOS 7)
    + [Red Hat Enterprise Linux/CentOS](https://www.zabbix.com/documentation/4.0/zh/manual/installation/install_from_packages/rhel_centos)
    + 添加 Zabbix 软件仓库
        * 安装软件仓库配置包，这个包包含了 yum（软件包管理器）的配置文件。
            - `rpm -ivh http://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm`
        * 前端安装的先决条件，Zabbix 前端需要额外的基础安装包。 您需要在运行 Zabbix 前端的系统中启用可选 rpms 的软件仓库：
            - `yum-config-manager --enable rhel-7-server-optional-rpms`
    + 安装 Server/proxy/前端 (自己只安装server和web前端)
        * 安装 Zabbix server（适用于 RHEL7，在 RHEL 6 上弃用）并使用 MySQL 数据库(若用pg数据库则mysql替换为pgsql)：
            - `yum install zabbix-server-mysql`
        * 安装 Zabbix 前端（适用于 RHEL 7，在 RHEL 6 上弃用）并使用 MySQL 数据库：
            - `yum install zabbix-web-mysql`
    + 创建数据库
        * 对于 Zabbix server 和 proxy 守护进程而言，数据库是必须的。而运行 Zabbix agent 是不需要的。如果 Zabbix server 和 Zabbix proxy 安装在相同的主机，它们必须创建不同名字的数据库！
    + 导入数据
        * 使用 MySQL 来导入 Zabbix server 的初始数据库 schema 和数据
            - 创建数据库`create database zabbix`
            - 创建zabbix用户 `create user zabbix identified by 'zabbix';`，选择zabbix.*赋全部权限：`grant all on zabbix.* to zabbix;`
            - `zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix`
            - `zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -h 192.168.xxx.xxx -uroot -p zabbix` 使用root，docker环境的mysql
    + 为 Zabbix server/proxy 配置数据库(本地proxy不使用)
        * `vi /etc/zabbix/zabbix_server.conf`
            - DBHost=localhost(设置ip)
            - DBName=zabbix
            - DBUser=zabbix
            - DBPassword=<password>
    + 启动 Zabbix server 进程
        * `service zabbix-server start`
    + 设置开机启动
        * `systemctl enable zabbix-server`
    + Zabbix 前端配置
        * 对于 RHEL 7 和更高版本，Zabbix 前端的 Apache 配置文件位于 `/etc/httpd/conf.d/zabbix.conf`。
        * 取消 "date.timezone" 注释，并设置当前时区，ll /etc/localtime查看链接的时区文件为`../usr/share/zoneinfo/Asia/Shanghai`，则设置为"Asia/Shanghai"
    + SELinux 配置
        * getenforce本地关闭了SELinux，若开启需要参考进行配置
    + 前端和SELinux配置完成后重新启动Apache web服务器
        * `service httpd restart`
        * 设置httpd开机启动 `systemctl enable httpd`
    + 安装 Agent
        * 安装：`yum install zabbix-agent`
        * 启动：`service zabbix-agent start`
    + 安装完成，按链接检查前端安装项，数据库地址、用户密码等
        * [前端安装步骤](https://www.zabbix.com/documentation/4.0/manual/installation/install#installing_frontend)
        * 确认配置完成后，会出来登录页面，默认用户： Admin, 密码： zabbix

#### 入门使用

- [5. 快速入门](https://www.zabbix.com/documentation/4.0/zh/manual/quickstart/login)
- 配置
    + 可以切换中文：点击右上角人体图标->User->Language->选Chinese
    + Admin登录，可以看到`配置（Configuration）` and `管理（Administration）` 菜单(权限)
    + 增加用户
        * 管理（Administration） → 用户（Users）
        * `媒介`
            - 默认情况下，没有为新增的用户定义媒介（media，即通知发送方式)
            - 如需要创建，可以到'媒介（Media）'标签下（用户->报警媒介)，然后点击增加（Add）
        * `添加权限`
            - 默认的情况下，一个新用户没有全选访问任何主机
            - 在Zabbix中，主机的访问权限是被分配到用户组，而不是单个用户。
            - 修改用户组后在用户列表界面的用户类型可体现，超级管理员/管理员/用户
    + 新建主机
        * Zabbix中的主机（Host）是一个你想要监控的网络实体（物理的，或者虚拟的）。
        * 配置（Configuration） → 主机（Hosts）菜单，查看已配置的主机信息。
            - 默认已有一个名为'Zabbix server'的预先定义好的主机。
            - 建议不要修改该默认名称，该名称和zabbix_agentd.conf里面的Hostname要一样，否则会报“cannot send list of active checks to "127.0.0.1": host [Zabbix server] not found”
        * 主机名称，可以使用字母数字、空格、点"."、中划线"-"、下划线"_"。
        * 选择一个或者多个组
        * 输入主机的IP地址。注意如果这是Zabbix server的IP地址，它必须是Zabbix agent配置文件中‘Server’参数的值。
            - 要监控的主机上，zabbix_agentd.conf配置文件中的Server或者ServerActive配置加上zabbix server的地址(,分隔)并重启服务
            - 配置文件可以配置日志位置，和日志等级，出现问题时可以开启debug等级排查问题`DebugLevel`设置为4
    + 新建监控项
        * 监控项是Zabbix中获得数据的基础。没有监控项，就没有数据——因为一个主机中只有监控项定义了单一的指标或者需要获得的数据。
        * 所有的监控项都是依赖于主机的。当我们要配置一个监控项时，先要进入 `配置` → `主机` 页面查找到新建的主机。
        * 新主机的`监控项`列数字没有或者是0，点击`监控项`进入->创建监控项（Create item）
            - `名称（Name）` 输入 CPU Load 作为值
            - `值（Key）` 手动输入 `system.cpu.load` 作为值(下拉框出来的`system.cpu.load[<cpu>,<mode>]` **会提示无效参数**)
            - `信息类型（Type of information）` float
            - 减少监控项历史保留的天数，7或者14天。对于数据库而言，最佳实践是避免数据库保留过多的历史数据。
            - 当完成后，点击添加（Add）。新的监控项将出现在监控项列表中。点击列表中的详细（Details）以查看具体细节。
            - (如果`Key`参数错误，修改后点击`现在检查`，再点更新，日志提示"xxxname:system.cpu.load" became supported)
        * 查看数据
            - 监控/或监测（Monitoring）(页面最上面一栏) → 最新数据（Latest data）, 在过滤器中选择刚才新建的主机，然后点击应用（Apply)。
            - 如果你在没有看到类似截图中的监控项信息，请确认：
                + 输入的监控项'值（Key）' 和 '信息类型（Type of information）'正确
                + agent和server都在运行状态
                + 主机状态为'监控（Monitored）'并且它的可用性图标是绿色的
                + 在主机的下拉菜单中已经选择了对应主机，且监控项处于启用状态
    + 新建触发器
        * 如果收到的数据超过了这个定义好的级别，触发器将被“触发”，或者进入“异常（Problem）”状态
        * 如果数据再次`恢复`到合理的范围，触发器将会到“正常（Ok）”状态。
        * `配置` -> `主机` -> 选择一个主机找到`触发器`列点击进入 -> 右上角`创建触发器`
            - `名称（Name）` 输入："CPU load too high on 'xdCentOS_50.118' for 3 minutes"作为值。这个值会作为触发器的名称被现实在列表和其他地方
            - `表达式（Expression）` 输入：`{xdCentOS_50.118:system.cpu.load.avg(3m)}>2`
                + 此处，监控项值(system.cpu.load)用于指出具体的监控项。如果3分钟内，CPU负载的平均值超过2，那么就触发了问题的阈值。
                + 界面提供了`表达式构造器`用于便捷构造表达式
            - 完成后，点击添加（Add）。
        * 显示触发器状态
            - 如果CPU负载超过了你在触发器中定义的阈值，这个问题将显示在`监控/监测（Monitoring）` → `问题（Problems）`中。
            - 闪烁意味着这个触发器状态最近30分钟内发生过变化。
    + 获取问题通知
        * 当监控项收集了数据后，触发器会根据异常状态触发报警。
        * 根据一些报警机制，它也会通知我们一些重要的事件，而不需要我们直接在Zabbix前端进行查看。
        * 这就是`通知（Notifications）`的功能。`E-mail`是最常用的异常通知发送方式。
            - `E-mail配置` `管理（Administration）` → `报警媒介类型（Media types）`→ `Email` 进行配置
                + SMTP服务器地址设置
                    * 使用外部SMTP服务器(e.g. 注册qq邮箱开启SMTP获取授权码，可参考：[Zabbix使用QQ邮箱通知](https://www.cnblogs.com/yinzhengjie/p/10389897.html))
                    * 自己尝试Linux搭建SMTP服务器，postfix/dovecot，尝试失败。。。
                + 现在你已经配置了'Email'作为一种可用的媒体类型。一个媒体类型必须通过发送地址来关联用户(如同我们在配置一个新用户中做的)，否则它将无法生效。
            - `新建动作`
                + 发送通知是Zabbix中动作（actions）执行的操作之一
                + 因此，为了`建立一个通知`，前往`配置（Configuration）` → `动作（Actions）`，然后点击`创建动作（Create action）`。
                + `新建操作` 我们还需要定义这个动作具体做了什么 —— 即在 `操作（Operations）标签页`中执行的操作。
                    * 点击"新的"，进行操作定义，选用户组或者用户
        * 可以在`报表（Reports）` → `动作日志（Action log）`中检查动作日志
* 模板
    - [6 新建模板](https://www.zabbix.com/documentation/4.0/zh/manual/quickstart/template)
    - 在之前的章节中学会了如何配置监控项、触发器，以及如何从主机上获得问题的通知。
    - 虽然这些步骤提供了很大的灵活性，但仍然需要很多步骤才能完成。如果我们需要配置上千台主机，一些自动化操作会带来更多便利性。
    - 模板（templates）功能可以实现这一点。模板允许对有用的监控项、触发器和其他对象进行分组，只需要一步就可以对监控主机应用模板，以达到反复重用的目的。
    - `创建模板`：配置（Configuration） → 模板（Templates）→ 创建模板，创建后添加监控、添加触发器等信息
        + 创建时需要选择群组，模板必须属于一个组。
    - `链接模版到主机`：配置 -> 主机 -> 选择一个主机 -> 点击模板页 -> 选择某个或者某些模板
    - `取消链接模板`
        + Unlink - 取消链接模板，但保留它的监控项、触发器和图表(主机的监控项等信息还在)
        + Unlink and clear - 取消链接模板并删除所有它的监控项、触发器和图表

#### 配置

* 监控项
    - 监控项键值(Key)的格式：形如 `icmpping[,,200,,500]`
        + 允许字符：`0-9a-zA-Z_-.`
            * 另外参数相关的字符：`[ , ]`
        + 参数：监控项的键值可以有多个逗号分隔的参数；
            * 参数也可以为空，此时使用默认值。
            * 如果指定了后面的其它参数，则**该参数前面的参数位置**必须添加对应数量的逗号。
        + 每个key参数可以是带引号、无引号的字符串或数组
            * 仅支持用双引号，不支持单引号。
    - 时间格式
        + 时间间隔包含
            * `md` - month days
            * `wd`或者`w` - week days
            * `h` - hours
            * `m` - minutes
            * `s` – seconds
        + 自定义时间间隔
            * `灵活间隔`，包含：间隔和周期
                - e.g. 间隔`10` 周期`1-5,09:00-18:00` 监控项将在工作日时间内每10秒检查一次。(间隔设置0则表示周期内不做检查)
            * `调度间隔`，在特定时间检查监控项
                - 格式：`md<filter>wd<filter>h<filter>m<filter>s<filter>`
                    + filter定义为： `[<from>[-<to>]][/<step>]`
                - e.g. `wd1-5h9`      每周一至周五9:00
                - e.g. `h9m0-59/30`   在9:00，9:30执行(即0-59分，间隔30m)
                - 更多示例见：[示例](https://www.zabbix.com/documentation/4.0/zh/manual/config/items/item/custom_intervals)
* 日志文件监控
    - [日志文件监控](https://www.zabbix.com/documentation/4.0/zh/manual/config/items/itemtypes/log_items)
    - Zabbix可以集中监控和分析 支持/不支持日志轮询的日志文件。
    - 当日志文件**包含某些字符串或字符串模式**时，可以使用通知来警告用户。
        + 被监控日志文件的大小限制取决于 大文件支持(32为操作系统上能力能达到 2 GB)。
    - 配置要求(/etc/zabbix/zabbix_agentd.conf)：
        + 'Hostname'参数与前端的主机名一致
            * **说明**：设置成主动监控项在的那个主机名，并不是指"Zabbix server"这台
        + 'ServerActive'参数中的服务器被指定用于处理主动检查
            * 指定 Zabbix server 或者 Zabbix proxy 的地址
        + 关于配置文件的各项说明可参考：[Zabbix agent (UNIX)](https://www.zabbix.com/documentation/4.0/manual/appendix/config/zabbix_agentd)
    - zabbix用户需要有对应日志文件的权限
        + 安装zabbix时，自动添加了zabbix用户(/sbin/nologin类型，即不可登录)，使用时报错了(提示无权限)：active check "log[/home/xxxfile,”xdtest”,,,skip,,]" is not supported: Cannot obtain information for file "/home/xxxfile": [13] Permission denied
        + **解决：** `usermod -a -G root zabbix` 把zabbix加入到root组中(文件权限为`-rw-r--r-- 1 root root`，同组和不同组用户看起来都有读权限，但还是把zabbix加到root组吧，还不明确是什么原因导致权限拒绝了)
            * (试过`visudo`添加zabbix到sudoers中并不行，貌似添加了只是支持以root权限运行命令而已："Allow root to run any commands anywhere"，还是建议加一下，后面介绍的远程执行命令需要有执行权限`zabbix ALL=NOPASSWD: ALL`)
            * (试过chown把文件和目录改为zabbix用户和zabbix组也不行)
    - 监控项配置
        + `类型(Type)`
            * 选择`Zabbix agent (active)` (对应中文界面：`Zabbix客户端(主动式)`，翻译应该翻译为代理)
        + `键值(Key)`
            * log相关的各个参数说明可参考(log项)：[1 Zabbix客户端](https://www.zabbix.com/documentation/4.0/zh/manual/config/items/itemtypes/zabbix_agent#supported_item_keys)
            * `log[file,<regexp>,<encoding>,<maxlines>,<mode>,<output>,<maxdelay>]`
                - `file`：日志文件完整路径和名称
                - `encoding`：编码标识符，"UTF-8"/
                - `maxlines`：Agent将发送到Zabbix服务器或代理的每秒最大行数。 此参数覆盖zabbix_agentd.conf中的“MaxLinesPerSecond”值(默认20行)
                - `mode`：all (默认值)； skip 跳过历史的数据（即只管日志新增的内容）
                - `output`：输出格式模板，可以自定义输出的格式。 `regexp`正则表达式中格式化匹配的位置可以用`\N`(N可以取值0-9)表示，会替换为对应的位置。
                    + e.g. `regexp表达式`为"task run [0-9.]+ sec, processed ([0-9]+) records"，且日志行为"2015-11-13 10:08:26 task run 6.08 sec, processed 6080 records, 0 errors"，则`\1`表示`6080`
                - `maxdelay`：最大延迟（秒数，浮点型），若>0.0，则可以只分析maxdelay秒内的行
                - 示例：
                    + `log[/var/log/syslog]`
                    + `log[/var/log/syslog,error]` 匹配关键字error
                    + `log[/home/zabbix/logs/logfile,,,100]` 每秒最烦发送100行(指定参数前面的参数位置置空并用,隔开，其后不必)
            * `logrt[file_regexp, <regexp>,<encoding>,<maxlines>,<mode>,<output>,<maxdelay>]`
                - `file_regexp` 文件名以及正则表达式定义的文件名的绝对路径，可以匹配满足一定模式的文件列表
                - `{logrt[/root/log_[0-9]{4}-[0-12]{2}-[1-31]{2}.txt]`
            * `log.count[file,<regexp>,<encoding>,<maxproclines>,<mode>,<maxdelay>]`
                - `maxproclines`：Agent每秒将分析的最大行数。默认值为 10*'MaxLinesPerSecond'(即若配置文件保持默认则分析为200行)
            * logrt.count
        + `更新间隔Update interval (in sec)`
            * 该参数定义了Zabbix代理检查日志文件中任何更改的频率。将其设置为`1秒`将确保你能尽快的获得新记录。
    - 注意事项
        + 代理从上次停止的点开始读取日志文件。(所以是否设置mode为skip关系不大?)
        + 在代理刚刚启动或已收到以前被禁用或不支持的监控项的情况下，*已经分析的*字节数（大小计数器）和最后修改时间（时间计数器）*存储在Zabbix数据库中*并发送到代理，以确保代理从此开始读取日志文件。
        + 每当日志文件变得小于代理已知的日志大小计数器时，计数器将重置为零，代理从开始位置读取日志文件，将时间计数器考虑在内。
        + Zabbix agent每 `Update interval` 秒处理一次日志文件的新记录。
        + 对于大于256kB的日志文件记录，只有前256kB与正则表达式匹配，而其余部分将被忽略。(1MB的日志更新就识别不到了？**待测**)
        + 'maxdelay'>0可能导致 忽略重要的日志文件记录和错过的报警 ，只有在必要时才使用
        + 默认情况下，日志监控项将跟踪出现在日志文件中的所有新行。日志文件中写入大量的消息时，所有这些消息将被完全分析，可配置“maxlines”参数进行限制。
            - 但依旧存在两个问题：
                + 1. 向服务器报告大量潜在的不太有用的消息，消耗数据库中的空间。
                + 2. 由于每秒分析的行数有限，代理可能会滞后于最新的日志记录数小时。
            - 解决方案是通过`maxdelay`参数
                + 如果指定'maxdelay'> 0，在每次检查处理字节数时，将测量剩余字节数和处理时间(代理会根据这些数字估计剩余需要的秒数)。
                + 如果延迟不超过“maxdelay”，那么代理将像往常一样继续分析日志文件。
                + 如果延迟大于“maxdelay”，那么代理将通过“跳转”到一个新的*估计位置*来忽略日志文件的一个块， 以便在“maxdelay”秒内分析剩下的行。
                + **不推荐设置 'maxdelay' < 'update interval'（这可能会导致频繁的“jumps”）**
                + e.g. `log[/root/xxx,,,,skip,,5]`
    - 若有两个监控项监控同一个日志文件，有时只生效一个(现象比较奇怪，尝试了很久，对同一文件尽量不要有多个日志监控项)
* 触发器
    - [3 触发器](https://www.zabbix.com/documentation/4.0/zh/manual/config/triggers)
        + [2 触发器表达式](https://www.zabbix.com/documentation/4.0/zh/manual/config/triggers/expression)
        + 支持的函数：[1 Supported trigger functions](https://www.zabbix.com/documentation/4.0/manual/appendix/triggers/functions)
            * `avg (sec|#num,<time_shift>)` 平均值
                - 参数一表示最大计算周期，可取值1h,3s等形式；和#5形式，表示最近5个值，`avg(1h)`表示一小时平均值
                - 参数二表示时间偏移，如 `avg(1h,1d)`表示1天前的一小时平均值
            * `last (<sec|#num>,<time_shift>)` 最近的值
                - 参数一表示最大计算周期
                    + `last()`和`last(#1)`等价，最近一个值，`last(#3)`最近第三个值(不是最近三个)
                - 参数二时间偏移，和avg中一致，表示时间偏移前的值
* 动作
    - 若要远程操作，则需agent配置文件里配置选项 `EnableRemoteCommands=1`，是否日志记录也可选择开启`LogRemoteCommands=1`
    - `sudo sh /root/xxx.sh` 执行命令时需要指定`sudo`
        + 且在/etc/sudoers文件中加上(通过`visudo`编辑)：`zabbix     ALL=NOPASSWD: ALL`
        + 默认情况下，Zabbix用户没有权限重新启动系统服务。
    - 远程命令不适用于主动模式Zabbix代理
    - 可以设置循环多个通知或操作(通过步骤列来控制次数)，参考下面链接示例(但每个操作之间默认时间60s-604800s之间，如果要立即执行操作和通知，目前自己方式是新建两个动作分别处理。。。)
    - [2 远程命令](https://www.zabbix.com/documentation/4.0/zh/manual/config/notifications/action/operation/remote_command)
* 宏
    - 支持的宏：[1 宏使用场景](https://www.zabbix.com/documentation/4.0/zh/manual/appendix/macros/supported_by_location)
        + 监控项: {ITEM.KEY1}
        + 触发器内容: {TRIGGER.EXPRESSION}
        + 时间和日期: {EVENT.TIME} on {EVENT.DATE}
        + 事件名: {EVENT.NAME}
        + 主机: {HOST.NAME}
        + 严重程度: {EVENT.SEVERITY}
        + 事件 ID: {EVENT.ID}

## SMTP

## DNS

[DNS详解: A记录,子域名,CNAME别名,PTR,MX,TXT,SRV,TTL](https://yq.aliyun.com/articles/611293)

A记录 A (Address) 记录是用来指定主机名（或域名）对应的IP地址记录。

## netstat

* netstat
    - `netstat -anp`
    - `netstat -nptul` 所有监听的连接
        + `-t` [--tcp|-t]
        + `-u` [--udp|-u]
        + `-l` [--listening|-l] 只显示正在侦听的套接字
        + `-p` [--program|-p]   显示套接字所属进程的PID和名称
        + `-n` [--numeric|-n]   显示数字形式地址而不是去解析主机、端口或用户名。
            * 前面描述`ps`时写过选项的风格
                - UNIX options，前面必须有一个破折号"-"
                - BSD options，不能使用破折号
                - GNU long options，前面有两个破折号"--"

## 负载均衡

LB集群是load balance 集群的简写，负载均衡集群
LVS是一个实现负载均衡集群的开源软件项目
LVS架构从逻辑上可分为调度层(Director)、server集群层(Real server)和共享存储层


golang consul-grpc服务注册与发现

## Ubuntu安装

* 镜像源
  - [中科大](http://mirrors.ustc.edu.cn/ubuntu-releases/) 速度挺快的