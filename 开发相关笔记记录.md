[TOC]


## Tips

开发过程过程中注意空格影响！
  makefile字符串赋值给变量时末尾空格(编辑器尽量开启空格和tab显示)


## REST

REST API: 即Representational State Transfer(表述性状态转移)的缩写
其优点如下：

* 在RESTful架构中，每一个URL代表一种资源；
* 客户端和服务器之间，传递这种资源的某种表现层；
* 客户端通过四个HTTP指令，对服务器端资源进行操作，实现“表现层状态转化”。 建议开发者使用REST API进行币币交易或者资产提现等操作。

## WebSocket API

WebSocket API: WebSocket是HTML5一种新的协议(Protocol)。

>它实现了客户端与服务器全双工通信，使得数据可以快速地双向传播。

通过一次简单的握手就可以建立客户端和服务器连接，服务器根据业务规则可以主动推送信息给客户端。

其优点如下：

* 客户端和服务器进行数据传输时，请求头信息比较小，大概2个字节;
* 客户端和服务器皆可以主动地发送数据给对方；
* 不需要多次创建TCP请求和销毁，节约宽带和服务器的资源。 强烈建议开发者使用WebSocket API获取**市场行情**和**买卖深度**等信息。

## grpc

### grpc介绍
[Go使用grpc+http打造高性能微服务](https://blog.csdn.net/RA681t58CJxsgCkJ31/article/details/78601747)

gRPC是由Google主导开发的RPC框架，使用HTTP/2协议并用Protobuf作为序列化工具

与REST不同的是，REST是基于HTTP1.1 JOSN格式的一种轻量级服务模式

#### JSON和Protobuf比较：

* 首先可以从JOSN与Protobuf之间的差别入手进行对比，Protobuf很难读，它是面向机器的文字格式，而JSON则是面向人的；
* Protobuf相对于JSON而言编解码速度都非常快；
* 最后就是兼容性，现在基本所有浏览器都支持JOSN格式，而Protobuf目前仅部分语言支持。

#### http1.1与http2比较

* http1.1是文本方式，因此http的请求我们都可以很清楚的读懂；
* http1.1中每一个请求会有一个新的connection，但是http2 是一个持续的http connection；
* http1是持续repetitive，http2是compressed；
* http1.1所有浏览器都默认支持，而http2只是部分支持。

HTTP/1的主要问题
[深度解析gRPC以及京东分布式服务框架跨语言实战](http://www.sohu.com/a/126977118_494947)

Head-of-line blocking，新请求的发起必须等待服务器对前一个请求的回应，无法同时发起多个请求，导致很难充分利用TCP连接。
* 头部冗余

HTTP头部包含大量重复数据，比如cookies，多个请求的cookie可能完全一样


### protocol buffer

[Potocol Buffer详解](https://www.cnblogs.com/oumyye/p/4652780.html)

Protobuf 编译器会将 .proto 文件编译生成对应的数据访问类以对 Protobuf 数据进行序列化、反序列化操作

#### 定义第一个Protocol Buffer消息
1. 创建扩展名为.proto的文件
2. 将以下内容存入该文件中。
      message LogonReqMessage {
          required int64 acctID = 1;
          required string passwd = 2;
      }

    说明:
    message是消息定义的关键字
    LogonReqMessage为消息的名字，等同于结构体名或类名。
    required前缀表示该字段为必要字段，既在序列化和反序列化之前该字段必须已经被赋值
    	(另外两个类似的关键字:optional和repeated)
    int64和string分别表示长整型和字符串型的消息字段
    	(在Protocol Buffer中存在一张类型对照表，该对照表中还将给出在不同的数据场景下，哪种类型更为高效。)
    acctID和passwd分别表示消息字段名
    标签数字1和2则表示不同的字段在序列化后的二进制数据中的布局位置。
    	(该值在同一message中不能重复，对于Protocol Buffer而言，标签值为1到15的字段在编码时可以得到优化，既标签值和类型信息仅占有一个byte，标签范围是16到2047的将占有两个bytes；在设计消息结构时，可以尽可能考虑让repeated类型的字段标签位于1到15之间，这样便可以有效的节省编码后的字节数量)

#### 定义第二个（含有枚举字段）Protocol Buffer消息。

enum UserStatus {
          OFFLINE = 0;  //表示处于离线状态的用户
          ONLINE = 1;   //表示处于在线状态的用户
      }
      message UserInfo {
          required int64 acctID = 1;
          required string name = 2;
          required UserStatus status = 3;
      }

   以上消息定义的关键性说明:
   enum是枚举类型定义的关键字
   UserStatus为枚举的名字
   枚举值之间的分隔符是分号，而不是逗号。
   OFFLINE/ONLINE为枚举值
   0和1表示枚举值所对应的实际整型值，可以为枚举值指定任意整型值，而无需总是从0开始定义

#### 定义第三个（含有嵌套消息字段）Protocol Buffer消息

可以在同一个.proto文件中定义多个message

enum UserStatus {
          OFFLINE = 0;
          ONLINE = 1;
      }
message UserInfo {
          required int64 acctID = 1;
          required string name = 2;
          required UserStatus status = 3;
      }
message LogonRespMessage {
          required LoginResult logonResult = 1;
          required UserInfo userInfo = 2;
      }

      说明：
      LogonRespMessage消息的定义中包含另外一个消息类型作为其字段，如UserInfo userInfo
      Protocol Buffer提供了另外一个关键字import，这样我们便可以将很多通用的message定义在同一个.proto文件中，而其他消息定义文件可以通过import的方式将该文件中定义的消息包含进来，如：
      import "myproject/CommonMessages.proto"

> Potocol Buffer部分概念原则

#### 限定符(required/optional/repeated)的基本规则
1. 在每个消息中必须至少留有一个required类型的字段。
2. 每个消息中可以包含0个或多个optional类型的字段。
3. repeated表示的字段可以包含0个或多个数据。需要说明的是，这一点有别于C++/Java中的数组，因为后两者中的数组必须包含至少一个元素。
4. 如果打算在原有消息协议中添加新的字段，同时还要保证老版本的程序能够正常读取或写入，那么对于新添加的字段必须是optional或repeated。

proto3中，去掉了required 和 optional

>We dropped required fields in proto3 because required fields are generally considered harmful and violating protobuf's compatibility semantics.

使用repeated时, protoc生成struct字段为指针数组，即成员都是指针
e.g. MsgList              []*HelloRequest

访问时，使用import包名加结构类型, e.g. 给结构体成员赋初值时: MsgList: []*(pt.HelloRequest){&(pt.HelloRequest{Name: "helloname"})}  (结构体变量的地址赋值给指针数组作为一个成员)

#### 类型对照表
见链接 [](https://www.cnblogs.com/oumyye/p/4652780.html)
| .proto Type | Notes | C++ Type | Java Type  |
| ----------- | ----- | -------- | ---------- |
| double      |       |double    |double      |
| float       |       |float     |float       |
| int32       | Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint32 instead.|  int32   |int|
| int64       | Uses variable-length encoding. Inefficient for encoding negative numbers – if your field is likely to have negative values, use sint64 instead.|  int64   |long|
| uint32      |  Uses variable-length encoding.|   uint32  |int|
| uint64      |  Uses variable-length encoding.|   uint64  |long|
| sint32      |  Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s.|   int32   |int|
| sint64      |  Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s.|   int64   |long|
| fixed32     | Always four bytes. More efficient than uint32 if values are often greater than 228.|    uint32  |int|
| fixed64     | Always eight bytes. More efficient than uint64 if values are often greater than 256.|   uint64  |long|
| sfixed32    |  Always four bytes.|   int32   |int|
| sfixed64    |  Always eight bytes.|  int64   |long|
| bool        || bool  |boolean|
| string      |A string must always contain UTF-8 encoded or 7-bit ASCII text.| string  |String|
| bytes       |May contain any arbitrary sequence of bytes.|  string  |ByteString|


#### Protocol Buffer消息升级原则

在实际的开发中会存在这样一种应用场景，消息格式因为某些需求的变化而不得不进行必要的升级，但又需要基于新老消息格式的新老程序同时运行，一般遵循如下规则：

1. 不要修改已经存在字段的标签号。
2. 任何新添加的字段必须是optional和repeated限定符，否则无法保证新老程序在互相传递消息时的消息兼容性。
3. 在原有的消息中，不能移除已经存在的required字段，optional和repeated类型的字段可以被移除，但是他们**之前使用的标签号必须被保留**，不能被新的字段重用。
4. int32、uint32、int64、uint64和bool等类型之间是兼容的，sint32和sint64是兼容的，string和bytes是兼容的，fixed32和sfixed32，以及fixed64和sfixed64之间是兼容的，这意味着如果想修改原有字段的类型时，为了保证兼容性，**只能将其修改为与其原有类型兼容的类型**，否则就将打破新老消息格式的兼容性。
5. optional和repeated限定符也是相互兼容的。

#### packages

我们可以在.proto文件中定义包名，如：
      package ourproject.lyphone;
      该包名在生成对应的C++文件时，将被替换为名字空间名称，既namespace ourproject { namespace lyphone。而在生成的Java代码文件中将成为包名。

#### gRPC c++

* 结构体成员问题

参考：
[对set_allocated_和mutable_的使用](https://blog.csdn.net/wujunokay/article/details/51287312)

[gRPC Basics - C++](https://grpc.io/docs/tutorials/basic/cpp/)

对于grpc中的结构体成员，通过：
`request->mutable_B类型成员名b()` 的方式访问，

查看分析grpc生成的.cpp和.h文件代码，生成的成员函数为`mutable_`、`set_allocated_`，通过这种方式访问和设置成员。

下面代码演示(另外分析函数入参被限定为const时的访问情况)：

* 程序伪代码：

```cpp

// 假设 B b; 是A的成员变量
void func(const &B)
{
}
...(const A *request) 
{
    // A类中的成员b作为入参，调用func函数，表面上需要解引用作为入参，但直接解引用会报错
    func(*request->mutable_b());
}

// grpc访问结构体成员
若request为const修饰的变量，要调用如下func函数的话，需要解引用，会出现const的this调用非const函数，编译报类似下面错误。
```

* 编译报错：

```sh
# const访问问题
错误：将‘const A’作为‘B* A::mutable_Bstructfield()’的‘this’实参时丢弃了类型限定 [-fpermissive]
```

* 使用方式：

可通过新增变量方式解引用：

```cpp
    auto a = new A;  //注意资源的释放，可以改成智能指针防止忘记
    a->CopyFrom(*request)
    func(*a->mutable_b)
```

* 定义返回为 stream时，成员中返回错误码问题
    - 

## TCP

TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。

## 集群

LB集群是load balance 集群的简写，负载均衡集群
LVS是一个实现负载均衡集群的开源软件项目
LVS架构从逻辑上可分为调度层(Director)、server集群层(Real server)和共享存储层

[gRPC服务发现&负载均衡](https://segmentfault.com/a/1190000008672912)

## windows 命令

tasklist 查看进程
tasklist|findstr "9108"

## curl

>curl -X 123.45.67.89:1080 Yahoo
-X选项用于指定代理（服务器和端口号）

>curl -d "user=nickwolfe&password=12345" http://www.yahoo.com/login.cgi
-d选项用于指定发送请求时POST命令的数据

```sh
curl -X POST http://127.0.0.1:8000/person -d "first_name=hello&last_name=world" | python -m json.tool
```

python -m, -m将库中的python模块用作脚本去运行

将模块当做脚本去启动有什么用？
python xxx.py
python -m xxx.py
这是两种加载py文件的方式:
1叫做直接运行
2相当于import,叫做当做模块来启动

## git

### 删除Git中缓存的用户名和密码

运行一下命令缓存输入的用户名和密码：
git config --global credential.helper wincred
清除掉缓存在git中的用户名和密码
git credential-manager uninstall

### 恢复某个已修改的文件（撤销未提交的修改）
git checkout .(全部，或者指定文件来恢复部分)  //本地删除的记录恢复

### 基本命令

Git book：  
[Git 基础 ](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)

* git pull
    - 拉取远程分支更新到本地仓库
    - `git pull <远程主机名> <远程分支名>:<本地分支名>`，一般我们简写成 `git pull`
    - git pull = git fetch + git merge
    - git fetch不会进行合并，执行后需要手动执行git merge合并，而git pull拉取远程分之后直接与本地分支进行合并。
    - 强制覆盖本地：git pull --force
* git fetch
    - 更新远程代码到本地仓库
    - FETCH_HEAD指的是: 某个branch在服务器上的最新状态
        + 这个列表保存在 .Git/FETCH_HEAD 文件中, 其中每一行对应于远程服务器的一个分支。
        + 如果没有显式的指定远程分支, 则远程分支的master将作为默认的FETCH_HEAD
        + 如果指定了远程分支, 就将这个远程分支作为FETCH_HEAD
    - git fetch更新本地仓库的两种用法
        + 方法一
            * `git fetch origin master` #从远程的origin仓库的master分支下载代码到本地的origin master
            * `git log -p master.. origin/master` #比较本地的仓库和远程参考的区别
            * `git merge origin/master` #把远程下载下来的代码合并到本地仓库，远程的和本地的合并
        + 方法二
            * `git fetch origin master:temp` #从远程的origin仓库的master分支下载到本地并新建一个分支temp
            * `git diff temp`  #比较master分支和temp分支的不同
            * `git merge temp` #合并temp分支到master分支
            * `git branch -d temp` #删除temp
* git reset
    - git reset会将撤销点之后的操作都回退到暂存区中
    - git reset是直接删除指定的commit
* git revert
    - git revert 仅仅是撤销某次提交
    - git revert是用一次新的commit来回滚之前的commit

* 撤消操作
    - [2.4 Git 基础 - 撤消操作](https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%92%A4%E6%B6%88%E6%93%8D%E4%BD%9C)


## spdlog

使用，两种方式：
1. 只有头文件的方式(代码中不需要加spdlog.cpp)
  拷贝include/spdlog 到代码路径，编译时，添加-std=c++11
  这种方式不需要-DSPDLOG_COMPILED_LIB
2. 使用静态库方式(推荐,把spdlog.cpp编进代码，编译更快)
  拷贝src/spdlog.cpp到代码路径，将cpp一起编译，需要加宏-DSPDLOG_COMPILED_LIB和-std=c++11

日志等级： (从上到下越来越严重，默认日志等级及其更高等级会进行打印，默认info)
  trace
  debug
  info
  warn
  error
  critical

### 基本用法及说明

[spdlog学习笔记](https://blog.csdn.net/haojie_superstar/article/details/89383433)

#### logger
  日志记录器，通过传入一个或者多个sink给它进行记录一个或多个位置
  可以通过spdlog自身的函数方法创建logger，也可以手动创建(先创建一个或者多个sink，再将sink传给spdlog::logger的构造函数进行创建)
    自身方法使用工厂模式创建实例，e.g. spdlog::daily_logger_mt
    sink的命名空间层次为 sdplog::sinks::具体sink类型，e.g. spdlog::sinks:stdout_sink_mt

#### sink

  sink是实际将日志写入目标位置的对象。
  每一个sink仅应负责写一个目标文件（比如 file，console，db）
  并且每一个sink有专属的私有格式化器formatter实例。 (可以手动创建sink，传递给logger，实现多个sink写入)

可用sink：

rotating_file_sink 达到最大文件大小时，关闭文件，重命名文件并创建新文件。
    `spdlog::rotating_logger_mt使用该sink`
daily_file_sink  每天在一个特别的时间创建一个新的日志文件，并在文件名字上添加一个时间戳
    `spdlog::daily_logger_mt`
simple_file_sink 无任何限制的向一个日志文件中写入
    `spdlog::basic_logger_mt`
stdout_sink/stderr_sink with colors
    `spdlog::stdout_color_mt`
    `spdlog::color_logger_mt`
syslog_sink POSIX syslog(3) 发送日志到syslog
    `spdlog::syslog_logger`
dist_sink 将日志消息分发到其他接收器列表 **使用这个sink实现多个sink记日志**
    没有工厂模式返回logger，需要手动添加

```cpp
    auto distsink = std::make_shared<spdlog::sinks::dist_sink_mt>();
    distsink->add_sink(std::make_shared<spdlog::sinks::stdout_sink_mt>());
    distsink->add_sink(std::make_shared<spdlog::sinks::rotating_file_sink_mt>(filepath, 1024*1024*1, 3));
    auto mydistlogger = std::make_shared<spdlog::logger>("mydistlogger", distsink);
    spdlog::register_logger(mydistlogger);
```

**注意**：用户应该负责去创建任何他们需要的文件夹。spdlog除了文件**不会尝试创建任何文件夹**

spdlog::info
spdlog::error

#### 线程安全说明

* spdlog:: 命名空间下的是线程安全的

* 对于sinks，以 _mt 后缀结尾的是线程安全的，比如：daily_file_sink_mt
             以_st 后缀结尾的是非线程安全的，比如：daily_file_sink_st

  单线程的sink不可以在多线程中使用，它的速度会更快，因为没有锁竞争

1.  不同线程处理时以下函数不应该操作：
当loggers在不同的线程同时执行时，下述函数不应该被调用
  spdlog::set_error_handler(log_err_handler) // or logger->set_error_handler(log_err_handler);
logger在其它线程执行过程中，添加或移除sink是线程不安全的
  logger->sinks().push_back(new_sink);       // Don't do this if other thread is already using this logger

2. 要创建线程安全的loggers，使用带 _mt 后缀的工厂函数
  auto logger = spdlog::basic_logger_mt(...);

3. 要创建单线程的loggers，使用带 _st 后缀的工厂函数
  auto logger = spdlog::basic_logger_st(...);

#### 使用
spdlog支持使用最小集的方式，意味着你只用包含你实际需要的头文件，而不是全部，比如说你只需要使用 rotating logger，那么你只需要
`#include <spdlog/sinks/rotating_file_sink.h>`

对于异步特性，你还需要
`#include <spdlog/asynch.h>`

* 几种使用模式：
  返回智能指针 std::shared_ptr<logger>
    每一个logger中包含一个存有一个或多个 std::shared_ptr<spdlog::sink>的 vector
    logger在记录每一条日志时（如果是有效的级别），将会调用每一个std::shared_ptr<spdlog::sink>中的sink(log_msg)函数

```cpp
* stdout打印
    auto console = spdlog::stdout_logger_mt("console");

* 基本文件记录，只有一个，不循环使用不限制大小
    #include "spdlog/sinks/basic_file_sink.h"
    // Create basic file logger (not rotated) // support for basic file logging
    auto my_logger = spdlog::basic_logger_mt("basic_logger", "logs/basic.txt");

* rotate句柄，限制大小和备份数量
    #include "spdlog/sinks/rotating_file_sink.h" // support for rotating file logging
    // file rotating logger with 5mb size max and 3 rotated files，5MB大小，3个循环备份文件(即共4个日志文件) rotate循环，旋转
    auto file_logger = spdlog::rotating_logger_mt("file_logger", "myfilename", 1024 * 1024 * 5, 3);

* 异步logger 使用工厂函数创建异步logger(循环记日志时，每次异步logger不阻塞)
    #include "spdlog/sinks/daily_file_sink.h"
    #include <spdlog/asynch.h>  //异步logger加头文件
    auto async_file = spdlog::basic_logger_mt<spdlog::async_factory>("async_file_logger", "logs/async_log.txt");
  可以通过创建异步logger前调用以下函数来修改线程池个数和待写日志队列长度
    inline void init_thread_pool(size_t q_size, size_t thread_count)

* 创建一个由多个loggers共享同一个输出文件的sink

* auto console = spdlog::stdout_color_mt("xdconsole");
    #include "spdlog/sinks/stdout_color_sinks.h"

  使用spdlog::get("...")访问loggers
    (spdlog::get("xdconsole"))->info("test spdlog::get function")
  spdlog::get可能会拖慢你的程序，因为它内部维护了一把锁，所以要谨慎使用。
    一个很好的方法是建立一个std::shared_ptr<spdlog::logger>私有成员变量，并在构造函数中初始化
```

* 手动创建loggers

参考(上面的sink章节，dist_sink可创建写多个sink的logger)

```cpp
  auto sink = std::make_shared<spdlog::sinks::stdout_sink_mt>();
  auto my_logger= std::make_shared<spdlog::logger>("mylogger", sink);
  my_logger->info("etstesfdljk");
```

* 设置函数

```cpp
  //设置一个logger, 后续使用spdlog::info时，会使用该logger记录
  spdlog::set_default_logger(file_logger);

  //设置模式字符串
  set_pattern(pattern_string);
    //格式应用到所有被注册的logger
    spdlog::set_pattern("*** [%H:%M:%S %z] [thread %t] %v ***");
    //格式应用到具体的logger
    some_logger->set_pattern(">>>>>>>>> %H:%M:%S %z %v <<<<<<<<<");
    //格式应用到具体的logger某个特定sink
    some_logger->sinks()[1]->set_pattern("..");
```

  [spdlog学习笔记_模式标记](https://blog.csdn.net/haojie_superstar/article/details/89383433)
    %H %M %S %z, 时(0-23) 分 秒 时区(“+02:00”)
    %I 时(1-12), %e 毫秒; %f 微秒

    %Y 年(“2014”), %m 月; %d 日(1-31)
    %C 年(“14”); %B 月份全名(August); %A 星期全名(Thursday)


用SPDLOG_INFO/SPDLOG_TRACE 等宏定义记录才有：不能指定logger
    %@ 文件名:行号(my_file.cpp:123)
    %s 文件名
    %# 行号
    %! 函数名

    %P 进程id; %t 线程id

    %+ spdlog的默认格式 “[2014-10-31 23:46:59.678] [mylogger] [info] Some message”
    %v 用户要记的信息

      即 [%Y-%m-%d %H:%M:%S.%e] [%n] [%l] %v

    %^ “[mylogger] [info(green)] Some message”
    %L 日志等级缩写(“D”, “I”, etc)
    %l 日志等级(“debug”, “info”)
    %n logger名

    %% %号

  对齐
    右对齐
      %8l  ("    info")
    -左对齐
      %-8l ("info    ")
    =中间对齐
      %=8l ("  info  ")

[%Y-%m-%d %H:%M:%S.%e] %^

## 编译

### pkg-config 编译时找库 和 ldconfig 运行时找库
编译grpc, third_party少包, git checkout .
  `git submodule update --init`
编译项目pkg-config找不到库
  export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH
运行项目找不到动态库，系统中添加路径，或LD_LIBRARY_PATH
  vi /etc/ld.so.conf，添加一行 /usr/local/lib，然后执行ldconfig

编译时提示未定义的引用，如果-l链接了，且路径已经配置或者-L已经指定，还有可能是:
-l链接库在引用库的函数文件之前，这样就会链接不到库，所以要保证链接库的顺序在引用它之前

#### pkg-config
[pkg-config 详解](https://blog.csdn.net/newchenxf/article/details/51750239)

pkg-config是一个linux下的命令，用于获得某一个库/模块的所有编译相关的信息。

```sh
pkg-config --cflags --libs libmongocxx 执行结果为：

-I/usr/local/include/mongocxx/v_noabi -I/usr/local/include/bsoncxx/v_noabi  -L/usr/local/lib -lmongocxx -lbsoncxx
```

> 如果你写了一个库，不管是静态的还是动态的，要提供给第三方使用，那除了给人家库/头文件，最好也写一个pc文件，这样别人使用就方便很多，不用自己再手动写依赖了你哪些库，只需要敲一个”pkg-config [YOUR_LIB] --libs --cflags”。

pkg-config信息两个来源
  第一种：取系统的/usr/lib下的所有*.pc文件。
  第二种：PKG_CONFIG_PATH环境变量所指向的路径下的所有*.pc文件。

## makefile

**注意！ `PRJ_DIR="${shell cd ..;pwd}"       #注释说明`, 这样注释处理会将空格也赋值给PRJ_DIR**

[Makefile编译目录下多个文件以及函数wildcard用法](https://blog.csdn.net/hunanchenxingyu/article/details/12205305)
[makefile 中字符串处理和文件处理函数](https://blog.csdn.net/qhexin/article/details/16951097)

```sh
1. wildcard
  找出目录和指定目录下所有的后缀为c和cpp的文件
  $(wildcard *.c, *.cpp, /***/***/*.c)
    C_SRC = $(wildcard *.c)
    同C_SRC=$(shell echo *.c)

2. foreach
  组合foreach查找多个路径
    SRC_FILES += $(foreach dir,$(SRC_DIR),$(wildcard $(dir)/*.cpp))

3. patsubst 模式字符串替换函数
  $(patsubst <pattern>,<replacement>,<text>)
    <pattern>可以包括通配符“%”，表示任意长度的字串
    如果<replacement>中也包含“%”，那么，<replacement>中的这个“%”将是<pattern>中的那个“%
    以“\%”来表示真实含义的"%"
  e.g.
      将所有的cpp文件的后缀替换为o文件
      CPP_OBJ = $(patsubst %cpp, %o, $(CPP_SRC))
        同CPP_OBJ=$(CPP_SRC:%.cpp=%.o)

4. notdir
  dir=$(notdir $(src)) 把带路径的文件去掉路径，只留文件名

5. subst 字符串替换函数
  $(subst <from>,<to>,<text>)
  e.g.
    $(subst ee,EE,feet on the street)， 将"feet on the street"中的"ee"替换为"EE"，若要替换为空则,,

  其他字符串处理：
    去空格函数——strip
    e.g.
      $(strip a b c ) 把字串“a b c ”去到开头和结尾的空格，结果是“a b c”。

    过滤函数——filter
      sources := foo.c bar.c baz.s ugh.h
      $(filter %.c %.s,$(sources))返回的值是“foo.c bar.c baz.s”。
    反过滤函数——filter-out
      objects=main1.o foo.o main2.o bar.o
      mains=main1.o main2.o
      $(filter-out $(mains),$(objects)) 返回值是“foo.o bar.o”
    排序函数——sort
      $(sort foo bar lose)返回“bar foo lose”
    取单词函数——word
      取第n个，从1开始数
      $(word 2, foo bar baz)返回值是“bar”
    取单词串函数——wordlist
      第几到第几个
      $(wordlist 2, 3, foo bar baz)返回值是“bar baz”
    单词个数统计函数——words
      $(words, foo bar baz)返回值是“3”
    首单词函数——firstword
      $(firstword foo bar)返回值是“foo”
  文件名操作函数：
    取目录函数——dir
      目录部分是指最后一个反斜杠（“/”）之前的部分。如果没有反斜杠，那么返回“./”
      $(dir src/foo.c hacks)返回值是“src/ ./”
    取文件函数——notdir
      非目录部分是指最后一个反斜杠（“/”）之后的部分
      $(notdir src/foo.c hacks)返回值是“foo.c hacks”
    取后缀函数——suffix
      如果文件没有后缀，则返回空字串
      $(suffix src/foo.c src-1.0/bar.c hacks)返回值是“.c .c
    取前缀函数——basename
      如果文件没有前缀，则返回空字串
      $(basename src/foo.c src-1.0/bar.c hacks)返回值是“src/foo src-1.0/bar hacks”
    加后缀函数——addsuffix
      $(addsuffix .c,foo bar)返回值是“foo.c bar.c”
    加前缀函数——addprefix
      $(addprefix src/,foo bar)返回值是“src/foo src/bar”
    连接函数——join
      $(join <list1>,<list2>)
      如果<list1>的单词个数要比<list2>的多，那么，<list1>中的多出来的单词将保持原样。如果<list2>的单词个数要比<list1>多，那么，<list2>多出来的单词将被复制到list1中末尾
      $(join aaa bbb , 111 222 333)返回值是“aaa111 bbb222 333”
```

通配符$@、$^、$<

这三个分别表示：
$@          --代表目标文件(target)
$^            --代表所有的依赖文件(components)
$<           --代表第一个依赖文件(components中最左边的那个)。

```sh
main.out:main.o line1.o line2.o
  g++ -o $@ $^
main.o:main.c line1.h line2.h
  g++ -c $<
line1.o:line1.c line1.h
  g++ -c $<
line2.o:line2.c line2.h
  g++ -c $<
```

### ifeq语法

```
ifeq ($(CC),gcc)
    $(CC) -o foo $(objects) $(libs_for_gcc)
else
    $(CC) -o foo $(objects) $(normal_libs)
endif
```

## CMake

[在 linux 下使用 CMake 构建应用程序](https://www.ibm.com/developerworks/cn/linux/l-cn-cmake/)

1. 编写CMakeLists.txt
2. 执行cmake path生成Makefile(path时CMakeLists.txt所在目录)
3. 使用make进行编译

### CMakeLists.txt 的语法

由命令、注释和空格组成

其中命令是不区分大小写的,符号"#"后面的内容被认为是注释。

命令由命令名称、小括号和参数组成,参数之间使用空格进行间隔。 (注意VERSION大写)

```c
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
4 ADD_EXECUTABLE(main ${DIR_SRCS})
```
`aux_source_directory(<dir> <variable>)`
  命令会把参数 <dir> 中所有的源文件名称赋值给参数 <variable>

完成了文件 CMakeLists.txt 的编写后需要使用 cmake 或 ccmake 命令生成Makefile 。 ccmake 与命令 cmake 的不同之处在于 ccmake 提供了一个图形化的操作界面。

加子目录src，链接库Test，并将子目录编译成库(静态库.a)

```
1 PROJECT(main)
2 CMAKE_MINIMUM_REQUIRED(VERSION 2.6)
3 ADD_SUBDIRECTORY( src )
4 AUX_SOURCE_DIRECTORY(. DIR_SRCS)
5 ADD_EXECUTABLE(main ${DIR_SRCS}  )
6 TARGET_LINK_LIBRARIES( main Test )
```

子目录src中的CMakeLists.txt

```
1 AUX_SOURCE_DIRECTORY(. DIR_TEST1_SRCS)
2 ADD_LIBRARY ( Test ${DIR_TEST1_SRCS})
```

## linux

### history日志显示日期

.bashrc中设置环境变量:
export HISTTIMEFORMAT="%F %T `whoami` "

### 重定向标准错误

`mv a.log back/ 2>tmp.log  (或者2>>tmp.log)`

将执行的错误信息输出重定向到日志tmp.log中，**注意，2>之间不能有空格**

这种情况下，错误信息只会打印到tmp.log中，若要打印到文件的同时，终端上也能打印(标准输出1)，则可使用tee：

```sh
mv a.log back/ 2>&1 | tee -a tmp.log
```

### tee

[tee命令](https://www.cnblogs.com/leezhxing/p/4092532.html)

tee命令读取**标准输入**，把这些内容同时**输出到标准输出**和**（多个）文件**中，tee命令可以重定向标准输出到多个文件。

在使用管道线时，前一个命令的**标准错误**输出不会被tee读取。

```sh
tee
    只输出到标准输出
tee file
    输出到标准输出的同时，保存到文件file中
    如果文件不存在，则创建；如果已经存在，则覆盖之。
tee -a file
    输出到标准输出的同时，追加到文件file中。
    如果已经存在，就在末尾追加内容，而不是覆盖。
tee -
    输出到标准输出两次
tee file1 file2
    同时保存到file1和file2中

ls "*" 2>&1 | tee -a ls.txt
    使用tee命令把标准错误输出也保存到文件
```

### history记录时间
export HISTTIMEFORMAT="%F %T `whoami` "

### vim
替换指定行之间  :10,15s/abc/hhh/g

把204到233间的" = "替换为"("
`:204,233s/ = /(/g`

204到233间 ");"替换为"));"
`:204,233s/\)\;/));/g`

查找以\结尾：
/\\$  (\\为'\'转义)

### find

查找目录 时跳过指定目录，使用prune(英 /pruːn/   删除；减少)
  (注意顺序，-path接源路径，后面跟-prune，再跟-o，后面再跟其他过滤选项，-print不能少)：
  `find . -path './util' -prune -o -type d -print`

过滤多个目录：
  `find . \( -path './util' -o -path './tradebot \) -prune -o -type d -print`

  -o 类似于 or,  或者;
  -a 类似于 and, 且

  (1) grep指定h文件类型查找hello字符串：
find . -type f -name '*.h' | xargs grep "hello"

查看端口 lsof -i:5000

* 排除目录下所有以md结尾的文件：
`find . -type f ! -name "*.md"`

* 排除多个：
`find . -type f ! -name "*.md" ! -name "*.o"`

* 正则表达式：
`find . -regex '.*\.md\|.*\.h\|.*\.cpp'`

### 统计文本行数

语法：wc [选项] 文件…

说明：该命令统计给定文件中的字节数、字数、行数。如果没有给出文件名，则从标准输入读取。

    该命令各选项含义如下：

    　　- c 统计字节数
    　　- l 统计行数
    　　- w 统计字数

* `wc -lcw Makefile`

* 统计src目录下所有cpp文件代码行数(子目录也会统计)

`find src/ -name "*.cpp" |xargs cat|wc -l`

* 统计当前目录及子目录下文件行数
`find . -type f |xargs cat|wc -l`

* 统计当前目录及子目录下.h和.cpp文件行数
`find . -type f -name "*.h" -o -name "*.cpp" |xargs cat|wc -l`
`find . -type f -name "*.h" |xargs cat|wc -l`

* 统计src目录下所有cpp文件代码行数(过滤空行)

`find src/ -name "*.cpp" |xargs cat | grep -v ^$ | wc -l`

### unzip

unzip zip文件

### 目录排序

du -s -d1|sort -n      (h会影响排序，仅按数字来排的)

### grep 查找后去重

grep "#include <boost" -rn *|awk -F' ' '{print $2}'|sort|uniq  (注意要sort，要不仅去重相邻的)

### echo 不换行

* echo -e 允许对下面列出的加反斜线转义的字符进行解释

```sh
  \n    换行符
  \c    禁止尾随的换行符
  \t    水平制表符
  等等

  echo -e "hello\n"  在原来基础上多加一个换行
  echo -e "hello\c"  不换行
```

* `echo -n "hello"` 也可指定不换行(-n 不输出行尾的换行符)

### 正则表达式

非：  volume:[^0] 匹配"volume:"后接非0的行

### chkconfig

chkconfig命令主要用来更新（启动或停止）和查询系统服务的运行级信息。
谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。

```sh
查看开机自启动的服务
chkconfig --list

只查看MySQL服务
chkconfig --list mysqld

配置MySQL的开机自动启动
chkconfig --add mysql
chkconfig mysqld on

命令启动/关闭MySQL实例
service mysqld start/stop
/etc/init.d/mysqld start/stop
```

### systemctl

1. 查看系统当前默认启动项目的方法，不再是setup之类的了。
`systemctl list-unit-files`

2. 取消mysqld的自启动
`systemctl disable mysqld`

查看状态，先status
`systemctl status mysqld.service`

### cpu信息

cpu信息在 /proc/cpuinfo中，根据grep过滤关键字，并配合uniq/sort/wc来过滤重复/排序/计数，统计各信息

* 查看物理CPU的个数(实际物理cpu的个数)

`cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l`

* 查看CPU是几核心(物理核数，每个cpu的物理核数，若有多个物理cpu，核心数都一样就一条记录)

`cat /proc/cpuinfo |grep "cores"|uniq`

* 查看逻辑CPU的个数(若该cpu支持超线程，则1个物理核对应2个逻辑核/线程。 若支持超线程则与物理核是两倍的关系)

`cat /proc/cpuinfo |grep "processor"|wc -l`

超线程计数可以理解为：一颗CPU当成两颗来用，将一颗具有超线程功能的物理CPU变成两颗逻辑CPU，而逻辑CPU对操作系统来说，跟物理CPU并没有什么区别。

超线程介绍：[图说超线程技术(Hyper-Threading Technology)](https://www.cnblogs.com/idorax/p/6884088.html)

获取开发环境配置：

```sh
echo -n "cpu个数: "
cat /proc/cpuinfo |grep "physical id"|sort |uniq|wc -l
echo -n "cpu核数: "
cat /proc/cpuinfo |grep "cores"|uniq
echo -n "逻辑核数: "
cat /proc/cpuinfo |grep "processor"|wc -l

echo -n "操作系统: "
cat /etc/redhat-release
echo -n "gcc版本: "
gcc -v
```

### yum

* yum
    - yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。
    - 基于RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。
    - 命令形式一般如下：`yum [options] [command] [package ...]`
        + [options]是可选的，选项包括-h（帮助），-y（当安装过程提示选择全部为"yes"），-q（不显示安装的过程）等等。
        + [command]为所要进行的操作，[package ...]是操作的对象。
    - 安装
        + `yum install package1` 安装指定的安装包package1
        + `yum groupinsall group1` 安装程序组group1
    - 更新和升级
        + `yum update package1` 更新指定程序包package1
        + `yum check-update` 检查可更新的程序
        + `yum upgrade package1` 升级指定程序包package1
    - 查找和显示
        + `yum info package1` 显示安装包信息package1
            * e.g. `yum info sysstat`，结果里会展示：名称、架构、版本、大小、源、简介、协议、描述、已安装、可安装 等信息
        + `yum list` 显示所有已经安装和可以安装的程序包
        + `yum list package1` 显示指定程序包安装情况package1(会展示指定的已安装和可安装的包)
    - 删除程序
        + `yum remove package1` 或 `yum erase package1` 删除程序包package1
    - 清除缓存
        + `yum clean packages` 清除缓存目录下的软件包
    - [linux yum命令详解](cnblogs.com/chuncn/archive/2010/10/17/1853915.html)

## watch

`watch -n1 -d` -d高亮改变的位置

## valgrind

valgrind ./simulate_server --leak-check=full --show-leak-kinds=definite

## mysql
安装Mysql 8.0
[CentOS 7 安装 Mysql 8.0 教程](https://blog.csdn.net/danykk/article/details/80137223)
1）配置Mysql 8.0安装源
sudo rpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-1.noarch.rpm
2）安装Mysql 8.0
sudo yum --enablerepo=mysql80-community install mysql-community-server

## centos7 mongodb c++驱动安装

翻译：
[mongodb c++ 驱动](https://www.jianshu.com/p/c982a2960175)
  1. 安装c驱动
  2. 下载最新的 mongocxx driver
     git clone https://github.com/mongodb/mongo-cxx-driver.git --branch releases/stable --depth 1
     cd mongo-cxx-driver/build
  3. 配置驱动
     cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=/usr/local ..
  4. 编译和安装驱动
     若用默认的 MNMLSTC 的C++17 `make EP_mnmlstc_core` (实际安装未执行该步，不确定是否有影响，make正常安装成功)
     make && make install

[mongodb c 驱动](https://www.jianshu.com/p/d77680254418) (第一步安装c驱动，翻译链接)

```sh
  $ wget https://github.com/mongodb/mongo-c-driver/releases/download/1.13.0/mongo-c-driver-1.13.0.tar.gz
  $ tar xzf mongo-c-driver-1.13.0.tar.gz
  $ cd mongo-c-driver-1.13.0
  $ mkdir cmake-build
  $ cd cmake-build
  $ cmake -DENABLE_AUTOMATIC_INIT_AND_CLEANUP=OFF ..

  $ make
  $ make install
```

官网：
[Installing the mongocxx driver](http://mongocxx.org/mongocxx-v3/installation/)

**注意下载安装包最好到官网,博客中下载链接可能是很老的包**

## mongodb安装
[Linux平台安装MongoDB](https://www.runoob.com/mongodb/mongodb-linux-install.html)
curl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-4.0.12.tgz   # 下载 (对应版本修改下)
tar -zxvf mongodb-linux-x86_64-3.0.6.tgz                                   # 解压
mv  mongodb-linux-x86_64-3.0.6/ /usr/local/mongodb                         # 将解压包拷贝到指定目录

MongoDB 的可执行文件位于 bin 目录下，所以可以将其添加到 PATH 路径中：

export PATH=<mongodb-install-directory>/bin:$PATH
<mongodb-install-directory> 为你 MongoDB 的安装路径。如本文的 /usr/local/mongodb 。

  创建数据库目录
MongoDB的数据存储在data目录的db目录下，但是这个目录在安装过程不会自动创建，所以你需要手动创建data目录，并在data目录中创建db目录。
`mkdir -p /data/db`

  命令行中运行 MongoDB 服务
`$ ./mongod`

MongoDB后台管理 Shell
如果你需要进入MongoDB后台管理，你需要先打开mongodb装目录的下的bin目录，然后执行mongo命令文件。

MongoDB Shell是MongoDB自带的交互式Javascript shell,用来对MongoDB进行操作和管理的交互式环境。

当你进入mongoDB后台后，它默认会链接到 test 文档（数据库）：

```sh
$ cd /usr/local/mongodb/bin
$ ./mongo
MongoDB shell version: 3.0.6
connecting to: test
Welcome to the MongoDB shell.
……
```

## 灰度发布

参考百度百科：
[灰度发布](https://baike.baidu.com/item/%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83)

* 灰度发布（又名金丝雀发布）是指在黑与白之间，能够平滑过渡的一种发布方式。
    - 在其上可以进行A/B testing，即让一部分用户继续用产品特性A，一部分用户开始用产品特性B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来。
    - 灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度。

* 灰度期：灰度发布开始到结束期间的这一段时间，称为灰度期。

* 作用： 及早获得用户的意见反馈，完善产品功能，提升产品质量 让用户参与产品测试，加强与用户互动 降低产品升级所影响的用户范围

本质上灰度测试可以算作A/B测试的一种特例

> 灰度发布与互联网公司常用A/B测试似乎比较类似，国外互联网公司似乎并没有所谓的灰度发布的概念。
> 按照wikipedia中对A/B测试的定义，A/B测试又叫：A/B/N Testing、Multivariate Testing，因此本质上灰度测试可以算作A/B测试的一种特例。

* 步骤：
    - 1）定义目标
    - 2）选定策略：包括用户规模、发布频率、功能覆盖度、回滚策略、运营策略、新旧系统部署策略等
    - 3）筛选用户：包括用户特征、用户数量、用户常用功能、用户范围等
    - 4）部署系统：部署新系统、部署用户行为分析系统（web analytics）、设定分流规则、运营数据分析、分流规则微调
    - 5）发布总结：用户行为分析报告、用户问卷调查、社会化媒体意见收集、形成产品功能改进列表
    - 6）产品完善
    - 7）新一轮灰度发布或完整发布

## QT

[Qt Downloads](http://download.qt.io/archive/qt/) 环境搭建(官网的下载链接点击进去找不到界面)

## UML类图

[UML类图与类的关系详解](http://uml.org.cn/oobject/201104212.asp)

[UML——在Visual Studio 2013/2015中设计UML类图](https://www.cnblogs.com/SceneryHao/p/5355915.html)

Unified Modeling Language (UML)又称统一建模语言或标准建模语言。

简单说就是以图形方式表现模型，根据不同模型进行分类

常用 UML 动态图（5 个）：用例图，活动图，状态机图，序列图，通信图。
常用 UML 静态图（4 个）：类图，包图，部署图，构件图。

在所有UML图中，类图是使用频率最高的UML图。
类图用于描述系统中所包含的类以及它们之间的相互关系，帮助人们简化对系统的理解，它是系统分析和设计阶段的重要产物，也是系统编码和测试的重要模型依据。

类图主要关系有：泛化（Generalization）,  实现（Realization），关联（Association)，聚合（Aggregation），组合(Composition)，依赖(Dependency)

* 泛化（Generalization)
    - 【泛化关系】：是一种继承关系，表示一般与特殊的关系，它指定了子类如何特化父类的所有特征和行为。
    - 【代码体现】：类继承另一个类
    - 【箭头指向】：带三角箭头的实线，箭头指向父类


## gdb

* 断点
    - 添加
        + `break` / `b`, 四种形式
            * break line-number                    在执行给定行之前
            * break function-name                  在进入指定的函数之前
            * break line-or-function if condition  如果condition（条件）是真，程序到达指定行或函数时停止
            * break routine-name                   在指定例程的入口处设置断点
        + 可以在各个原文件中设置断点
            * break filename:line-number
            * break filename:function-name
        + 回车会在上一个位置再次设置一个端点
    - 查看
        + `info break`
    - 删除
        + `delete`
            * delete 5 (指定编号)
            * delete 1-10(连续的断点号)
        + `clear`
            * clear list.c:12           //删除文件：行号的所有断点
            * clear 12                  //删除行号的所有断点
            * clear list.c:list_delet   //删除文件：函数的所有断点
            * clear 删除断点是基于行的，不是把所有的断点都删除
    - 临时断点
        + 在使用gdb调试时，如果想让断点只生效一次，可以使用`tbreak`命令（缩写为`tb`），和设置断点的过程一样
            * 临时断点13显示:*del*, 普通断点:*keep*
    - 条件断点
        + `break 行号 if 条件`，意思是只有在条件满足的时候，断点才会被触发
        + `b 222 if i==100` (i为100时触发断点)
    - 忽略断点
        + 在设置了断点之后，可以使用命令`ignore 断点编号i cnt`来忽略断点，意思是接下来的cnt次编号为i的断点触发都不会让程序暂停，只有第cnt+1次断点触发才会让程序暂停

```sh
# 临时断点
Num     Type           Disp Enb Address            What
13      breakpoint     del  y   0x0000000000415383 in Thread_func(void*) at src/func.cpp:224
14      breakpoint     keep y   0x0000000000415353 in Thread_func(void*) at src/func.cpp:222
```

### 问题

收到：signal SIGABRT，程序退出

```golang
//gdb程序报错退出
// (发现问题是root用户编译，用普通用户执行的，push_back()时就报这个退出了，奇葩问题奇葩操作...):
Program received signal SIGABRT, Aborted.

terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc

Program received signal SIGABRT, Aborted.
[Switching to Thread 0x7ffff070f700 (LWP 12784)]
0x00007ffff5573207 in raise () from /lib64/libc.so.6

//bt查看:
(gdb) bt
#0  0x00007ffff5573207 in raise () from /lib64/libc.so.6
#1  0x00007ffff55748f8 in abort () from /lib64/libc.so.6
#2  0x00007ffff609d445 in __gnu_cxx::__verbose_terminate_handler () at ../../../../libstdc++-v3/libsupc++/vterminate.cc:95
#3  0x00007ffff609b5d6 in __cxxabiv1::__terminate (handler=<optimized out>)
    at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:38
#4  0x00007ffff609b603 in std::terminate () at ../../../../libstdc++-v3/libsupc++/eh_terminate.cc:48
#5  0x00007ffff609b823 in __cxxabiv1::__cxa_throw (obj=0x7fffe0013ce0, tinfo=0x7ffff6322b00 <typeinfo for std::bad_alloc>,
    dest=0x7ffff6099cd0 <std::bad_alloc::~bad_alloc()>) at ../../../../libstdc++-v3/libsupc++/eh_throw.cc:87
#6  0x00007ffff609bd1d in operator new (sz=18446744073709551600) at ../../../../libstdc++-v3/libsupc++/new_op.cc:56
#7  0x00000000004259e8 in __gnu_cxx::new_allocator<TestResult>::allocate (this=0x7ffff070eb20, __n=256204778801521550)
    at /usr/local/include/c++/4.8.5/ext/new_allocator.h:104
#8  0x0000000000421ec5 in std::_Vector_base<TestResult, std::allocator<TestResult> >::_M_allocate (
    this=0x7ffff070eb20, __n=256204778801521550) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:168
#9  0x0000000000525324 in std::vector<TestResult, std::allocator<TestResult> >::_M_emplace_back_aux<TestResult const&> (this=0x7ffff070eb20) at /usr/local/include/c++/4.8.5/bits/vector.tcc:404
#10 0x00000000005212d5 in std::vector<TestResult, std::allocator<TestResult> >::push_back (
    this=0x7ffff070eb20, __x=...) at /usr/local/include/c++/4.8.5/bits/stl_vector.h:911
```


## 线程

* pthread_create 创建分离线程后，传入的参数应该立即(*应该usleep一定的时间*,e.g. 1ms), 在线程中新建存储区进行存储，不应该一直使用外部的地址。

## perf

* centos安装 `yum install perf`
* 需要以root用户运行
* `perf top -p 进程号`， 查看cpu使用率高问题

* `while(1) {dosomething();}`，或者直接`while(1) {}` cpu使用率100%问题
    - Unix系统使用cpu通过时间片轮转(而Windows则属于抢占式的，进程主动放弃使用CPU)，while(1){}会持续占用cpu，导致cpu使用率很高
    - 在while体中添加usleep(1000)，即sleep 1ms，cpu使用率大大降低
    - 在while体中，若当次不执行任何操作，建议添加一个短的等待时间(**包含不满足继续条件直接continue,不执行任何其他语句的情况**)
    - 中断
        + 内核统计程序占的CPU是通过时钟中断完成的，当时钟中断发生时候，通过IP记数器(程序计数器PC)找到发生前正在运行的程序。
        + 程序不做事情时，进入内核中的 idle() 程序，等待中断唤醒。而该程序使CPU处于休息状态，将CPU的系统时钟频率调整到很低，此时会比较省电，风扇不转，然后在这个状态下循环等待

>理想情况下，假设原本执行一次循环只需要消耗10个CPU周期的话，如果不进行阻塞，2Ghz的CPU在一秒内会执行2*10^9/10=2*10^8次的循环，然而在1秒内执行那么多次循环对我们的程序一点帮助都没有，还会抢占CPU资源；而阻塞该程序1ms后，相当于每进行一次循环后就让出1ms的运算资源，也就是让出2*10^6个cpu周期，原本占用100%的程序只会占用不到1万次CPU周期，这对于2Ghz的CPU来说几乎是0负担的。 [CPU占用率100%](https://cloud.tencent.com/developer/article/1327007)

## strace

strace -p进程号或者线程号

## stress

* stress是一个Linux系统压力测试工具，可模拟CPU、IO、内存负载
    - 先`yum install -y epel-release`, 再 `yum install -y stress`
        + EPEL (Extra Packages for Enterprise Linux)是基于Fedora的一个项目，为“红帽系”的操作系统提供额外的软件包，适用于RHEL、CentOS和Scientific Linux.
        + 首先我们需要安装一个叫”epel-release”的软件包，这个软件包会自动配置yum的软件仓库。当然你也可以不安装这个包，自己配置软件仓库也是一样的。 软件仓库配置目录在：`/etc/yum.repos.d/`

* 使用
    - `-t N` 或 `--timeout N`：运行秒数
    - `-c N` 或 `--cpu N`：产生多个处理sqrt()函数的CPU进程
        + `stress -c 2 -t 10` 其两个进程测CPU，跑10s
    - `-i N` 或 `--io N`：产生多个处理sync()函数的磁盘I/O进程
    - `-m N` 或 `--vm N`：产生多个处理malloc()/free()内存分配函数的进程
        + `--vm-bytes B`：指定内存的byte数为B，默认值是256MB
        + `--vm-hang N`：指定malloc分配的内存多少秒后free()释放掉，默认不释放，0无效
    - `-d N` 或 `--hdd N`：产生多个处理write()/unlink()的进程
        + `--hdd-bytes B`：指定每个hdd进程处理的byte字节数，默认1GB

## mpstat

[mpstat命令](https://man.linuxde.net/mpstat)

* mpstat
    - mpstat命令指令主要用于多CPU环境下，它显示各个可用CPU的状态信息，包括硬件软件中断信息。
    - 这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。
    - 包含在 sysstat 软件包中，`yum info sysstat`查看该软件包信息(CentOS)
    - `mpstat [ -A ] [ -u ] [ -V ] [ -I { SUM | CPU | SCPU | ALL } ] [ -P { cpu [,...] | ON | ALL } ] [ interval [ count ] ]` (最后两个参数用于指定间隔和次数)
    - `mpstat (选项) (参数)`
        + 选项-P：指定CPU编号，指定-P ALL 则显示所有逻辑CPU列表，并会显示一个all的统计
        + 参数 间隔时间：每次报告的间隔时间（秒）；
        + 参数 次数：显示报告的次数。
        + e.g. `mpstat -P ALL 5 2` 所有CPU，间隔5S，只显示2次(参数和选项均为可选)
    - 当mpstat不带参数时，输出为从系统启动以来的平均值，*默认打印CPU*使用报告
    - The mpstat command can be used both on SMP and UP machines
        + UP（Uni-Processor）：系统只有一个处理器单元，即单核CPU系统
        + SMP（Symmetric Multi-Processors）：系统有多个处理器单元。各个处理器之间共享总线，内存等等。 在操作系统看来，各个处理器之间没有区别。

```sh
[➜ /home/xd/ ]$ mpstat -P ALL 3 #间隔3s，该虚拟机环境有两个逻辑CPU
Linux 3.10.0-957.el7.x86_64 (localhost.localdomain)     2019年11月25日     _x86_64_    (2 CPU)

13时56分13秒  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
13时56分16秒  all   48.71    0.00    0.00    0.00    0.00    0.17    0.00    0.00    0.00   51.11
13时56分16秒    0   91.17    0.00    0.00    0.00    0.00    0.35    0.00    0.00    0.00    8.48
13时56分16秒    1    8.31    0.00    0.33    0.00    0.00    0.33    0.00    0.00    0.00   91.03
```

* 含义
    - CPU CPU编号(all为平均)
    - %usr
        + 在用户态的CPU使用率
    - %nice
        + 在用户态以nice等级执行时的CPU使用率
            * nice/renice设置nice值为非0时，CPU跑在%nice等级上，看mpstat里%usr的使用率会比较小，大部分使用率在%nice列
            * nice默认0时，%nice列是0.00
    - %sys
        + 内核态的CPU使用率(注意不包含硬件和软件中断的时间)
    - %iowait
        + 系统有未完成的磁盘IO请求时，CPU闲置状态的时间百分比
    - %irq
        + CPU为服务硬件中断的时间百分比
    - %soft
        + CPU为服务软件中断的时间百分比
    - %steal
        + 管理程序为另一个虚拟处理器提供服务时，虚拟CPU非自愿等待所花费的时间百分比
    - %guest
        + CPU运行一个虚拟处理器花费的时间百分比
    - %gnice
        + CPU运行一个设置了nice的客户机花费的时间百分比
    - %idle
        + CPU处于空闲状态且系统没有未完成的磁盘I/O请求时的时间百分比

## pidstat



## ps各项释义

```sh
[➜ /home/xd/ ]$ ps -lp9467
F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD
1 R  1000  9467  9466 99  80   0 -  1827 -      pts/4    00:36:24 stress
```

* 含义
    - 查看man手册
    - F(PROCESS FLAGS): flags associated with the process，进程相关的标志
        + `1    forked but didn't exec` fork但不执行
        + `4    used super-user privileges` 使用超级用户权限
    - S(PROCESS STATE CODES): 进程的状态
        + D    uninterruptible sleep (usually IO)，不可中断状态(最常见的是等待硬件设备的 I/O 响应)
        + R    running or runnable (on run queue)，运行或者可运行状态
        + S    interruptible sleep (waiting for an event to complete)，可中断的的sleep
        + T    stopped by job control signal，任务控制信号中止
        + t    stopped by debugger during the tracing
        + W    paging (not valid since the 2.6.xx kernel)，2.6内核版本之后无效
        + X    dead (should never be seen)，看不到该状态
        + Z    defunct ("zombie") process, terminated but not reaped by its parent，僵尸进程
    - UID 进程号
    - PPID 父进程号
    - C(pcpu) CPU使用率
    - PRI
        + 进程优先级，值越*小*优先级越*高*
        + 一般启动进程的PRI为 20
    - NI 进程nice值
        + 表示进程可被执行的优先级的修正数值
        + PRI值越小越快被执行，那么加入nice值后，将会使得PRI变为：`PRI(new)=PRI(old)+nice` (即通过nice/renice修改nice会改变PRI)
        + 当nice值为负值的时候，那么该程序新PRI值将变小，即其优先级会变高，则其越快被执行
        + 进程的nice值不是进程的优先级，它们不是一个概念，但是进程nice值会影响到进程的优先级变化
    - ADDR
    - SZ
        + size in physical pages of the core image of the process，映射到内存中的页面, 这些页面仅由进程单独使用，进程实际占用的内存数
        + VSZ
            * virtual memory size of the process in KiB (1024-byte units), 进程的虚拟内存大小(KB)
        + RSS
            * resident set size, the non-swapped physical memory that a task has used (in kiloBytes), 常驻集大小，任务使用的非交换物理内存(KB)
            * This is usually at least 20 KiB of memory that is always resident，通常有20KB常驻内存
    - WCHAN
        + address of the kernel function where the process is sleeping 进程正在休眠的内核函数的地址，运行中的进程将显示'-'
    - TTY
        + tty ==> 泛指所有终端(Terminal)
        + 它是 Teletype(或者TeletypeWriter)的缩写，中文翻译：电传打字机
    - TIME
        + accumulated cpu time, user + system，累计cpu时间，用户+系统

* 修改进程优先级的命令主要有两个：`nice`, `renice`
    - [linux进程优先级、进程nice值](https://blog.csdn.net/codestinity/article/details/7496962)
    - `nice` 改变程序执行的优先权等级
        + 语法：`nice [-n <优先等级>][--help][--version][执行指令]`
            * -n 设置欲执行的指令的优先权等级，等级的范围从[-20, 19]，其中-20最高，19最低 (即值越小，进程优先级越高)
    - `renice` renice指令可重新调整程序执行的优先权等级。
        + e.g. `renice -5 -p 5200`, 将5200进程的nice设置为-5
    - 也可以在`top`中，输入`r`，对指定PID进行nice的调整设置

* 僵尸进程
    - 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。
    - 一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为**僵尸进程**。
    - 危害：如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。
* 孤儿进程
    - 一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
    - 孤儿进程不会导致资源浪费

## htop

[htop使用详解](https://www.cnblogs.com/yqsun/p/5396363.html)

官网安装：https://sourceforge.net/projects/htop/ , 下载tar.gz文件解压，./configure; make; make install

* 比较
    - 两者相比起来，top比较繁琐
    - 默认支持图形界面的鼠标操作
    - 可以横向或纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行
    - 杀进程时不需要输入进程号等

* htop每列内容与top差不多，多了不少便捷的操作
    - 可以通过鼠标进行点击操作，最下方栏列出了F1~F10，都可以通过鼠标点击，当然也可以按键盘按键
    - `S` (或`F2`) 进行一些htop的设置，里面可以用鼠标操作(按快捷键会自动修改里面的配置)
        + Meters (htop顶端的显示项)
            * 分左右两边, 从Available meters中选择，F5添加到左边，F6添加到右边(最下面有操作提示信息)
            * 在对应的选项上按回车，可以选择该项展示的方式: LED会模拟液晶屏显示/Bar显示进度条/Text文本
            * 本设置：添加hostname(文本), Clock(文本，显示时间)
        + Display options (显示选项)
            * 可以设置线程是否展示、线程名称是否展示等(可以勾选显示线程名)
            * 本设置：取消用户线程隐藏、不同颜色显示线程、显示线程名、高亮程序基本名称
        + Colors 设置显示颜色，默认颜色挺舒服的
        + Columns 选择主面板要展示的列，默认的列是跟top保持一致的，可以定制选择加一些列
            * 本设置：添加读和写io、忽略信号
        + **设置是本用户生效**
    - `/` (或`F3`) 可搜索进程名，光标会跳到进程位置
    - `\` (或`F4`) 过滤进程，和F3类似，不过过滤后只显示该进程
        + 退出该模式则再次按下`\` (可以看到输入还是上次的关键字)，需要再Esc退出(此时回车只会退出本次输入)
    - `t` (或`F5`) 显示树形结构
    - `k` (或`F9`) 对进程传递信号，按下后左边会多出一个信号列表视图(右边视图停留在选择的进程)，可用鼠标或上下键选择要传递的信号
    - `q` (或`F10`) 退出htop
    - `u` 选择展示列表中某个用户的进程，要退出则再按u后选所有用户
    - `H` 显示或隐藏用户线程，默认是显示(默认显示进程名，可以设置显示线程名，不过`\`过滤时就只能过滤显示进程名，线程名不一样则显示不了，可以配合ps -Tp或者top -Hp找到对应线程号，再到htop中查看跟踪)
    - `M`/`P`/`T` 按内存/CPU/TIME+ 排序，用`I` 来倒转排序顺序
    - `s` 对选择的进程来用`strace`追踪
